{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(828, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"result_nback.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "#Transform data\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(828, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.delete(data, 1, 1) #timestamp\n",
    "data = np.delete(data, 2, 1) # EEG_F3_Alpha\n",
    "data = np.delete(data, 3, 1) # EEG_F3_Beta\n",
    "data = np.delete(data, 4, 1) # EEG_F3_Theta\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nback gyakorlas', 286880.0, 170520.0, 933.41, 4.9275, 307.67,\n",
       "       343.79], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"nback gyakorlas\",\"0back\",\"1back\",\"2back\",\"3back\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "data[:, 1] = preprocessing.scale(data[:, 1])\n",
    "data[:, 2] = preprocessing.scale(data[:, 2])\n",
    "data[:, 3] = preprocessing.scale(data[:, 3])\n",
    "data[:, 4] = preprocessing.scale(data[:, 4])\n",
    "data[:, 5] = preprocessing.scale(data[:, 5])\n",
    "data[:, 6] = preprocessing.scale(data[:, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i, 0] = level2int[data[i, 0]]\n",
    "\n",
    "x_data = data[:, 1:]\n",
    "y_data = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 6) (579, 5) (124, 6) (124, 5) (125, 6) (125, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, input_shape=(6,)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579 samples, validate on 124 samples\n",
      "Epoch 1/150\n",
      "579/579 [==============================] - 0s - loss: 1.5075 - acc: 0.3506 - val_loss: 1.4087 - val_acc: 0.3548\n",
      "Epoch 2/150\n",
      "579/579 [==============================] - 0s - loss: 1.4099 - acc: 0.4145 - val_loss: 1.3227 - val_acc: 0.4274\n",
      "Epoch 3/150\n",
      "579/579 [==============================] - 0s - loss: 1.3506 - acc: 0.4214 - val_loss: 1.2816 - val_acc: 0.4919\n",
      "Epoch 4/150\n",
      "579/579 [==============================] - 0s - loss: 1.3291 - acc: 0.4525 - val_loss: 1.2545 - val_acc: 0.4839\n",
      "Epoch 5/150\n",
      "579/579 [==============================] - 0s - loss: 1.3031 - acc: 0.4680 - val_loss: 1.2365 - val_acc: 0.4597\n",
      "Epoch 6/150\n",
      "579/579 [==============================] - 0s - loss: 1.2589 - acc: 0.4905 - val_loss: 1.1967 - val_acc: 0.5161\n",
      "Epoch 7/150\n",
      "579/579 [==============================] - 0s - loss: 1.2470 - acc: 0.4974 - val_loss: 1.1793 - val_acc: 0.4597\n",
      "Epoch 8/150\n",
      "579/579 [==============================] - 0s - loss: 1.2004 - acc: 0.5147 - val_loss: 1.1605 - val_acc: 0.5081\n",
      "Epoch 9/150\n",
      "579/579 [==============================] - 0s - loss: 1.1960 - acc: 0.5268 - val_loss: 1.1221 - val_acc: 0.5323\n",
      "Epoch 10/150\n",
      "579/579 [==============================] - 0s - loss: 1.1714 - acc: 0.4957 - val_loss: 1.1159 - val_acc: 0.5081\n",
      "Epoch 11/150\n",
      "579/579 [==============================] - 0s - loss: 1.1596 - acc: 0.5095 - val_loss: 1.0793 - val_acc: 0.5323\n",
      "Epoch 12/150\n",
      "579/579 [==============================] - 0s - loss: 1.1255 - acc: 0.5112 - val_loss: 1.0594 - val_acc: 0.5323\n",
      "Epoch 13/150\n",
      "579/579 [==============================] - 0s - loss: 1.1186 - acc: 0.5406 - val_loss: 1.0694 - val_acc: 0.5161\n",
      "Epoch 14/150\n",
      "579/579 [==============================] - 0s - loss: 1.1172 - acc: 0.5406 - val_loss: 1.0313 - val_acc: 0.5242\n",
      "Epoch 15/150\n",
      "579/579 [==============================] - 0s - loss: 1.0679 - acc: 0.5440 - val_loss: 1.0353 - val_acc: 0.5403\n",
      "Epoch 16/150\n",
      "579/579 [==============================] - 0s - loss: 1.0675 - acc: 0.5440 - val_loss: 1.0055 - val_acc: 0.5968\n",
      "Epoch 17/150\n",
      "579/579 [==============================] - 0s - loss: 1.0125 - acc: 0.5976 - val_loss: 0.9607 - val_acc: 0.5887\n",
      "Epoch 18/150\n",
      "579/579 [==============================] - 0s - loss: 1.0463 - acc: 0.5682 - val_loss: 0.9581 - val_acc: 0.5645\n",
      "Epoch 19/150\n",
      "579/579 [==============================] - 0s - loss: 1.0086 - acc: 0.5820 - val_loss: 0.9623 - val_acc: 0.5968\n",
      "Epoch 20/150\n",
      "579/579 [==============================] - 0s - loss: 0.9792 - acc: 0.6010 - val_loss: 0.9107 - val_acc: 0.6371\n",
      "Epoch 21/150\n",
      "579/579 [==============================] - 0s - loss: 0.9980 - acc: 0.6045 - val_loss: 0.9431 - val_acc: 0.5887\n",
      "Epoch 22/150\n",
      "579/579 [==============================] - 0s - loss: 0.9507 - acc: 0.6235 - val_loss: 0.8877 - val_acc: 0.6694\n",
      "Epoch 23/150\n",
      "579/579 [==============================] - 0s - loss: 0.9760 - acc: 0.6149 - val_loss: 0.9023 - val_acc: 0.5968\n",
      "Epoch 24/150\n",
      "579/579 [==============================] - 0s - loss: 0.9325 - acc: 0.6062 - val_loss: 0.8809 - val_acc: 0.5726\n",
      "Epoch 25/150\n",
      "579/579 [==============================] - 0s - loss: 0.9167 - acc: 0.6235 - val_loss: 0.8877 - val_acc: 0.6129\n",
      "Epoch 26/150\n",
      "579/579 [==============================] - 0s - loss: 0.8805 - acc: 0.6390 - val_loss: 0.8358 - val_acc: 0.6129\n",
      "Epoch 27/150\n",
      "579/579 [==============================] - 0s - loss: 0.9041 - acc: 0.6149 - val_loss: 0.8697 - val_acc: 0.5968\n",
      "Epoch 28/150\n",
      "579/579 [==============================] - 0s - loss: 0.8928 - acc: 0.6287 - val_loss: 0.8414 - val_acc: 0.6452\n",
      "Epoch 29/150\n",
      "579/579 [==============================] - 0s - loss: 0.8905 - acc: 0.6356 - val_loss: 0.8267 - val_acc: 0.6129\n",
      "Epoch 30/150\n",
      "579/579 [==============================] - 0s - loss: 0.8521 - acc: 0.6598 - val_loss: 0.8192 - val_acc: 0.6532\n",
      "Epoch 31/150\n",
      "579/579 [==============================] - 0s - loss: 0.8548 - acc: 0.6235 - val_loss: 0.8678 - val_acc: 0.6371\n",
      "Epoch 32/150\n",
      "579/579 [==============================] - 0s - loss: 0.8599 - acc: 0.6615 - val_loss: 0.7894 - val_acc: 0.6613\n",
      "Epoch 33/150\n",
      "579/579 [==============================] - 0s - loss: 0.8391 - acc: 0.6494 - val_loss: 0.8072 - val_acc: 0.6371\n",
      "Epoch 34/150\n",
      "579/579 [==============================] - 0s - loss: 0.8322 - acc: 0.6632 - val_loss: 0.7855 - val_acc: 0.6371\n",
      "Epoch 35/150\n",
      "579/579 [==============================] - 0s - loss: 0.8462 - acc: 0.6494 - val_loss: 0.7637 - val_acc: 0.6774\n",
      "Epoch 36/150\n",
      "579/579 [==============================] - 0s - loss: 0.8193 - acc: 0.6701 - val_loss: 0.7916 - val_acc: 0.6210\n",
      "Epoch 37/150\n",
      "579/579 [==============================] - 0s - loss: 0.8465 - acc: 0.6528 - val_loss: 0.8094 - val_acc: 0.6532\n",
      "Epoch 38/150\n",
      "579/579 [==============================] - 0s - loss: 0.8314 - acc: 0.6649 - val_loss: 0.8092 - val_acc: 0.6210\n",
      "Epoch 39/150\n",
      "579/579 [==============================] - 0s - loss: 0.8134 - acc: 0.6995 - val_loss: 0.7317 - val_acc: 0.6452\n",
      "Epoch 40/150\n",
      "579/579 [==============================] - 0s - loss: 0.7721 - acc: 0.6770 - val_loss: 0.7964 - val_acc: 0.6290\n",
      "Epoch 41/150\n",
      "579/579 [==============================] - 0s - loss: 0.7698 - acc: 0.7029 - val_loss: 0.7394 - val_acc: 0.6452\n",
      "Epoch 42/150\n",
      "579/579 [==============================] - 0s - loss: 0.7699 - acc: 0.6943 - val_loss: 0.7559 - val_acc: 0.6532\n",
      "Epoch 43/150\n",
      "579/579 [==============================] - 0s - loss: 0.7658 - acc: 0.6822 - val_loss: 0.7611 - val_acc: 0.6371\n",
      "Epoch 44/150\n",
      "579/579 [==============================] - 0s - loss: 0.7594 - acc: 0.6822 - val_loss: 0.7679 - val_acc: 0.6694\n",
      "Epoch 45/150\n",
      "579/579 [==============================] - 0s - loss: 0.7479 - acc: 0.6857 - val_loss: 0.7305 - val_acc: 0.6613\n",
      "Epoch 46/150\n",
      "579/579 [==============================] - 0s - loss: 0.7509 - acc: 0.7064 - val_loss: 0.6901 - val_acc: 0.6613\n",
      "Epoch 47/150\n",
      "579/579 [==============================] - 0s - loss: 0.7215 - acc: 0.6978 - val_loss: 0.7244 - val_acc: 0.6855\n",
      "Epoch 48/150\n",
      "579/579 [==============================] - 0s - loss: 0.7409 - acc: 0.7271 - val_loss: 0.7775 - val_acc: 0.6371\n",
      "Epoch 49/150\n",
      "579/579 [==============================] - 0s - loss: 0.7753 - acc: 0.6960 - val_loss: 0.6938 - val_acc: 0.6935\n",
      "Epoch 50/150\n",
      "579/579 [==============================] - 0s - loss: 0.7547 - acc: 0.6908 - val_loss: 0.7081 - val_acc: 0.7016\n",
      "Epoch 51/150\n",
      "579/579 [==============================] - 0s - loss: 0.7104 - acc: 0.7081 - val_loss: 0.6862 - val_acc: 0.6694\n",
      "Epoch 52/150\n",
      "579/579 [==============================] - 0s - loss: 0.7458 - acc: 0.6891 - val_loss: 0.6825 - val_acc: 0.6613\n",
      "Epoch 53/150\n",
      "579/579 [==============================] - 0s - loss: 0.6880 - acc: 0.7375 - val_loss: 0.6726 - val_acc: 0.7016\n",
      "Epoch 54/150\n",
      "579/579 [==============================] - 0s - loss: 0.6986 - acc: 0.7323 - val_loss: 0.6430 - val_acc: 0.6855\n",
      "Epoch 55/150\n",
      "579/579 [==============================] - 0s - loss: 0.6877 - acc: 0.7237 - val_loss: 0.6753 - val_acc: 0.6613\n",
      "Epoch 56/150\n",
      "579/579 [==============================] - 0s - loss: 0.6607 - acc: 0.7392 - val_loss: 0.6823 - val_acc: 0.7258\n",
      "Epoch 57/150\n",
      "579/579 [==============================] - 0s - loss: 0.7107 - acc: 0.7168 - val_loss: 0.6315 - val_acc: 0.7016\n",
      "Epoch 58/150\n",
      "579/579 [==============================] - 0s - loss: 0.6965 - acc: 0.7254 - val_loss: 0.6514 - val_acc: 0.6855\n",
      "Epoch 59/150\n",
      "579/579 [==============================] - 0s - loss: 0.6959 - acc: 0.7219 - val_loss: 0.6331 - val_acc: 0.6855\n",
      "Epoch 60/150\n",
      "579/579 [==============================] - 0s - loss: 0.6740 - acc: 0.7323 - val_loss: 0.6255 - val_acc: 0.6935\n",
      "Epoch 61/150\n",
      "579/579 [==============================] - 0s - loss: 0.6869 - acc: 0.7012 - val_loss: 0.6514 - val_acc: 0.7258\n",
      "Epoch 62/150\n",
      "579/579 [==============================] - 0s - loss: 0.6612 - acc: 0.7444 - val_loss: 0.6329 - val_acc: 0.6935\n",
      "Epoch 63/150\n",
      "579/579 [==============================] - 0s - loss: 0.6455 - acc: 0.7427 - val_loss: 0.6161 - val_acc: 0.7419\n",
      "Epoch 64/150\n",
      "579/579 [==============================] - 0s - loss: 0.6520 - acc: 0.7340 - val_loss: 0.6174 - val_acc: 0.7177\n",
      "Epoch 65/150\n",
      "579/579 [==============================] - 0s - loss: 0.6348 - acc: 0.7288 - val_loss: 0.6379 - val_acc: 0.7581\n",
      "Epoch 66/150\n",
      "579/579 [==============================] - 0s - loss: 0.6073 - acc: 0.7686 - val_loss: 0.6027 - val_acc: 0.7661\n",
      "Epoch 67/150\n",
      "579/579 [==============================] - 0s - loss: 0.6477 - acc: 0.7375 - val_loss: 0.6073 - val_acc: 0.7177\n",
      "Epoch 68/150\n",
      "579/579 [==============================] - 0s - loss: 0.6693 - acc: 0.7288 - val_loss: 0.5943 - val_acc: 0.7500\n",
      "Epoch 69/150\n",
      "579/579 [==============================] - 0s - loss: 0.6247 - acc: 0.7617 - val_loss: 0.6372 - val_acc: 0.6935\n",
      "Epoch 70/150\n",
      "579/579 [==============================] - 0s - loss: 0.6416 - acc: 0.7237 - val_loss: 0.5796 - val_acc: 0.7823\n",
      "Epoch 71/150\n",
      "579/579 [==============================] - 0s - loss: 0.6008 - acc: 0.7686 - val_loss: 0.5883 - val_acc: 0.7742\n",
      "Epoch 72/150\n",
      "579/579 [==============================] - 0s - loss: 0.5929 - acc: 0.7634 - val_loss: 0.5726 - val_acc: 0.7661\n",
      "Epoch 73/150\n",
      "579/579 [==============================] - 0s - loss: 0.6252 - acc: 0.7565 - val_loss: 0.6201 - val_acc: 0.7097\n",
      "Epoch 74/150\n",
      "579/579 [==============================] - 0s - loss: 0.6237 - acc: 0.7496 - val_loss: 0.6183 - val_acc: 0.7097\n",
      "Epoch 75/150\n",
      "579/579 [==============================] - 0s - loss: 0.5829 - acc: 0.7547 - val_loss: 0.5675 - val_acc: 0.7903\n",
      "Epoch 76/150\n",
      "579/579 [==============================] - 0s - loss: 0.6306 - acc: 0.7409 - val_loss: 0.5602 - val_acc: 0.7661\n",
      "Epoch 77/150\n",
      "579/579 [==============================] - 0s - loss: 0.6026 - acc: 0.7392 - val_loss: 0.5666 - val_acc: 0.7500\n",
      "Epoch 78/150\n",
      "579/579 [==============================] - 0s - loss: 0.6021 - acc: 0.7651 - val_loss: 0.5679 - val_acc: 0.7742\n",
      "Epoch 79/150\n",
      "579/579 [==============================] - 0s - loss: 0.6234 - acc: 0.7375 - val_loss: 0.5899 - val_acc: 0.7258\n",
      "Epoch 80/150\n",
      "579/579 [==============================] - 0s - loss: 0.6127 - acc: 0.7617 - val_loss: 0.5724 - val_acc: 0.7661\n",
      "Epoch 81/150\n",
      "579/579 [==============================] - 0s - loss: 0.6158 - acc: 0.7565 - val_loss: 0.6248 - val_acc: 0.7419\n",
      "Epoch 82/150\n",
      "579/579 [==============================] - 0s - loss: 0.6017 - acc: 0.7599 - val_loss: 0.5623 - val_acc: 0.7419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe713e6850>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 150\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/125 [=======================>......] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.69764662384986875, 0.7520000100135803]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
