{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "Data read started...\n",
      "Data read finished.\n",
      "(522, 11) (603, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "nback = pd.read_csv(\"result_nback_3.csv\")\n",
    "nback = nback.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(\"Data read started...\")\n",
    "tetris = pd.read_csv(\"result_tetris.csv\")\n",
    "tetris = tetris.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(nback.shape, tetris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(522, 7) (603, 7)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    nback = np.delete(nback, 1, 1) \n",
    "    tetris = np.delete(tetris, 1, 1)\n",
    "\n",
    "print(nback.shape, tetris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3back', 1318300.0, 1839.9, 673.37, 4.746279069767441, 371.67,\n",
       "       522.54], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_nback=[\"1back\",\"2back\",\"3back\"]\n",
    "level_tetris=[\"tetris1\",\"tetris2\",\"tetris3\"]\n",
    "\n",
    "level_n2int = dict((p, i) for i, p in enumerate(level_nback))\n",
    "int2level_n = dict((i, p) for i, p in enumerate(level_nback))\n",
    "\n",
    "level_t2int = dict((p, i) for i, p in enumerate(level_tetris))\n",
    "int2level_t = dict((i, p) for i, p in enumerate(level_tetris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,7):\n",
    "    nback[:, i] = preprocessing.scale(nback[:, i])\n",
    "    tetris[:, i] = preprocessing.scale(tetris[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(nback)):\n",
    "    nback[i, 0] = level_n2int[nback[i, 0]]\n",
    "    \n",
    "for i in range(len(tetris)):\n",
    "    tetris[i, 0] = level_t2int[tetris[i, 0]]\n",
    "\n",
    "x_nback = nback[:, 1:]\n",
    "y_nback = nback[:, 0]\n",
    "x_tetris = tetris[:, 1:]\n",
    "y_tetris = tetris[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]] [[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "nback_one_hot = ohe.fit_transform(y_nback.reshape(-1,1)).toarray()\n",
    "tetris_one_hot = ohe.fit_transform(y_tetris.reshape(-1,1)).toarray()\n",
    "print(nback_one_hot, tetris_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(nback.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_nback = x_nback[indices]\n",
    "nback_one_hot = nback_one_hot[indices]\n",
    "\n",
    "indices = np.arange(tetris.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_tetris = x_tetris[indices]\n",
    "tetris_one_hot = tetris_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_train = int(len(x_nback)*0.85)\n",
    "\n",
    "x_train = x_nback[0:nb_train]\n",
    "y_train = nback_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_nback[nb_train:]\n",
    "y_valid = nback_one_hot[nb_train:]\n",
    "\n",
    "x_test = x_tetris[0:100]\n",
    "y_test = tetris_one_hot[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 6) (443, 3) (79, 6) (79, 3) (100, 6) (100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, input_shape=(6,)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 443 samples, validate on 79 samples\n",
      "Epoch 1/150\n",
      "443/443 [==============================] - 0s - loss: 1.0041 - acc: 0.5102 - val_loss: 0.8811 - val_acc: 0.6456\n",
      "Epoch 2/150\n",
      "443/443 [==============================] - 0s - loss: 0.9024 - acc: 0.6208 - val_loss: 0.8326 - val_acc: 0.6329\n",
      "Epoch 3/150\n",
      "443/443 [==============================] - 0s - loss: 0.8694 - acc: 0.6208 - val_loss: 0.8360 - val_acc: 0.6456\n",
      "Epoch 4/150\n",
      "443/443 [==============================] - 0s - loss: 0.8236 - acc: 0.6591 - val_loss: 0.8349 - val_acc: 0.6582\n",
      "Epoch 5/150\n",
      "443/443 [==============================] - 0s - loss: 0.8205 - acc: 0.6456 - val_loss: 0.8110 - val_acc: 0.6582\n",
      "Epoch 6/150\n",
      "443/443 [==============================] - 0s - loss: 0.8044 - acc: 0.6546 - val_loss: 0.7990 - val_acc: 0.6582\n",
      "Epoch 7/150\n",
      "443/443 [==============================] - 0s - loss: 0.7927 - acc: 0.6614 - val_loss: 0.7859 - val_acc: 0.6582\n",
      "Epoch 8/150\n",
      "443/443 [==============================] - 0s - loss: 0.7886 - acc: 0.6614 - val_loss: 0.7779 - val_acc: 0.6709\n",
      "Epoch 9/150\n",
      "443/443 [==============================] - 0s - loss: 0.7345 - acc: 0.6637 - val_loss: 0.7702 - val_acc: 0.6709\n",
      "Epoch 10/150\n",
      "443/443 [==============================] - 0s - loss: 0.7354 - acc: 0.6704 - val_loss: 0.7392 - val_acc: 0.6835\n",
      "Epoch 11/150\n",
      "443/443 [==============================] - 0s - loss: 0.7444 - acc: 0.6682 - val_loss: 0.7356 - val_acc: 0.6835\n",
      "Epoch 12/150\n",
      "443/443 [==============================] - 0s - loss: 0.7160 - acc: 0.6953 - val_loss: 0.7362 - val_acc: 0.6709\n",
      "Epoch 13/150\n",
      "443/443 [==============================] - 0s - loss: 0.7320 - acc: 0.6772 - val_loss: 0.7061 - val_acc: 0.6962\n",
      "Epoch 14/150\n",
      "443/443 [==============================] - 0s - loss: 0.6829 - acc: 0.7201 - val_loss: 0.6914 - val_acc: 0.7215\n",
      "Epoch 15/150\n",
      "443/443 [==============================] - 0s - loss: 0.6801 - acc: 0.7178 - val_loss: 0.6974 - val_acc: 0.7215\n",
      "Epoch 16/150\n",
      "443/443 [==============================] - 0s - loss: 0.6661 - acc: 0.7336 - val_loss: 0.6849 - val_acc: 0.7342\n",
      "Epoch 17/150\n",
      "443/443 [==============================] - 0s - loss: 0.6612 - acc: 0.7472 - val_loss: 0.6713 - val_acc: 0.7089\n",
      "Epoch 18/150\n",
      "443/443 [==============================] - 0s - loss: 0.6691 - acc: 0.7223 - val_loss: 0.6504 - val_acc: 0.7089\n",
      "Epoch 19/150\n",
      "443/443 [==============================] - 0s - loss: 0.6480 - acc: 0.7381 - val_loss: 0.6364 - val_acc: 0.6962\n",
      "Epoch 20/150\n",
      "443/443 [==============================] - 0s - loss: 0.6203 - acc: 0.7494 - val_loss: 0.6429 - val_acc: 0.6835\n",
      "Epoch 21/150\n",
      "443/443 [==============================] - 0s - loss: 0.6140 - acc: 0.7585 - val_loss: 0.6321 - val_acc: 0.6709\n",
      "Epoch 22/150\n",
      "443/443 [==============================] - 0s - loss: 0.6241 - acc: 0.7336 - val_loss: 0.6111 - val_acc: 0.6835\n",
      "Epoch 23/150\n",
      "443/443 [==============================] - 0s - loss: 0.5862 - acc: 0.7720 - val_loss: 0.5985 - val_acc: 0.7089\n",
      "Epoch 24/150\n",
      "443/443 [==============================] - 0s - loss: 0.5894 - acc: 0.7404 - val_loss: 0.5969 - val_acc: 0.7342\n",
      "Epoch 25/150\n",
      "443/443 [==============================] - 0s - loss: 0.6079 - acc: 0.7427 - val_loss: 0.6091 - val_acc: 0.7089\n",
      "Epoch 26/150\n",
      "443/443 [==============================] - 0s - loss: 0.5833 - acc: 0.7494 - val_loss: 0.5817 - val_acc: 0.7089\n",
      "Epoch 27/150\n",
      "443/443 [==============================] - 0s - loss: 0.5879 - acc: 0.7698 - val_loss: 0.6026 - val_acc: 0.7342\n",
      "Epoch 28/150\n",
      "443/443 [==============================] - 0s - loss: 0.5718 - acc: 0.7743 - val_loss: 0.5694 - val_acc: 0.7215\n",
      "Epoch 29/150\n",
      "443/443 [==============================] - 0s - loss: 0.5594 - acc: 0.7743 - val_loss: 0.5897 - val_acc: 0.6962\n",
      "Epoch 30/150\n",
      "443/443 [==============================] - 0s - loss: 0.5517 - acc: 0.7856 - val_loss: 0.5551 - val_acc: 0.7595\n",
      "Epoch 31/150\n",
      "443/443 [==============================] - 0s - loss: 0.5451 - acc: 0.7833 - val_loss: 0.5543 - val_acc: 0.7848\n",
      "Epoch 32/150\n",
      "443/443 [==============================] - 0s - loss: 0.5627 - acc: 0.7675 - val_loss: 0.5710 - val_acc: 0.7342\n",
      "Epoch 33/150\n",
      "443/443 [==============================] - 0s - loss: 0.5456 - acc: 0.7878 - val_loss: 0.5451 - val_acc: 0.7722\n",
      "Epoch 34/150\n",
      "443/443 [==============================] - 0s - loss: 0.5251 - acc: 0.7765 - val_loss: 0.5362 - val_acc: 0.7595\n",
      "Epoch 35/150\n",
      "443/443 [==============================] - 0s - loss: 0.5497 - acc: 0.7494 - val_loss: 0.5649 - val_acc: 0.7468\n",
      "Epoch 36/150\n",
      "443/443 [==============================] - 0s - loss: 0.5367 - acc: 0.7968 - val_loss: 0.5387 - val_acc: 0.7595\n",
      "Epoch 37/150\n",
      "443/443 [==============================] - 0s - loss: 0.5251 - acc: 0.7765 - val_loss: 0.5327 - val_acc: 0.7595\n",
      "Epoch 38/150\n",
      "443/443 [==============================] - 0s - loss: 0.5207 - acc: 0.7810 - val_loss: 0.5514 - val_acc: 0.7595\n",
      "Epoch 39/150\n",
      "443/443 [==============================] - 0s - loss: 0.5117 - acc: 0.7991 - val_loss: 0.5306 - val_acc: 0.7848\n",
      "Epoch 40/150\n",
      "443/443 [==============================] - 0s - loss: 0.4963 - acc: 0.7923 - val_loss: 0.5241 - val_acc: 0.7342\n",
      "Epoch 41/150\n",
      "443/443 [==============================] - 0s - loss: 0.4885 - acc: 0.7856 - val_loss: 0.5217 - val_acc: 0.7722\n",
      "Epoch 42/150\n",
      "443/443 [==============================] - 0s - loss: 0.4997 - acc: 0.7968 - val_loss: 0.5268 - val_acc: 0.7722\n",
      "Epoch 43/150\n",
      "443/443 [==============================] - 0s - loss: 0.4838 - acc: 0.8081 - val_loss: 0.5088 - val_acc: 0.7722\n",
      "Epoch 44/150\n",
      "443/443 [==============================] - 0s - loss: 0.5043 - acc: 0.7856 - val_loss: 0.5139 - val_acc: 0.7342\n",
      "Epoch 45/150\n",
      "443/443 [==============================] - 0s - loss: 0.4934 - acc: 0.7991 - val_loss: 0.5199 - val_acc: 0.7595\n",
      "Epoch 46/150\n",
      "443/443 [==============================] - 0s - loss: 0.4780 - acc: 0.7968 - val_loss: 0.5127 - val_acc: 0.7975\n",
      "Epoch 47/150\n",
      "443/443 [==============================] - 0s - loss: 0.4733 - acc: 0.7901 - val_loss: 0.5121 - val_acc: 0.7848\n",
      "Epoch 48/150\n",
      "443/443 [==============================] - 0s - loss: 0.4619 - acc: 0.8104 - val_loss: 0.5071 - val_acc: 0.7975\n",
      "Epoch 49/150\n",
      "443/443 [==============================] - 0s - loss: 0.4960 - acc: 0.7878 - val_loss: 0.5028 - val_acc: 0.7848\n",
      "Epoch 50/150\n",
      "443/443 [==============================] - 0s - loss: 0.4504 - acc: 0.8104 - val_loss: 0.4893 - val_acc: 0.7848\n",
      "Epoch 51/150\n",
      "443/443 [==============================] - 0s - loss: 0.4799 - acc: 0.7901 - val_loss: 0.4892 - val_acc: 0.7468\n",
      "Epoch 52/150\n",
      "443/443 [==============================] - 0s - loss: 0.4552 - acc: 0.8059 - val_loss: 0.5071 - val_acc: 0.7595\n",
      "Epoch 53/150\n",
      "443/443 [==============================] - 0s - loss: 0.4338 - acc: 0.8172 - val_loss: 0.4851 - val_acc: 0.7595\n",
      "Epoch 54/150\n",
      "443/443 [==============================] - 0s - loss: 0.4782 - acc: 0.7901 - val_loss: 0.5013 - val_acc: 0.7595\n",
      "Epoch 55/150\n",
      "443/443 [==============================] - 0s - loss: 0.4410 - acc: 0.8126 - val_loss: 0.4976 - val_acc: 0.7595\n",
      "Epoch 56/150\n",
      "443/443 [==============================] - 0s - loss: 0.4508 - acc: 0.8036 - val_loss: 0.4850 - val_acc: 0.7848\n",
      "Epoch 57/150\n",
      "443/443 [==============================] - 0s - loss: 0.4398 - acc: 0.8194 - val_loss: 0.4956 - val_acc: 0.7595\n",
      "Epoch 58/150\n",
      "443/443 [==============================] - 0s - loss: 0.4309 - acc: 0.8194 - val_loss: 0.4969 - val_acc: 0.7595\n",
      "Epoch 59/150\n",
      "443/443 [==============================] - 0s - loss: 0.4363 - acc: 0.8104 - val_loss: 0.4873 - val_acc: 0.7722\n",
      "Epoch 60/150\n",
      "443/443 [==============================] - 0s - loss: 0.4258 - acc: 0.8149 - val_loss: 0.4908 - val_acc: 0.7595\n",
      "Epoch 61/150\n",
      "443/443 [==============================] - 0s - loss: 0.4186 - acc: 0.8239 - val_loss: 0.4899 - val_acc: 0.7595\n",
      "Epoch 62/150\n",
      "443/443 [==============================] - 0s - loss: 0.4041 - acc: 0.8330 - val_loss: 0.4895 - val_acc: 0.7468\n",
      "Epoch 63/150\n",
      "443/443 [==============================] - 0s - loss: 0.4162 - acc: 0.8307 - val_loss: 0.4870 - val_acc: 0.7975\n",
      "Epoch 64/150\n",
      "443/443 [==============================] - 0s - loss: 0.4012 - acc: 0.8172 - val_loss: 0.4899 - val_acc: 0.7975\n",
      "Epoch 65/150\n",
      "443/443 [==============================] - 0s - loss: 0.4054 - acc: 0.8194 - val_loss: 0.4878 - val_acc: 0.7468\n",
      "Epoch 66/150\n",
      "443/443 [==============================] - 0s - loss: 0.4112 - acc: 0.8375 - val_loss: 0.5055 - val_acc: 0.7595\n",
      "Epoch 67/150\n",
      "443/443 [==============================] - 0s - loss: 0.4165 - acc: 0.8172 - val_loss: 0.4758 - val_acc: 0.7848\n",
      "Epoch 68/150\n",
      "443/443 [==============================] - 0s - loss: 0.4019 - acc: 0.8172 - val_loss: 0.4685 - val_acc: 0.7722\n",
      "Epoch 69/150\n",
      "443/443 [==============================] - 0s - loss: 0.3898 - acc: 0.8307 - val_loss: 0.4942 - val_acc: 0.7595\n",
      "Epoch 70/150\n",
      "443/443 [==============================] - 0s - loss: 0.4196 - acc: 0.8104 - val_loss: 0.4903 - val_acc: 0.7595\n",
      "Epoch 71/150\n",
      "443/443 [==============================] - 0s - loss: 0.3907 - acc: 0.8104 - val_loss: 0.4839 - val_acc: 0.7595\n",
      "Epoch 72/150\n",
      "443/443 [==============================] - 0s - loss: 0.3934 - acc: 0.8307 - val_loss: 0.4745 - val_acc: 0.7722\n",
      "Epoch 73/150\n",
      "443/443 [==============================] - 0s - loss: 0.3795 - acc: 0.8307 - val_loss: 0.4931 - val_acc: 0.7468\n",
      "Epoch 74/150\n",
      "443/443 [==============================] - 0s - loss: 0.3916 - acc: 0.8262 - val_loss: 0.4995 - val_acc: 0.7468\n",
      "Epoch 75/150\n",
      "443/443 [==============================] - 0s - loss: 0.4096 - acc: 0.8239 - val_loss: 0.4692 - val_acc: 0.7848\n",
      "Epoch 76/150\n",
      "443/443 [==============================] - 0s - loss: 0.3771 - acc: 0.8330 - val_loss: 0.4806 - val_acc: 0.7722\n",
      "Epoch 77/150\n",
      "443/443 [==============================] - 0s - loss: 0.3916 - acc: 0.8239 - val_loss: 0.4808 - val_acc: 0.7595\n",
      "Epoch 78/150\n",
      "443/443 [==============================] - 0s - loss: 0.3656 - acc: 0.8533 - val_loss: 0.4787 - val_acc: 0.7595\n",
      "Epoch 79/150\n",
      "443/443 [==============================] - 0s - loss: 0.3614 - acc: 0.8465 - val_loss: 0.4802 - val_acc: 0.7468\n",
      "Epoch 80/150\n",
      "443/443 [==============================] - 0s - loss: 0.3553 - acc: 0.8488 - val_loss: 0.4548 - val_acc: 0.7848\n",
      "Epoch 81/150\n",
      "443/443 [==============================] - 0s - loss: 0.3977 - acc: 0.8284 - val_loss: 0.4752 - val_acc: 0.7468\n",
      "Epoch 82/150\n",
      "443/443 [==============================] - 0s - loss: 0.3752 - acc: 0.8262 - val_loss: 0.4727 - val_acc: 0.7595\n",
      "Epoch 83/150\n",
      "443/443 [==============================] - 0s - loss: 0.3919 - acc: 0.8262 - val_loss: 0.4867 - val_acc: 0.7595\n",
      "Epoch 84/150\n",
      "443/443 [==============================] - 0s - loss: 0.3663 - acc: 0.8397 - val_loss: 0.4841 - val_acc: 0.7722\n",
      "Epoch 85/150\n",
      "443/443 [==============================] - 0s - loss: 0.3637 - acc: 0.8284 - val_loss: 0.4760 - val_acc: 0.7848\n",
      "Epoch 86/150\n",
      "443/443 [==============================] - 0s - loss: 0.3525 - acc: 0.8691 - val_loss: 0.4673 - val_acc: 0.7722\n",
      "Epoch 87/150\n",
      "443/443 [==============================] - 0s - loss: 0.3631 - acc: 0.8307 - val_loss: 0.4617 - val_acc: 0.7722\n",
      "Epoch 88/150\n",
      "443/443 [==============================] - 0s - loss: 0.3741 - acc: 0.8397 - val_loss: 0.4679 - val_acc: 0.7975\n",
      "Epoch 89/150\n",
      "443/443 [==============================] - 0s - loss: 0.3736 - acc: 0.8420 - val_loss: 0.4515 - val_acc: 0.7722\n",
      "Epoch 90/150\n",
      "443/443 [==============================] - 0s - loss: 0.3620 - acc: 0.8330 - val_loss: 0.4859 - val_acc: 0.7342\n",
      "Epoch 91/150\n",
      "443/443 [==============================] - 0s - loss: 0.3612 - acc: 0.8420 - val_loss: 0.4767 - val_acc: 0.7595\n",
      "Epoch 92/150\n",
      "443/443 [==============================] - 0s - loss: 0.3462 - acc: 0.8600 - val_loss: 0.4474 - val_acc: 0.7722\n",
      "Epoch 93/150\n",
      "443/443 [==============================] - 0s - loss: 0.3600 - acc: 0.8262 - val_loss: 0.4317 - val_acc: 0.7595\n",
      "Epoch 94/150\n",
      "443/443 [==============================] - 0s - loss: 0.3512 - acc: 0.8420 - val_loss: 0.4403 - val_acc: 0.8101\n",
      "Epoch 95/150\n",
      "443/443 [==============================] - 0s - loss: 0.3401 - acc: 0.8488 - val_loss: 0.4497 - val_acc: 0.7595\n",
      "Epoch 96/150\n",
      "443/443 [==============================] - 0s - loss: 0.3586 - acc: 0.8307 - val_loss: 0.4614 - val_acc: 0.7595\n",
      "Epoch 97/150\n",
      "443/443 [==============================] - 0s - loss: 0.3419 - acc: 0.8442 - val_loss: 0.4850 - val_acc: 0.7595\n",
      "Epoch 98/150\n",
      "443/443 [==============================] - 0s - loss: 0.3435 - acc: 0.8330 - val_loss: 0.4765 - val_acc: 0.7468\n",
      "Epoch 99/150\n",
      "443/443 [==============================] - 0s - loss: 0.3289 - acc: 0.8465 - val_loss: 0.4648 - val_acc: 0.7468\n",
      "Epoch 100/150\n",
      "443/443 [==============================] - 0s - loss: 0.3390 - acc: 0.8600 - val_loss: 0.4638 - val_acc: 0.7722\n",
      "Epoch 101/150\n",
      "443/443 [==============================] - 0s - loss: 0.3213 - acc: 0.8510 - val_loss: 0.4789 - val_acc: 0.7468\n",
      "Epoch 102/150\n",
      "443/443 [==============================] - 0s - loss: 0.3334 - acc: 0.8623 - val_loss: 0.4544 - val_acc: 0.7848\n",
      "Epoch 103/150\n",
      "443/443 [==============================] - 0s - loss: 0.3195 - acc: 0.8600 - val_loss: 0.4657 - val_acc: 0.7595\n",
      "Epoch 104/150\n",
      "443/443 [==============================] - 0s - loss: 0.3215 - acc: 0.8713 - val_loss: 0.4759 - val_acc: 0.7468\n",
      "Epoch 105/150\n",
      "443/443 [==============================] - 0s - loss: 0.3393 - acc: 0.8488 - val_loss: 0.4697 - val_acc: 0.7595\n",
      "Epoch 106/150\n",
      "443/443 [==============================] - 0s - loss: 0.3306 - acc: 0.8646 - val_loss: 0.4831 - val_acc: 0.7595\n",
      "Epoch 107/150\n",
      "443/443 [==============================] - 0s - loss: 0.3301 - acc: 0.8420 - val_loss: 0.4679 - val_acc: 0.7722\n",
      "Epoch 108/150\n",
      "443/443 [==============================] - 0s - loss: 0.3303 - acc: 0.8736 - val_loss: 0.4580 - val_acc: 0.7722\n",
      "Epoch 109/150\n",
      "443/443 [==============================] - 0s - loss: 0.3330 - acc: 0.8781 - val_loss: 0.4662 - val_acc: 0.7595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcd16bbd90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 150\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.3876605033874512, 0.21000000089406967]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/100 [========>.....................] - ETA: 0s[2 2 2 0 2 0 2 0 0 2 2 1 2 1 2 1 2 1 2 2 0 2 2 2 2 0 1 2 0 2 0 0 0 2 2 1 1\n",
      " 2 0 1 1 2 1 2 2 0 1 0 2 0 1 2 1 2 2 1 0 0 2 2 2 0 1 2 1 1 0 0 0 1 0 2 2 2\n",
      " 0 1 2 0 2 2 1 0 2 1 2 2 2 0 2 2 2 0 2 0 0 2 2 1 2 0]\n",
      " 32/100 [========>.....................] - ETA: 0s                 precision    recall  f1-score   support\n",
      "\n",
      "class 0(level1)       0.07      0.06      0.06        35\n",
      "class 1(level2)       0.50      0.29      0.37        38\n",
      "class 2(level3)       0.16      0.30      0.21        27\n",
      "\n",
      "    avg / total       0.26      0.21      0.22       100\n",
      "\n",
      "[[ 2  6 27]\n",
      " [13 11 14]\n",
      " [14  5  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(level1)', 'class 1(level2)', 'class 2(level3)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
