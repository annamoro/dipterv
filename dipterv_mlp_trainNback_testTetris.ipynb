{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "Data read started...\n",
      "Data read finished.\n",
      "(522, 11) (603, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "nback = pd.read_csv(\"result_nback_3.csv\")\n",
    "nback = nback.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(\"Data read started...\")\n",
    "tetris = pd.read_csv(\"result_tetris.csv\")\n",
    "tetris = tetris.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(nback.shape, tetris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(522, 7) (603, 7)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    nback = np.delete(nback, i, 1) \n",
    "    tetris = np.delete(tetris, i, 1)\n",
    "\n",
    "print(nback.shape, tetris.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3back', 126910.0, 150630.0, 1839.9, 4.746279069767441, 371.67,\n",
       "       522.54], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nback[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_nback=[\"1back\",\"2back\",\"3back\"]\n",
    "level_tetris=[\"tetris1\",\"tetris2\",\"tetris3\"]\n",
    "\n",
    "level_n2int = dict((p, i) for i, p in enumerate(level_nback))\n",
    "int2level_n = dict((i, p) for i, p in enumerate(level_nback))\n",
    "\n",
    "level_t2int = dict((p, i) for i, p in enumerate(level_tetris))\n",
    "int2level_t = dict((i, p) for i, p in enumerate(level_tetris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,7):\n",
    "    nback[:, i] = preprocessing.scale(nback[:, i])\n",
    "    tetris[:, i] = preprocessing.scale(tetris[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(nback)):\n",
    "    nback[i, 0] = level_n2int[nback[i, 0]]\n",
    "    \n",
    "for i in range(len(tetris)):\n",
    "    tetris[i, 0] = level_t2int[tetris[i, 0]]\n",
    "\n",
    "x_nback = nback[:, 1:]\n",
    "y_nback = nback[:, 0]\n",
    "x_tetris = tetris[:, 1:]\n",
    "y_tetris = tetris[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]] [[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "nback_one_hot = ohe.fit_transform(y_nback.reshape(-1,1)).toarray()\n",
    "tetris_one_hot = ohe.fit_transform(y_tetris.reshape(-1,1)).toarray()\n",
    "print(nback_one_hot, tetris_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(nback.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_nback = x_nback[indices]\n",
    "nback_one_hot = nback_one_hot[indices]\n",
    "\n",
    "indices = np.arange(tetris.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_tetris = x_tetris[indices]\n",
    "tetris_one_hot = tetris_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_train = int(len(x_nback)*0.85)\n",
    "\n",
    "x_train = x_nback[0:nb_train]\n",
    "y_train = nback_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_nback[nb_train:]\n",
    "y_valid = nback_one_hot[nb_train:]\n",
    "\n",
    "x_test = x_tetris[0:100]\n",
    "y_test = tetris_one_hot[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(443, 6) (443, 3) (79, 6) (79, 3) (100, 6) (100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, input_shape=(6,)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 443 samples, validate on 79 samples\n",
      "Epoch 1/150\n",
      "443/443 [==============================] - 0s - loss: 1.0030 - acc: 0.4876 - val_loss: 0.9027 - val_acc: 0.6076\n",
      "Epoch 2/150\n",
      "443/443 [==============================] - 0s - loss: 0.9272 - acc: 0.5937 - val_loss: 0.8678 - val_acc: 0.5949\n",
      "Epoch 3/150\n",
      "443/443 [==============================] - 0s - loss: 0.8875 - acc: 0.6027 - val_loss: 0.8641 - val_acc: 0.6582\n",
      "Epoch 4/150\n",
      "443/443 [==============================] - 0s - loss: 0.8550 - acc: 0.6027 - val_loss: 0.8679 - val_acc: 0.6582\n",
      "Epoch 5/150\n",
      "443/443 [==============================] - 0s - loss: 0.8450 - acc: 0.6208 - val_loss: 0.8494 - val_acc: 0.6582\n",
      "Epoch 6/150\n",
      "443/443 [==============================] - 0s - loss: 0.8371 - acc: 0.6321 - val_loss: 0.8447 - val_acc: 0.6456\n",
      "Epoch 7/150\n",
      "443/443 [==============================] - 0s - loss: 0.8130 - acc: 0.6388 - val_loss: 0.8394 - val_acc: 0.6709\n",
      "Epoch 8/150\n",
      "443/443 [==============================] - 0s - loss: 0.8145 - acc: 0.6343 - val_loss: 0.8354 - val_acc: 0.6582\n",
      "Epoch 9/150\n",
      "443/443 [==============================] - 0s - loss: 0.7861 - acc: 0.6321 - val_loss: 0.8260 - val_acc: 0.6582\n",
      "Epoch 10/150\n",
      "443/443 [==============================] - 0s - loss: 0.7866 - acc: 0.6433 - val_loss: 0.8040 - val_acc: 0.6709\n",
      "Epoch 11/150\n",
      "443/443 [==============================] - 0s - loss: 0.7864 - acc: 0.6366 - val_loss: 0.8168 - val_acc: 0.6835\n",
      "Epoch 12/150\n",
      "443/443 [==============================] - 0s - loss: 0.7779 - acc: 0.6659 - val_loss: 0.8263 - val_acc: 0.6582\n",
      "Epoch 13/150\n",
      "443/443 [==============================] - 0s - loss: 0.7837 - acc: 0.6479 - val_loss: 0.7945 - val_acc: 0.6962\n",
      "Epoch 14/150\n",
      "443/443 [==============================] - 0s - loss: 0.7383 - acc: 0.6840 - val_loss: 0.7735 - val_acc: 0.6582\n",
      "Epoch 15/150\n",
      "443/443 [==============================] - 0s - loss: 0.7355 - acc: 0.6704 - val_loss: 0.7886 - val_acc: 0.6835\n",
      "Epoch 16/150\n",
      "443/443 [==============================] - 0s - loss: 0.7202 - acc: 0.6749 - val_loss: 0.7751 - val_acc: 0.7089\n",
      "Epoch 17/150\n",
      "443/443 [==============================] - 0s - loss: 0.7110 - acc: 0.7088 - val_loss: 0.7814 - val_acc: 0.6835\n",
      "Epoch 18/150\n",
      "443/443 [==============================] - 0s - loss: 0.7196 - acc: 0.6885 - val_loss: 0.7626 - val_acc: 0.7089\n",
      "Epoch 19/150\n",
      "443/443 [==============================] - 0s - loss: 0.7068 - acc: 0.6998 - val_loss: 0.7398 - val_acc: 0.6962\n",
      "Epoch 20/150\n",
      "443/443 [==============================] - 0s - loss: 0.6910 - acc: 0.6998 - val_loss: 0.7457 - val_acc: 0.6835\n",
      "Epoch 21/150\n",
      "443/443 [==============================] - 0s - loss: 0.6855 - acc: 0.7201 - val_loss: 0.7263 - val_acc: 0.6835\n",
      "Epoch 22/150\n",
      "443/443 [==============================] - 0s - loss: 0.6802 - acc: 0.6930 - val_loss: 0.7099 - val_acc: 0.6835\n",
      "Epoch 23/150\n",
      "443/443 [==============================] - 0s - loss: 0.6633 - acc: 0.6998 - val_loss: 0.7255 - val_acc: 0.6709\n",
      "Epoch 24/150\n",
      "443/443 [==============================] - 0s - loss: 0.6652 - acc: 0.7178 - val_loss: 0.7201 - val_acc: 0.7089\n",
      "Epoch 25/150\n",
      "443/443 [==============================] - 0s - loss: 0.6703 - acc: 0.7043 - val_loss: 0.7111 - val_acc: 0.7089\n",
      "Epoch 26/150\n",
      "443/443 [==============================] - 0s - loss: 0.6550 - acc: 0.7223 - val_loss: 0.6908 - val_acc: 0.7215\n",
      "Epoch 27/150\n",
      "443/443 [==============================] - 0s - loss: 0.6375 - acc: 0.7223 - val_loss: 0.6883 - val_acc: 0.7215\n",
      "Epoch 28/150\n",
      "443/443 [==============================] - 0s - loss: 0.6290 - acc: 0.7381 - val_loss: 0.6764 - val_acc: 0.7342\n",
      "Epoch 29/150\n",
      "443/443 [==============================] - 0s - loss: 0.6346 - acc: 0.7178 - val_loss: 0.6914 - val_acc: 0.7089\n",
      "Epoch 30/150\n",
      "443/443 [==============================] - 0s - loss: 0.6271 - acc: 0.7427 - val_loss: 0.6722 - val_acc: 0.7215\n",
      "Epoch 31/150\n",
      "443/443 [==============================] - 0s - loss: 0.6299 - acc: 0.7269 - val_loss: 0.6613 - val_acc: 0.7089\n",
      "Epoch 32/150\n",
      "443/443 [==============================] - 0s - loss: 0.6333 - acc: 0.7291 - val_loss: 0.6665 - val_acc: 0.7342\n",
      "Epoch 33/150\n",
      "443/443 [==============================] - 0s - loss: 0.6212 - acc: 0.7381 - val_loss: 0.6561 - val_acc: 0.6962\n",
      "Epoch 34/150\n",
      "443/443 [==============================] - 0s - loss: 0.5969 - acc: 0.7291 - val_loss: 0.6481 - val_acc: 0.7215\n",
      "Epoch 35/150\n",
      "443/443 [==============================] - 0s - loss: 0.5930 - acc: 0.7472 - val_loss: 0.6416 - val_acc: 0.7215\n",
      "Epoch 36/150\n",
      "443/443 [==============================] - 0s - loss: 0.6003 - acc: 0.7630 - val_loss: 0.6343 - val_acc: 0.7342\n",
      "Epoch 37/150\n",
      "443/443 [==============================] - 0s - loss: 0.5855 - acc: 0.7540 - val_loss: 0.6398 - val_acc: 0.7342\n",
      "Epoch 38/150\n",
      "443/443 [==============================] - 0s - loss: 0.5786 - acc: 0.7494 - val_loss: 0.6539 - val_acc: 0.7089\n",
      "Epoch 39/150\n",
      "443/443 [==============================] - 0s - loss: 0.5650 - acc: 0.7472 - val_loss: 0.6262 - val_acc: 0.7342\n",
      "Epoch 40/150\n",
      "443/443 [==============================] - 0s - loss: 0.5717 - acc: 0.7517 - val_loss: 0.6215 - val_acc: 0.7215\n",
      "Epoch 41/150\n",
      "443/443 [==============================] - 0s - loss: 0.5694 - acc: 0.7540 - val_loss: 0.6090 - val_acc: 0.7089\n",
      "Epoch 42/150\n",
      "443/443 [==============================] - 0s - loss: 0.5795 - acc: 0.7314 - val_loss: 0.6244 - val_acc: 0.7215\n",
      "Epoch 43/150\n",
      "443/443 [==============================] - 0s - loss: 0.5613 - acc: 0.7449 - val_loss: 0.6194 - val_acc: 0.7215\n",
      "Epoch 44/150\n",
      "443/443 [==============================] - 0s - loss: 0.5582 - acc: 0.7291 - val_loss: 0.6045 - val_acc: 0.7215\n",
      "Epoch 45/150\n",
      "443/443 [==============================] - 0s - loss: 0.5584 - acc: 0.7562 - val_loss: 0.5939 - val_acc: 0.7215\n",
      "Epoch 46/150\n",
      "443/443 [==============================] - 0s - loss: 0.5418 - acc: 0.7698 - val_loss: 0.6149 - val_acc: 0.7342\n",
      "Epoch 47/150\n",
      "443/443 [==============================] - 0s - loss: 0.5649 - acc: 0.7472 - val_loss: 0.6051 - val_acc: 0.6962\n",
      "Epoch 48/150\n",
      "443/443 [==============================] - 0s - loss: 0.5490 - acc: 0.7540 - val_loss: 0.5892 - val_acc: 0.7342\n",
      "Epoch 49/150\n",
      "443/443 [==============================] - 0s - loss: 0.5442 - acc: 0.7607 - val_loss: 0.5912 - val_acc: 0.7215\n",
      "Epoch 50/150\n",
      "443/443 [==============================] - 0s - loss: 0.5325 - acc: 0.7856 - val_loss: 0.5769 - val_acc: 0.7215\n",
      "Epoch 51/150\n",
      "443/443 [==============================] - 0s - loss: 0.5353 - acc: 0.7585 - val_loss: 0.5802 - val_acc: 0.7342\n",
      "Epoch 52/150\n",
      "443/443 [==============================] - 0s - loss: 0.5318 - acc: 0.7675 - val_loss: 0.5780 - val_acc: 0.7468\n",
      "Epoch 53/150\n",
      "443/443 [==============================] - 0s - loss: 0.5143 - acc: 0.7720 - val_loss: 0.5664 - val_acc: 0.7342\n",
      "Epoch 54/150\n",
      "443/443 [==============================] - 0s - loss: 0.5373 - acc: 0.7675 - val_loss: 0.5942 - val_acc: 0.7089\n",
      "Epoch 55/150\n",
      "443/443 [==============================] - 0s - loss: 0.5244 - acc: 0.7494 - val_loss: 0.5697 - val_acc: 0.7342\n",
      "Epoch 56/150\n",
      "443/443 [==============================] - 0s - loss: 0.5199 - acc: 0.7652 - val_loss: 0.5570 - val_acc: 0.7215\n",
      "Epoch 57/150\n",
      "443/443 [==============================] - 0s - loss: 0.5095 - acc: 0.8014 - val_loss: 0.5539 - val_acc: 0.7468\n",
      "Epoch 58/150\n",
      "443/443 [==============================] - 0s - loss: 0.5012 - acc: 0.7585 - val_loss: 0.5597 - val_acc: 0.7342\n",
      "Epoch 59/150\n",
      "443/443 [==============================] - 0s - loss: 0.5077 - acc: 0.7856 - val_loss: 0.5687 - val_acc: 0.7215\n",
      "Epoch 60/150\n",
      "443/443 [==============================] - 0s - loss: 0.5202 - acc: 0.7720 - val_loss: 0.5499 - val_acc: 0.7468\n",
      "Epoch 61/150\n",
      "443/443 [==============================] - 0s - loss: 0.5172 - acc: 0.7788 - val_loss: 0.5647 - val_acc: 0.7468\n",
      "Epoch 62/150\n",
      "443/443 [==============================] - 0s - loss: 0.4999 - acc: 0.7788 - val_loss: 0.5661 - val_acc: 0.7215\n",
      "Epoch 63/150\n",
      "443/443 [==============================] - 0s - loss: 0.4838 - acc: 0.7878 - val_loss: 0.5501 - val_acc: 0.7342\n",
      "Epoch 64/150\n",
      "443/443 [==============================] - 0s - loss: 0.4783 - acc: 0.8262 - val_loss: 0.5471 - val_acc: 0.7342\n",
      "Epoch 65/150\n",
      "443/443 [==============================] - 0s - loss: 0.4865 - acc: 0.7788 - val_loss: 0.5455 - val_acc: 0.7468\n",
      "Epoch 66/150\n",
      "443/443 [==============================] - 0s - loss: 0.4777 - acc: 0.7946 - val_loss: 0.5545 - val_acc: 0.7468\n",
      "Epoch 67/150\n",
      "443/443 [==============================] - 0s - loss: 0.4923 - acc: 0.7923 - val_loss: 0.5300 - val_acc: 0.7595\n",
      "Epoch 68/150\n",
      "443/443 [==============================] - 0s - loss: 0.4787 - acc: 0.7991 - val_loss: 0.5130 - val_acc: 0.7722\n",
      "Epoch 69/150\n",
      "443/443 [==============================] - 0s - loss: 0.4781 - acc: 0.7991 - val_loss: 0.5436 - val_acc: 0.7468\n",
      "Epoch 70/150\n",
      "443/443 [==============================] - 0s - loss: 0.4946 - acc: 0.7946 - val_loss: 0.5410 - val_acc: 0.7722\n",
      "Epoch 71/150\n",
      "443/443 [==============================] - 0s - loss: 0.4603 - acc: 0.8172 - val_loss: 0.5196 - val_acc: 0.7468\n",
      "Epoch 72/150\n",
      "443/443 [==============================] - 0s - loss: 0.4651 - acc: 0.8014 - val_loss: 0.5148 - val_acc: 0.7722\n",
      "Epoch 73/150\n",
      "443/443 [==============================] - 0s - loss: 0.4858 - acc: 0.7833 - val_loss: 0.5259 - val_acc: 0.7722\n",
      "Epoch 74/150\n",
      "443/443 [==============================] - 0s - loss: 0.4693 - acc: 0.8239 - val_loss: 0.5213 - val_acc: 0.7595\n",
      "Epoch 75/150\n",
      "443/443 [==============================] - 0s - loss: 0.4749 - acc: 0.8059 - val_loss: 0.5176 - val_acc: 0.7848\n",
      "Epoch 76/150\n",
      "443/443 [==============================] - 0s - loss: 0.4751 - acc: 0.8036 - val_loss: 0.5288 - val_acc: 0.7722\n",
      "Epoch 77/150\n",
      "443/443 [==============================] - 0s - loss: 0.4539 - acc: 0.8059 - val_loss: 0.5347 - val_acc: 0.7595\n",
      "Epoch 78/150\n",
      "443/443 [==============================] - 0s - loss: 0.4387 - acc: 0.8149 - val_loss: 0.5132 - val_acc: 0.7722\n",
      "Epoch 79/150\n",
      "443/443 [==============================] - 0s - loss: 0.4464 - acc: 0.8081 - val_loss: 0.5015 - val_acc: 0.7595\n",
      "Epoch 80/150\n",
      "443/443 [==============================] - 0s - loss: 0.4366 - acc: 0.8104 - val_loss: 0.4984 - val_acc: 0.7848\n",
      "Epoch 81/150\n",
      "443/443 [==============================] - 0s - loss: 0.4401 - acc: 0.8081 - val_loss: 0.5087 - val_acc: 0.7722\n",
      "Epoch 82/150\n",
      "443/443 [==============================] - 0s - loss: 0.4562 - acc: 0.8149 - val_loss: 0.5043 - val_acc: 0.7975\n",
      "Epoch 83/150\n",
      "443/443 [==============================] - 0s - loss: 0.4472 - acc: 0.8149 - val_loss: 0.5148 - val_acc: 0.7975\n",
      "Epoch 84/150\n",
      "443/443 [==============================] - 0s - loss: 0.4444 - acc: 0.8194 - val_loss: 0.5033 - val_acc: 0.7468\n",
      "Epoch 85/150\n",
      "443/443 [==============================] - 0s - loss: 0.4463 - acc: 0.8284 - val_loss: 0.5039 - val_acc: 0.7848\n",
      "Epoch 86/150\n",
      "443/443 [==============================] - 0s - loss: 0.4143 - acc: 0.8397 - val_loss: 0.4874 - val_acc: 0.7595\n",
      "Epoch 87/150\n",
      "443/443 [==============================] - 0s - loss: 0.4335 - acc: 0.8126 - val_loss: 0.4857 - val_acc: 0.7848\n",
      "Epoch 88/150\n",
      "443/443 [==============================] - 0s - loss: 0.4506 - acc: 0.8307 - val_loss: 0.4889 - val_acc: 0.7722\n",
      "Epoch 89/150\n",
      "443/443 [==============================] - 0s - loss: 0.4346 - acc: 0.8149 - val_loss: 0.4812 - val_acc: 0.7722\n",
      "Epoch 90/150\n",
      "443/443 [==============================] - 0s - loss: 0.4353 - acc: 0.8217 - val_loss: 0.5027 - val_acc: 0.7848\n",
      "Epoch 91/150\n",
      "443/443 [==============================] - 0s - loss: 0.4473 - acc: 0.8059 - val_loss: 0.4783 - val_acc: 0.7848\n",
      "Epoch 92/150\n",
      "443/443 [==============================] - 0s - loss: 0.4425 - acc: 0.8104 - val_loss: 0.4595 - val_acc: 0.7975\n",
      "Epoch 93/150\n",
      "443/443 [==============================] - 0s - loss: 0.4279 - acc: 0.8194 - val_loss: 0.4611 - val_acc: 0.7975\n",
      "Epoch 94/150\n",
      "443/443 [==============================] - 0s - loss: 0.4155 - acc: 0.8330 - val_loss: 0.4786 - val_acc: 0.7848\n",
      "Epoch 95/150\n",
      "443/443 [==============================] - 0s - loss: 0.4387 - acc: 0.8149 - val_loss: 0.4694 - val_acc: 0.7848\n",
      "Epoch 96/150\n",
      "443/443 [==============================] - 0s - loss: 0.4164 - acc: 0.8194 - val_loss: 0.4708 - val_acc: 0.7722\n",
      "Epoch 97/150\n",
      "443/443 [==============================] - 0s - loss: 0.3997 - acc: 0.8375 - val_loss: 0.4850 - val_acc: 0.7848\n",
      "Epoch 98/150\n",
      "443/443 [==============================] - 0s - loss: 0.4000 - acc: 0.8397 - val_loss: 0.4707 - val_acc: 0.7975\n",
      "Epoch 99/150\n",
      "443/443 [==============================] - 0s - loss: 0.4251 - acc: 0.8239 - val_loss: 0.4815 - val_acc: 0.7722\n",
      "Epoch 100/150\n",
      "443/443 [==============================] - 0s - loss: 0.3984 - acc: 0.8442 - val_loss: 0.4648 - val_acc: 0.7975\n",
      "Epoch 101/150\n",
      "443/443 [==============================] - 0s - loss: 0.4084 - acc: 0.8284 - val_loss: 0.4626 - val_acc: 0.7848\n",
      "Epoch 102/150\n",
      "443/443 [==============================] - 0s - loss: 0.3970 - acc: 0.8284 - val_loss: 0.4647 - val_acc: 0.7848\n",
      "Epoch 103/150\n",
      "443/443 [==============================] - 0s - loss: 0.4040 - acc: 0.8442 - val_loss: 0.4607 - val_acc: 0.7848\n",
      "Epoch 104/150\n",
      "443/443 [==============================] - 0s - loss: 0.4060 - acc: 0.8397 - val_loss: 0.4481 - val_acc: 0.7975\n",
      "Epoch 105/150\n",
      "443/443 [==============================] - 0s - loss: 0.4048 - acc: 0.8262 - val_loss: 0.4477 - val_acc: 0.7848\n",
      "Epoch 106/150\n",
      "443/443 [==============================] - 0s - loss: 0.4161 - acc: 0.8239 - val_loss: 0.4591 - val_acc: 0.7848\n",
      "Epoch 107/150\n",
      "443/443 [==============================] - 0s - loss: 0.3925 - acc: 0.8397 - val_loss: 0.4504 - val_acc: 0.7848\n",
      "Epoch 108/150\n",
      "443/443 [==============================] - 0s - loss: 0.4095 - acc: 0.8194 - val_loss: 0.4543 - val_acc: 0.7848\n",
      "Epoch 109/150\n",
      "443/443 [==============================] - 0s - loss: 0.3958 - acc: 0.8330 - val_loss: 0.4615 - val_acc: 0.7975\n",
      "Epoch 110/150\n",
      "443/443 [==============================] - 0s - loss: 0.3809 - acc: 0.8397 - val_loss: 0.4441 - val_acc: 0.7848\n",
      "Epoch 111/150\n",
      "443/443 [==============================] - 0s - loss: 0.3877 - acc: 0.8555 - val_loss: 0.4483 - val_acc: 0.7848\n",
      "Epoch 112/150\n",
      "443/443 [==============================] - 0s - loss: 0.3956 - acc: 0.8420 - val_loss: 0.4473 - val_acc: 0.7848\n",
      "Epoch 113/150\n",
      "443/443 [==============================] - 0s - loss: 0.4115 - acc: 0.8352 - val_loss: 0.4641 - val_acc: 0.7848\n",
      "Epoch 114/150\n",
      "443/443 [==============================] - 0s - loss: 0.3851 - acc: 0.8600 - val_loss: 0.4434 - val_acc: 0.7848\n",
      "Epoch 115/150\n",
      "443/443 [==============================] - 0s - loss: 0.3931 - acc: 0.8352 - val_loss: 0.4254 - val_acc: 0.7848\n",
      "Epoch 116/150\n",
      "443/443 [==============================] - 0s - loss: 0.4096 - acc: 0.8420 - val_loss: 0.4283 - val_acc: 0.7975\n",
      "Epoch 117/150\n",
      "443/443 [==============================] - 0s - loss: 0.3976 - acc: 0.8262 - val_loss: 0.4446 - val_acc: 0.7722\n",
      "Epoch 118/150\n",
      "443/443 [==============================] - 0s - loss: 0.3857 - acc: 0.8442 - val_loss: 0.4373 - val_acc: 0.7848\n",
      "Epoch 119/150\n",
      "443/443 [==============================] - 0s - loss: 0.3772 - acc: 0.8397 - val_loss: 0.4619 - val_acc: 0.7848\n",
      "Epoch 120/150\n",
      "443/443 [==============================] - 0s - loss: 0.3944 - acc: 0.8352 - val_loss: 0.4353 - val_acc: 0.7722\n",
      "Epoch 121/150\n",
      "443/443 [==============================] - 0s - loss: 0.3893 - acc: 0.8488 - val_loss: 0.4240 - val_acc: 0.7975\n",
      "Epoch 122/150\n",
      "443/443 [==============================] - 0s - loss: 0.3814 - acc: 0.8397 - val_loss: 0.4384 - val_acc: 0.7848\n",
      "Epoch 123/150\n",
      "443/443 [==============================] - 0s - loss: 0.3581 - acc: 0.8600 - val_loss: 0.4285 - val_acc: 0.7975\n",
      "Epoch 124/150\n",
      "443/443 [==============================] - 0s - loss: 0.3637 - acc: 0.8555 - val_loss: 0.4200 - val_acc: 0.7848\n",
      "Epoch 125/150\n",
      "443/443 [==============================] - 0s - loss: 0.3670 - acc: 0.8510 - val_loss: 0.4471 - val_acc: 0.7975\n",
      "Epoch 126/150\n",
      "443/443 [==============================] - 0s - loss: 0.3611 - acc: 0.8600 - val_loss: 0.4167 - val_acc: 0.7975\n",
      "Epoch 127/150\n",
      "443/443 [==============================] - 0s - loss: 0.3707 - acc: 0.8420 - val_loss: 0.4363 - val_acc: 0.7975\n",
      "Epoch 128/150\n",
      "443/443 [==============================] - 0s - loss: 0.3869 - acc: 0.8555 - val_loss: 0.4206 - val_acc: 0.7722\n",
      "Epoch 129/150\n",
      "443/443 [==============================] - 0s - loss: 0.3682 - acc: 0.8442 - val_loss: 0.4309 - val_acc: 0.7975\n",
      "Epoch 130/150\n",
      "443/443 [==============================] - 0s - loss: 0.3735 - acc: 0.8668 - val_loss: 0.4302 - val_acc: 0.7848\n",
      "Epoch 131/150\n",
      "443/443 [==============================] - 0s - loss: 0.3657 - acc: 0.8488 - val_loss: 0.4380 - val_acc: 0.7975\n",
      "Epoch 132/150\n",
      "443/443 [==============================] - 0s - loss: 0.3627 - acc: 0.8510 - val_loss: 0.4140 - val_acc: 0.7975\n",
      "Epoch 133/150\n",
      "443/443 [==============================] - 0s - loss: 0.3941 - acc: 0.8420 - val_loss: 0.3994 - val_acc: 0.7975\n",
      "Epoch 134/150\n",
      "443/443 [==============================] - 0s - loss: 0.3484 - acc: 0.8713 - val_loss: 0.4294 - val_acc: 0.7975\n",
      "Epoch 135/150\n",
      "443/443 [==============================] - 0s - loss: 0.3467 - acc: 0.8600 - val_loss: 0.4343 - val_acc: 0.7848\n",
      "Epoch 136/150\n",
      "443/443 [==============================] - 0s - loss: 0.3377 - acc: 0.8758 - val_loss: 0.4276 - val_acc: 0.7975\n",
      "Epoch 137/150\n",
      "443/443 [==============================] - 0s - loss: 0.3604 - acc: 0.8668 - val_loss: 0.4150 - val_acc: 0.8101\n",
      "Epoch 138/150\n",
      "443/443 [==============================] - 0s - loss: 0.3780 - acc: 0.8465 - val_loss: 0.4217 - val_acc: 0.8101\n",
      "Epoch 139/150\n",
      "443/443 [==============================] - 0s - loss: 0.3903 - acc: 0.8465 - val_loss: 0.4199 - val_acc: 0.8228\n",
      "Epoch 140/150\n",
      "443/443 [==============================] - 0s - loss: 0.3138 - acc: 0.8871 - val_loss: 0.4340 - val_acc: 0.8101\n",
      "Epoch 141/150\n",
      "443/443 [==============================] - 0s - loss: 0.3670 - acc: 0.8555 - val_loss: 0.4213 - val_acc: 0.7975\n",
      "Epoch 142/150\n",
      "443/443 [==============================] - 0s - loss: 0.3596 - acc: 0.8713 - val_loss: 0.3892 - val_acc: 0.8228\n",
      "Epoch 143/150\n",
      "443/443 [==============================] - 0s - loss: 0.3636 - acc: 0.8465 - val_loss: 0.4085 - val_acc: 0.8101\n",
      "Epoch 144/150\n",
      "443/443 [==============================] - 0s - loss: 0.3359 - acc: 0.8758 - val_loss: 0.3995 - val_acc: 0.8101\n",
      "Epoch 145/150\n",
      "443/443 [==============================] - 0s - loss: 0.3431 - acc: 0.8646 - val_loss: 0.4152 - val_acc: 0.7975\n",
      "Epoch 146/150\n",
      "443/443 [==============================] - 0s - loss: 0.3546 - acc: 0.8578 - val_loss: 0.4167 - val_acc: 0.7975\n",
      "Epoch 147/150\n",
      "443/443 [==============================] - 0s - loss: 0.3284 - acc: 0.8555 - val_loss: 0.4123 - val_acc: 0.7975\n",
      "Epoch 148/150\n",
      "443/443 [==============================] - 0s - loss: 0.3550 - acc: 0.8668 - val_loss: 0.4007 - val_acc: 0.7975\n",
      "Epoch 149/150\n",
      "443/443 [==============================] - 0s - loss: 0.3416 - acc: 0.8578 - val_loss: 0.3957 - val_acc: 0.8101\n",
      "Epoch 150/150\n",
      "443/443 [==============================] - 0s - loss: 0.3399 - acc: 0.8488 - val_loss: 0.4143 - val_acc: 0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6033a0bfd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 150\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50/100 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.2339520454406738, 0.22999999672174454]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/100 [========>.....................] - ETA: 0s[2 2 2 0 1 0 2 0 0 2 2 1 2 1 2 1 2 0 2 2 0 2 2 2 2 0 1 0 0 2 0 0 0 2 2 2 1\n",
      " 2 0 1 0 2 1 2 2 0 0 0 2 0 1 2 0 2 2 1 0 0 2 2 2 2 1 1 1 2 1 2 2 1 1 2 2 2\n",
      " 0 1 2 1 2 2 0 1 2 1 2 2 2 0 1 0 2 0 2 2 0 2 2 2 2 0]\n",
      " 32/100 [========>.....................] - ETA: 0s                 precision    recall  f1-score   support\n",
      "\n",
      "class 0(level1)       0.11      0.09      0.10        35\n",
      "class 1(level2)       0.48      0.26      0.34        38\n",
      "class 2(level3)       0.20      0.37      0.26        27\n",
      "\n",
      "    avg / total       0.27      0.23      0.23       100\n",
      "\n",
      "[[ 3  5 27]\n",
      " [14 10 14]\n",
      " [11  6 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(level1)', 'class 1(level2)', 'class 2(level3)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
