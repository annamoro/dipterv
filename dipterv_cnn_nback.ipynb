{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(622, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"nback/result1.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    data = np.delete(data, 1, 1) \n",
    "    \n",
    "#data = np.delete(data, 1, 1) \n",
    "data = data[:,0:7]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3back', 1537.7, 796.38, 36.961999999999996, 4.696727272727268,\n",
       "       8.947000000000001, 16.387999999999998], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero: 206  one:  130  two:  139  three:  147\n"
     ]
    }
   ],
   "source": [
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == '0back'):\n",
    "        zero = zero + 1\n",
    "    if (data[i, 0] == '1back'):\n",
    "        one = one + 1\n",
    "    if (data[i, 0] == '2back'):\n",
    "        two = two + 1\n",
    "    if (data[i, 0] == '3back'):\n",
    "        three = three + 1\n",
    "\n",
    "print('zero:', zero, ' one: ', one, ' two: ', two, ' three: ', three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"0back\",\"1back\",\"2back\",\"3back\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,7):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "back0 = np.zeros((zero,6))\n",
    "back1 = np.zeros((one,6))\n",
    "back2 = np.zeros((two,6))\n",
    "back3 = np.zeros((three,6))\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == '0back'):\n",
    "        back0[j] = data[i, 1:]\n",
    "        j = j+1\n",
    "    if (data[i, 0] == '1back'):\n",
    "        back1[k] = data[i, 1:]\n",
    "        k = k+1\n",
    "    if (data[i, 0] == '2back'):\n",
    "        back2[l] = data[i, 1:]\n",
    "        l = l+1\n",
    "    if (data[i, 0] == '3back'):\n",
    "        back3[m] = data[i, 1:]\n",
    "        m = m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_data = data[:, 0]\n",
    "for i in range(len(data)):\n",
    "    y_data[i] = level2int[y_data[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data for convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track = 50\n",
    "null = np.array([0,0,0,0,0,0])\n",
    "\n",
    "for i in range(track-1):\n",
    "        back0 = np.vstack([back0, null])\n",
    "        back1 = np.vstack([back1, null])\n",
    "        back2 = np.vstack([back2, null])\n",
    "        back3 = np.vstack([back3, null])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = np.zeros((data.shape[0],6,track))         # final input data for the network\n",
    "y_one_hot = np.zeros((data.shape[0],4))          # to store one-hot data groupped\n",
    "\n",
    "for i in range(len(one_hot)):\n",
    "    y_one_hot[i]=one_hot[i]\n",
    "\n",
    "for i in range(len(back0)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back0[i+j]\n",
    "        \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1, len(back0)-track+1 + len(back1)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back1[index+j]\n",
    "    index = index+1\n",
    "    \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1 + len(back1)-track+1, len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back2[index+j]\n",
    "    index = index+1\n",
    "    \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1, \n",
    "                   len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1 + len(back3)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back3[index+j]\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 6, 50) (435, 4) (93, 6, 50) (93, 4) (94, 6, 50) (94, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(input_shape=(x_train[0].shape[-2],x_train[0].shape[-1]),\n",
    "                        nb_filter=30,\n",
    "                        filter_length=2,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu')) \n",
    "# First max-pooling layer\n",
    "model.add(MaxPooling1D(pool_length=2,stride=1))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Convolution1D(nb_filter=30,\n",
    "                        filter_length=2,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Final fully-connected layer\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 435 samples, validate on 93 samples\n",
      "Epoch 1/150\n",
      "435/435 [==============================] - 0s - loss: 1.3829 - acc: 0.2759 - val_loss: 1.3681 - val_acc: 0.3656\n",
      "Epoch 2/150\n",
      "435/435 [==============================] - 0s - loss: 1.3563 - acc: 0.3724 - val_loss: 1.3412 - val_acc: 0.5054\n",
      "Epoch 3/150\n",
      "435/435 [==============================] - 0s - loss: 1.3161 - acc: 0.4621 - val_loss: 1.2862 - val_acc: 0.5914\n",
      "Epoch 4/150\n",
      "435/435 [==============================] - 0s - loss: 1.2487 - acc: 0.5195 - val_loss: 1.1983 - val_acc: 0.6237\n",
      "Epoch 5/150\n",
      "435/435 [==============================] - 0s - loss: 1.1601 - acc: 0.5471 - val_loss: 1.0931 - val_acc: 0.6989\n",
      "Epoch 6/150\n",
      "435/435 [==============================] - 0s - loss: 1.0586 - acc: 0.6023 - val_loss: 0.9729 - val_acc: 0.7419\n",
      "Epoch 7/150\n",
      "435/435 [==============================] - 0s - loss: 0.9696 - acc: 0.6483 - val_loss: 0.8687 - val_acc: 0.7742\n",
      "Epoch 8/150\n",
      "435/435 [==============================] - 0s - loss: 0.8863 - acc: 0.6851 - val_loss: 0.7760 - val_acc: 0.7742\n",
      "Epoch 9/150\n",
      "435/435 [==============================] - 0s - loss: 0.8344 - acc: 0.6874 - val_loss: 0.6957 - val_acc: 0.8280\n",
      "Epoch 10/150\n",
      "435/435 [==============================] - 0s - loss: 0.7602 - acc: 0.7379 - val_loss: 0.6311 - val_acc: 0.8280\n",
      "Epoch 11/150\n",
      "435/435 [==============================] - 0s - loss: 0.7085 - acc: 0.7333 - val_loss: 0.5705 - val_acc: 0.8602\n",
      "Epoch 12/150\n",
      "435/435 [==============================] - 0s - loss: 0.6525 - acc: 0.7609 - val_loss: 0.5289 - val_acc: 0.8495\n",
      "Epoch 13/150\n",
      "435/435 [==============================] - 0s - loss: 0.6146 - acc: 0.8253 - val_loss: 0.4844 - val_acc: 0.8817\n",
      "Epoch 14/150\n",
      "435/435 [==============================] - 0s - loss: 0.6135 - acc: 0.7931 - val_loss: 0.4438 - val_acc: 0.8925\n",
      "Epoch 15/150\n",
      "435/435 [==============================] - 0s - loss: 0.5653 - acc: 0.8023 - val_loss: 0.4228 - val_acc: 0.9032\n",
      "Epoch 16/150\n",
      "435/435 [==============================] - 0s - loss: 0.5475 - acc: 0.8115 - val_loss: 0.3985 - val_acc: 0.8925\n",
      "Epoch 17/150\n",
      "435/435 [==============================] - 0s - loss: 0.5122 - acc: 0.8207 - val_loss: 0.3829 - val_acc: 0.9140\n",
      "Epoch 18/150\n",
      "435/435 [==============================] - 0s - loss: 0.5321 - acc: 0.8092 - val_loss: 0.3717 - val_acc: 0.9140\n",
      "Epoch 19/150\n",
      "435/435 [==============================] - 0s - loss: 0.5216 - acc: 0.8322 - val_loss: 0.3639 - val_acc: 0.9032\n",
      "Epoch 20/150\n",
      "435/435 [==============================] - 0s - loss: 0.4518 - acc: 0.8575 - val_loss: 0.3554 - val_acc: 0.9032\n",
      "Epoch 21/150\n",
      "435/435 [==============================] - 0s - loss: 0.4436 - acc: 0.8483 - val_loss: 0.3381 - val_acc: 0.9247\n",
      "Epoch 22/150\n",
      "435/435 [==============================] - 0s - loss: 0.4524 - acc: 0.8368 - val_loss: 0.3313 - val_acc: 0.9032\n",
      "Epoch 23/150\n",
      "435/435 [==============================] - 0s - loss: 0.4455 - acc: 0.8575 - val_loss: 0.3167 - val_acc: 0.9032\n",
      "Epoch 24/150\n",
      "435/435 [==============================] - 0s - loss: 0.4354 - acc: 0.8414 - val_loss: 0.3075 - val_acc: 0.9140\n",
      "Epoch 25/150\n",
      "435/435 [==============================] - 0s - loss: 0.3814 - acc: 0.8828 - val_loss: 0.2998 - val_acc: 0.9247\n",
      "Epoch 26/150\n",
      "435/435 [==============================] - 0s - loss: 0.3766 - acc: 0.8713 - val_loss: 0.2903 - val_acc: 0.9140\n",
      "Epoch 27/150\n",
      "435/435 [==============================] - 0s - loss: 0.3969 - acc: 0.8644 - val_loss: 0.2856 - val_acc: 0.9140\n",
      "Epoch 28/150\n",
      "435/435 [==============================] - 0s - loss: 0.3910 - acc: 0.8690 - val_loss: 0.3014 - val_acc: 0.9247\n",
      "Epoch 29/150\n",
      "435/435 [==============================] - 0s - loss: 0.4002 - acc: 0.8690 - val_loss: 0.2912 - val_acc: 0.9247\n",
      "Epoch 30/150\n",
      "435/435 [==============================] - 0s - loss: 0.3871 - acc: 0.8575 - val_loss: 0.2818 - val_acc: 0.9140\n",
      "Epoch 31/150\n",
      "435/435 [==============================] - 0s - loss: 0.3678 - acc: 0.8713 - val_loss: 0.2729 - val_acc: 0.9247\n",
      "Epoch 32/150\n",
      "435/435 [==============================] - 0s - loss: 0.3794 - acc: 0.8805 - val_loss: 0.2770 - val_acc: 0.9032\n",
      "Epoch 33/150\n",
      "435/435 [==============================] - 0s - loss: 0.3669 - acc: 0.8437 - val_loss: 0.2864 - val_acc: 0.9032\n",
      "Epoch 34/150\n",
      "435/435 [==============================] - 0s - loss: 0.3679 - acc: 0.8828 - val_loss: 0.2729 - val_acc: 0.9247\n",
      "Epoch 35/150\n",
      "435/435 [==============================] - 0s - loss: 0.3176 - acc: 0.8874 - val_loss: 0.2670 - val_acc: 0.9247\n",
      "Epoch 36/150\n",
      "435/435 [==============================] - 0s - loss: 0.3365 - acc: 0.8897 - val_loss: 0.2557 - val_acc: 0.9140\n",
      "Epoch 37/150\n",
      "435/435 [==============================] - 0s - loss: 0.3180 - acc: 0.8782 - val_loss: 0.2581 - val_acc: 0.9140\n",
      "Epoch 38/150\n",
      "435/435 [==============================] - 0s - loss: 0.3136 - acc: 0.8943 - val_loss: 0.2588 - val_acc: 0.9140\n",
      "Epoch 39/150\n",
      "435/435 [==============================] - 0s - loss: 0.3356 - acc: 0.8874 - val_loss: 0.2622 - val_acc: 0.9140\n",
      "Epoch 40/150\n",
      "435/435 [==============================] - 0s - loss: 0.3524 - acc: 0.8805 - val_loss: 0.2650 - val_acc: 0.9140\n",
      "Epoch 41/150\n",
      "435/435 [==============================] - 0s - loss: 0.3531 - acc: 0.8667 - val_loss: 0.2582 - val_acc: 0.9140\n",
      "Epoch 42/150\n",
      "435/435 [==============================] - 0s - loss: 0.3399 - acc: 0.8828 - val_loss: 0.2616 - val_acc: 0.9140\n",
      "Epoch 43/150\n",
      "435/435 [==============================] - 0s - loss: 0.3419 - acc: 0.8943 - val_loss: 0.2654 - val_acc: 0.9140\n",
      "Epoch 44/150\n",
      "435/435 [==============================] - 0s - loss: 0.2803 - acc: 0.9080 - val_loss: 0.2657 - val_acc: 0.9247\n",
      "Epoch 45/150\n",
      "435/435 [==============================] - 0s - loss: 0.3112 - acc: 0.8851 - val_loss: 0.2540 - val_acc: 0.9140\n",
      "Epoch 46/150\n",
      "435/435 [==============================] - 0s - loss: 0.3244 - acc: 0.8920 - val_loss: 0.2373 - val_acc: 0.9140\n",
      "Epoch 47/150\n",
      "435/435 [==============================] - 0s - loss: 0.3283 - acc: 0.8805 - val_loss: 0.2365 - val_acc: 0.9140\n",
      "Epoch 48/150\n",
      "435/435 [==============================] - 0s - loss: 0.2998 - acc: 0.8897 - val_loss: 0.2459 - val_acc: 0.9140\n",
      "Epoch 49/150\n",
      "435/435 [==============================] - 0s - loss: 0.2919 - acc: 0.9057 - val_loss: 0.2385 - val_acc: 0.9247\n",
      "Epoch 50/150\n",
      "435/435 [==============================] - 0s - loss: 0.3232 - acc: 0.8943 - val_loss: 0.2326 - val_acc: 0.9247\n",
      "Epoch 51/150\n",
      "435/435 [==============================] - 0s - loss: 0.3007 - acc: 0.8897 - val_loss: 0.2271 - val_acc: 0.9247\n",
      "Epoch 52/150\n",
      "435/435 [==============================] - 0s - loss: 0.2751 - acc: 0.9080 - val_loss: 0.2336 - val_acc: 0.9247\n",
      "Epoch 53/150\n",
      "435/435 [==============================] - 0s - loss: 0.2589 - acc: 0.9126 - val_loss: 0.2488 - val_acc: 0.9140\n",
      "Epoch 54/150\n",
      "435/435 [==============================] - 0s - loss: 0.2830 - acc: 0.8897 - val_loss: 0.2528 - val_acc: 0.9140\n",
      "Epoch 55/150\n",
      "435/435 [==============================] - 0s - loss: 0.2850 - acc: 0.9080 - val_loss: 0.2352 - val_acc: 0.9140\n",
      "Epoch 56/150\n",
      "435/435 [==============================] - 0s - loss: 0.2901 - acc: 0.9011 - val_loss: 0.2350 - val_acc: 0.9140\n",
      "Epoch 57/150\n",
      "435/435 [==============================] - 0s - loss: 0.2768 - acc: 0.8989 - val_loss: 0.2475 - val_acc: 0.9140\n",
      "Epoch 58/150\n",
      "435/435 [==============================] - 0s - loss: 0.2579 - acc: 0.9080 - val_loss: 0.2463 - val_acc: 0.9140\n",
      "Epoch 59/150\n",
      "435/435 [==============================] - 0s - loss: 0.2687 - acc: 0.8874 - val_loss: 0.2284 - val_acc: 0.9032\n",
      "Epoch 60/150\n",
      "435/435 [==============================] - 0s - loss: 0.2169 - acc: 0.9241 - val_loss: 0.2226 - val_acc: 0.9032\n",
      "Epoch 61/150\n",
      "435/435 [==============================] - 0s - loss: 0.2809 - acc: 0.8989 - val_loss: 0.2290 - val_acc: 0.9032\n",
      "Epoch 62/150\n",
      "435/435 [==============================] - 0s - loss: 0.2259 - acc: 0.9149 - val_loss: 0.2383 - val_acc: 0.9032\n",
      "Epoch 63/150\n",
      "435/435 [==============================] - 0s - loss: 0.2761 - acc: 0.8851 - val_loss: 0.2282 - val_acc: 0.9032\n",
      "Epoch 64/150\n",
      "435/435 [==============================] - 0s - loss: 0.2814 - acc: 0.8851 - val_loss: 0.2259 - val_acc: 0.9140\n",
      "Epoch 65/150\n",
      "435/435 [==============================] - 0s - loss: 0.2331 - acc: 0.9149 - val_loss: 0.2280 - val_acc: 0.9140\n",
      "Epoch 66/150\n",
      "435/435 [==============================] - 0s - loss: 0.2639 - acc: 0.9103 - val_loss: 0.2308 - val_acc: 0.9247\n",
      "Epoch 67/150\n",
      "435/435 [==============================] - 0s - loss: 0.2582 - acc: 0.9149 - val_loss: 0.2272 - val_acc: 0.9032\n",
      "Epoch 68/150\n",
      "435/435 [==============================] - 0s - loss: 0.2214 - acc: 0.9172 - val_loss: 0.2271 - val_acc: 0.9032\n",
      "Epoch 69/150\n",
      "435/435 [==============================] - 0s - loss: 0.2312 - acc: 0.9264 - val_loss: 0.2263 - val_acc: 0.9032\n",
      "Epoch 70/150\n",
      "435/435 [==============================] - 0s - loss: 0.2532 - acc: 0.9149 - val_loss: 0.2205 - val_acc: 0.9140\n",
      "Epoch 71/150\n",
      "435/435 [==============================] - 0s - loss: 0.2617 - acc: 0.8943 - val_loss: 0.2254 - val_acc: 0.9247\n",
      "Epoch 72/150\n",
      "435/435 [==============================] - 0s - loss: 0.2624 - acc: 0.9080 - val_loss: 0.2458 - val_acc: 0.9140\n",
      "Epoch 73/150\n",
      "435/435 [==============================] - 0s - loss: 0.2751 - acc: 0.9011 - val_loss: 0.2413 - val_acc: 0.9140\n",
      "Epoch 74/150\n",
      "435/435 [==============================] - 0s - loss: 0.2625 - acc: 0.9057 - val_loss: 0.2427 - val_acc: 0.9140\n",
      "Epoch 75/150\n",
      "435/435 [==============================] - 0s - loss: 0.2240 - acc: 0.9126 - val_loss: 0.2396 - val_acc: 0.9140\n",
      "Epoch 76/150\n",
      "435/435 [==============================] - 0s - loss: 0.2516 - acc: 0.9126 - val_loss: 0.2411 - val_acc: 0.9032\n",
      "Epoch 77/150\n",
      "435/435 [==============================] - 0s - loss: 0.2341 - acc: 0.9172 - val_loss: 0.2337 - val_acc: 0.9032\n",
      "Epoch 78/150\n",
      "435/435 [==============================] - 0s - loss: 0.2219 - acc: 0.9241 - val_loss: 0.2446 - val_acc: 0.9032\n",
      "Epoch 79/150\n",
      "435/435 [==============================] - 0s - loss: 0.2376 - acc: 0.9080 - val_loss: 0.2470 - val_acc: 0.9140\n",
      "Epoch 80/150\n",
      "435/435 [==============================] - 0s - loss: 0.2711 - acc: 0.9034 - val_loss: 0.2501 - val_acc: 0.9140\n",
      "Epoch 81/150\n",
      "435/435 [==============================] - 0s - loss: 0.2839 - acc: 0.8874 - val_loss: 0.2253 - val_acc: 0.9140\n",
      "Epoch 82/150\n",
      "435/435 [==============================] - 0s - loss: 0.1964 - acc: 0.9195 - val_loss: 0.2233 - val_acc: 0.9140\n",
      "Epoch 83/150\n",
      "435/435 [==============================] - 0s - loss: 0.1996 - acc: 0.9218 - val_loss: 0.2169 - val_acc: 0.9140\n",
      "Epoch 84/150\n",
      "435/435 [==============================] - 0s - loss: 0.2536 - acc: 0.9218 - val_loss: 0.2318 - val_acc: 0.9140\n",
      "Epoch 85/150\n",
      "435/435 [==============================] - 0s - loss: 0.2448 - acc: 0.9172 - val_loss: 0.2450 - val_acc: 0.9140\n",
      "Epoch 86/150\n",
      "435/435 [==============================] - 0s - loss: 0.2209 - acc: 0.9149 - val_loss: 0.2442 - val_acc: 0.9247\n",
      "Epoch 87/150\n",
      "435/435 [==============================] - 0s - loss: 0.2310 - acc: 0.9126 - val_loss: 0.2534 - val_acc: 0.9032\n",
      "Epoch 88/150\n",
      "435/435 [==============================] - 0s - loss: 0.2170 - acc: 0.9241 - val_loss: 0.2606 - val_acc: 0.9032\n",
      "Epoch 89/150\n",
      "435/435 [==============================] - 0s - loss: 0.2284 - acc: 0.9241 - val_loss: 0.2584 - val_acc: 0.9032\n",
      "Epoch 90/150\n",
      "435/435 [==============================] - 0s - loss: 0.2410 - acc: 0.9080 - val_loss: 0.2452 - val_acc: 0.9032\n",
      "Epoch 91/150\n",
      "435/435 [==============================] - 0s - loss: 0.2212 - acc: 0.9241 - val_loss: 0.2501 - val_acc: 0.9032\n",
      "Epoch 92/150\n",
      "435/435 [==============================] - 0s - loss: 0.2106 - acc: 0.9310 - val_loss: 0.2555 - val_acc: 0.9032\n",
      "Epoch 93/150\n",
      "435/435 [==============================] - 0s - loss: 0.1847 - acc: 0.9402 - val_loss: 0.2593 - val_acc: 0.9032\n",
      "Epoch 94/150\n",
      "435/435 [==============================] - 0s - loss: 0.2414 - acc: 0.9034 - val_loss: 0.2712 - val_acc: 0.9032\n",
      "Epoch 95/150\n",
      "435/435 [==============================] - 0s - loss: 0.2172 - acc: 0.9172 - val_loss: 0.2713 - val_acc: 0.8925\n",
      "Epoch 96/150\n",
      "435/435 [==============================] - 0s - loss: 0.1912 - acc: 0.9333 - val_loss: 0.2532 - val_acc: 0.8925\n",
      "Epoch 97/150\n",
      "435/435 [==============================] - 0s - loss: 0.2146 - acc: 0.9126 - val_loss: 0.2563 - val_acc: 0.9032\n",
      "Epoch 98/150\n",
      "435/435 [==============================] - 0s - loss: 0.2299 - acc: 0.9057 - val_loss: 0.2629 - val_acc: 0.9032\n",
      "Epoch 99/150\n",
      "435/435 [==============================] - 0s - loss: 0.2156 - acc: 0.9126 - val_loss: 0.2703 - val_acc: 0.9032\n",
      "Epoch 100/150\n",
      "435/435 [==============================] - 0s - loss: 0.2017 - acc: 0.9356 - val_loss: 0.2594 - val_acc: 0.9032\n",
      "Epoch 101/150\n",
      "435/435 [==============================] - 0s - loss: 0.2073 - acc: 0.9172 - val_loss: 0.2460 - val_acc: 0.9032\n",
      "Epoch 102/150\n",
      "435/435 [==============================] - 0s - loss: 0.2484 - acc: 0.9149 - val_loss: 0.2428 - val_acc: 0.9032\n",
      "Epoch 103/150\n",
      "435/435 [==============================] - 0s - loss: 0.2448 - acc: 0.9103 - val_loss: 0.2563 - val_acc: 0.8925\n",
      "Epoch 104/150\n",
      "435/435 [==============================] - 0s - loss: 0.2411 - acc: 0.9103 - val_loss: 0.2556 - val_acc: 0.8925\n",
      "Epoch 105/150\n",
      "435/435 [==============================] - 0s - loss: 0.2060 - acc: 0.9287 - val_loss: 0.2493 - val_acc: 0.9140\n",
      "Epoch 106/150\n",
      "435/435 [==============================] - 0s - loss: 0.2139 - acc: 0.9126 - val_loss: 0.2361 - val_acc: 0.9032\n",
      "Epoch 107/150\n",
      "435/435 [==============================] - 0s - loss: 0.1953 - acc: 0.9379 - val_loss: 0.2352 - val_acc: 0.9032\n",
      "Epoch 108/150\n",
      "435/435 [==============================] - 0s - loss: 0.1989 - acc: 0.9287 - val_loss: 0.2286 - val_acc: 0.9140\n",
      "Epoch 109/150\n",
      "435/435 [==============================] - 0s - loss: 0.2026 - acc: 0.9356 - val_loss: 0.2280 - val_acc: 0.9140\n",
      "Epoch 110/150\n",
      "435/435 [==============================] - 0s - loss: 0.1612 - acc: 0.9333 - val_loss: 0.2450 - val_acc: 0.9140\n",
      "Epoch 111/150\n",
      "435/435 [==============================] - 0s - loss: 0.1810 - acc: 0.9195 - val_loss: 0.2551 - val_acc: 0.9032\n",
      "Epoch 112/150\n",
      "435/435 [==============================] - 0s - loss: 0.1994 - acc: 0.9448 - val_loss: 0.2437 - val_acc: 0.9032\n",
      "Epoch 113/150\n",
      "435/435 [==============================] - 0s - loss: 0.1686 - acc: 0.9402 - val_loss: 0.2456 - val_acc: 0.9032\n",
      "Epoch 114/150\n",
      "435/435 [==============================] - 0s - loss: 0.2155 - acc: 0.9264 - val_loss: 0.2485 - val_acc: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fceec391750>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, nb_epoch=150, shuffle=True, callbacks=[earlyStopping], \n",
    "          validation_data = (x_valid, y_valid), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "50/94 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21436019527151229, 0.92553192630727243]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/94 [=========>....................] - ETA: 0s[0 1 1 0 1 3 2 2 0 3 1 0 2 2 3 0 0 3 0 1 1 3 3 1 0 2 2 3 2 2 1 1 0 0 0 2 1\n",
      " 1 3 2 0 0 1 1 3 2 1 0 3 0 0 2 0 3 3 3 2 1 0 0 2 3 2 1 0 0 1 0 0 1 0 0 3 0\n",
      " 0 1 2 2 2 3 2 0 0 3 2 1 0 2 3 1 2 3 2 2]\n",
      "32/94 [=========>....................] - ETA: 0s                precision    recall  f1-score   support\n",
      "\n",
      "class 0(0back)       0.90      0.96      0.93        28\n",
      "class 1(1back)       0.95      0.91      0.93        22\n",
      "class 2(2back)       0.92      0.92      0.92        24\n",
      " class3(3back)       0.95      0.90      0.92        20\n",
      "\n",
      "   avg / total       0.93      0.93      0.93        94\n",
      "\n",
      "[[27  1  0  0]\n",
      " [ 1 20  0  1]\n",
      " [ 2  0 22  0]\n",
      " [ 0  0  2 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(0back)', 'class 1(1back)', 'class 2(2back)', 'class3(3back)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
