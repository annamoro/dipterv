{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Convolution1D, MaxPooling1D\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(622, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"nback/result1.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 7)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    data = np.delete(data, 1, 1) \n",
    "    \n",
    "#data = np.delete(data, 1, 1) \n",
    "data = data[:,0:7]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3back', 1537.7, 796.38, 36.961999999999996, 4.696727272727268,\n",
       "       8.947000000000001, 16.387999999999998], dtype=object)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero: 206  one:  130  two:  139  three:  147\n"
     ]
    }
   ],
   "source": [
    "zero = 0\n",
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == '0back'):\n",
    "        zero = zero + 1\n",
    "    if (data[i, 0] == '1back'):\n",
    "        one = one + 1\n",
    "    if (data[i, 0] == '2back'):\n",
    "        two = two + 1\n",
    "    if (data[i, 0] == '3back'):\n",
    "        three = three + 1\n",
    "\n",
    "print('zero:', zero, ' one: ', one, ' two: ', two, ' three: ', three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"0back\",\"1back\",\"2back\",\"3back\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,7):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "back0 = np.zeros((zero,6))\n",
    "back1 = np.zeros((one,6))\n",
    "back2 = np.zeros((two,6))\n",
    "back3 = np.zeros((three,6))\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == '0back'):\n",
    "        back0[j] = data[i, 1:]\n",
    "        j = j+1\n",
    "    if (data[i, 0] == '1back'):\n",
    "        back1[k] = data[i, 1:]\n",
    "        k = k+1\n",
    "    if (data[i, 0] == '2back'):\n",
    "        back2[l] = data[i, 1:]\n",
    "        l = l+1\n",
    "    if (data[i, 0] == '3back'):\n",
    "        back3[m] = data[i, 1:]\n",
    "        m = m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_data = data[:, 0]\n",
    "for i in range(len(data)):\n",
    "    y_data[i] = level2int[y_data[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data for convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "track = 20\n",
    "null = np.array([0,0,0,0,0,0])\n",
    "\n",
    "for i in range(track-1):\n",
    "        back0 = np.vstack([back0, null])\n",
    "        back1 = np.vstack([back1, null])\n",
    "        back2 = np.vstack([back2, null])\n",
    "        back3 = np.vstack([back3, null])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = np.zeros((data.shape[0],6,track))         # final input data for the network\n",
    "y_one_hot = np.zeros((data.shape[0],1,4))          # to store one-hot data groupped\n",
    "\n",
    "for i in range(len(one_hot)):\n",
    "    y_one_hot[i]=one_hot[i]\n",
    "\n",
    "for i in range(len(back0)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back0[i+j]\n",
    "        \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1, len(back0)-track+1 + len(back1)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back1[index+j]\n",
    "    index = index+1\n",
    "    \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1 + len(back1)-track+1, len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back2[index+j]\n",
    "    index = index+1\n",
    "    \n",
    "index = 0\n",
    "for i in range(len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1, \n",
    "                   len(back0)-track+1 + len(back1)-track+1 + len(back2)-track+1 + len(back3)-track+1):\n",
    "    for j in range(track-1):\n",
    "        x_data[i, :, j] = back3[index+j]\n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 6, 20) (435, 1, 4) (93, 6, 20) (93, 1, 4) (94, 6, 20) (94, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Filter must not be larger than the input: Filter: (2, 1) Input: (1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-223-c9e7846efa68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Second max-pooling layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    322\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Exception('All layers in a Sequential model '\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;31m# This will call layer.build() if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0moutput_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# TODO: try to auto-infer shape if exception is raised by get_output_shape_for.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                         \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborder_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                                         dim_ordering='tf')\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# remove dummy last dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/keras/layers/pooling.pyc\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, border_mode, dim_ordering)\u001b[0m\n\u001b[1;32m     75\u001b[0m                           border_mode, dim_ordering):\n\u001b[1;32m     76\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m---> 77\u001b[0;31m                           border_mode, dim_ordering, pool_mode='max')\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, border_mode, dim_ordering, pool_mode)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m    663\u001b[0m                                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m                                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc\u001b[0m in \u001b[0;36m_max_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   1121\u001b[0m   result = _op_def_lib.apply_op(\"MaxPool\", input=input, ksize=ksize,\n\u001b[1;32m   1122\u001b[0m                                 \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                                 data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   1124\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    701\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    702\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    704\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2310\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1703\u001b[0m                          % op.type)\n\u001b[0;32m-> 1704\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mmax_pool_shape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    503\u001b[0m     out_rows, out_cols = get2d_conv_output_size(in_rows, in_cols, ksize_r,\n\u001b[1;32m    504\u001b[0m                                                 \u001b[0mksize_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                                                 padding)\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mget2d_conv_output_size\u001b[0;34m(input_height, input_width, filter_height, filter_width, row_stride, col_stride, padding_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m   return get_conv_output_size((input_height, input_width),\n\u001b[1;32m    183\u001b[0m                               \u001b[0;34m(\u001b[0m\u001b[0mfilter_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                               (row_stride, col_stride), padding_type)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/amoro/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mget_conv_output_size\u001b[0;34m(input_size, filter_size, strides, padding_type)\u001b[0m\n\u001b[1;32m    147\u001b[0m          zip(filter_size, input_size)):\n\u001b[1;32m    148\u001b[0m     raise ValueError(\"Filter must not be larger than the input: \"\n\u001b[0;32m--> 149\u001b[0;31m                      \"Filter: %r Input: %r\" % (filter_size, input_size))\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpadding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"VALID\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Filter must not be larger than the input: Filter: (2, 1) Input: (1, 1)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution1D(input_shape=(x_train[0].shape[-2],x_train[0].shape[-1]),\n",
    "                        nb_filter=30,\n",
    "                        filter_length=2,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu')) \n",
    "# First max-pooling layer\n",
    "model.add(MaxPooling1D(pool_length=2,stride=1))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Convolution1D(nb_filter=30,\n",
    "                        filter_length=2,\n",
    "                        border_mode='same',\n",
    "                        subsample_length=2,\n",
    "                        init='glorot_normal',\n",
    "                        activation='relu'))\n",
    "\n",
    "# Second max-pooling layer\n",
    "model.add(MaxPooling1D(pool_length=2, stride=1)) \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Final fully-connected layer\n",
    "model.add(Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 435 samples, validate on 93 samples\n",
      "Epoch 1/300\n",
      "435/435 [==============================] - 0s - loss: 1.2869 - acc: 0.4000 - val_loss: 1.1986 - val_acc: 0.4301\n",
      "Epoch 2/300\n",
      "435/435 [==============================] - 0s - loss: 1.0749 - acc: 0.5494 - val_loss: 0.9842 - val_acc: 0.5591\n",
      "Epoch 3/300\n",
      "435/435 [==============================] - 0s - loss: 0.9629 - acc: 0.6000 - val_loss: 1.0536 - val_acc: 0.5269\n",
      "Epoch 4/300\n",
      "435/435 [==============================] - 0s - loss: 0.9264 - acc: 0.6046 - val_loss: 0.9848 - val_acc: 0.5699\n",
      "Epoch 5/300\n",
      "435/435 [==============================] - 0s - loss: 0.8987 - acc: 0.6299 - val_loss: 0.9642 - val_acc: 0.6774\n",
      "Epoch 6/300\n",
      "435/435 [==============================] - 0s - loss: 0.8728 - acc: 0.6322 - val_loss: 0.9392 - val_acc: 0.6237\n",
      "Epoch 7/300\n",
      "435/435 [==============================] - 0s - loss: 0.8385 - acc: 0.6483 - val_loss: 0.9762 - val_acc: 0.6774\n",
      "Epoch 8/300\n",
      "435/435 [==============================] - 0s - loss: 0.8444 - acc: 0.6460 - val_loss: 1.0033 - val_acc: 0.5806\n",
      "Epoch 9/300\n",
      "435/435 [==============================] - 0s - loss: 0.8487 - acc: 0.6483 - val_loss: 0.9300 - val_acc: 0.6559\n",
      "Epoch 10/300\n",
      "435/435 [==============================] - 0s - loss: 0.7789 - acc: 0.6713 - val_loss: 0.9435 - val_acc: 0.6667\n",
      "Epoch 11/300\n",
      "435/435 [==============================] - 0s - loss: 0.7508 - acc: 0.6897 - val_loss: 1.1144 - val_acc: 0.6344\n",
      "Epoch 12/300\n",
      "435/435 [==============================] - 0s - loss: 0.8706 - acc: 0.6575 - val_loss: 0.9316 - val_acc: 0.6882\n",
      "Epoch 13/300\n",
      "435/435 [==============================] - 0s - loss: 0.7331 - acc: 0.7241 - val_loss: 1.0057 - val_acc: 0.6344\n",
      "Epoch 14/300\n",
      "435/435 [==============================] - 0s - loss: 0.7727 - acc: 0.6805 - val_loss: 0.9897 - val_acc: 0.6774\n",
      "Epoch 15/300\n",
      "435/435 [==============================] - 0s - loss: 0.7137 - acc: 0.7195 - val_loss: 1.0336 - val_acc: 0.5914\n",
      "Epoch 16/300\n",
      "435/435 [==============================] - 0s - loss: 0.7365 - acc: 0.6966 - val_loss: 0.9750 - val_acc: 0.6667\n",
      "Epoch 17/300\n",
      "435/435 [==============================] - 0s - loss: 0.6634 - acc: 0.7057 - val_loss: 1.0248 - val_acc: 0.6774\n",
      "Epoch 18/300\n",
      "435/435 [==============================] - 0s - loss: 0.6875 - acc: 0.7103 - val_loss: 0.9750 - val_acc: 0.6882\n",
      "Epoch 19/300\n",
      "435/435 [==============================] - 0s - loss: 0.6668 - acc: 0.7425 - val_loss: 0.9752 - val_acc: 0.7097\n",
      "Epoch 20/300\n",
      "435/435 [==============================] - 0s - loss: 0.6775 - acc: 0.7310 - val_loss: 0.9236 - val_acc: 0.6989\n",
      "Epoch 21/300\n",
      "435/435 [==============================] - 0s - loss: 0.6846 - acc: 0.7195 - val_loss: 0.9318 - val_acc: 0.6452\n",
      "Epoch 22/300\n",
      "435/435 [==============================] - 0s - loss: 0.6641 - acc: 0.7356 - val_loss: 1.0103 - val_acc: 0.6989\n",
      "Epoch 23/300\n",
      "435/435 [==============================] - 0s - loss: 0.6317 - acc: 0.7310 - val_loss: 0.8874 - val_acc: 0.7419\n",
      "Epoch 24/300\n",
      "435/435 [==============================] - 0s - loss: 0.6467 - acc: 0.7448 - val_loss: 0.9599 - val_acc: 0.6774\n",
      "Epoch 25/300\n",
      "435/435 [==============================] - 0s - loss: 0.5760 - acc: 0.7655 - val_loss: 0.8826 - val_acc: 0.7204\n",
      "Epoch 26/300\n",
      "435/435 [==============================] - 0s - loss: 0.5935 - acc: 0.7379 - val_loss: 0.9495 - val_acc: 0.7097\n",
      "Epoch 27/300\n",
      "435/435 [==============================] - 0s - loss: 0.6073 - acc: 0.7563 - val_loss: 0.9364 - val_acc: 0.7312\n",
      "Epoch 28/300\n",
      "435/435 [==============================] - 0s - loss: 0.5890 - acc: 0.7448 - val_loss: 0.9109 - val_acc: 0.7097\n",
      "Epoch 29/300\n",
      "435/435 [==============================] - 0s - loss: 0.6297 - acc: 0.7563 - val_loss: 1.0796 - val_acc: 0.6559\n",
      "Epoch 30/300\n",
      "435/435 [==============================] - 0s - loss: 0.5997 - acc: 0.7379 - val_loss: 1.0261 - val_acc: 0.6989\n",
      "Epoch 31/300\n",
      "435/435 [==============================] - 0s - loss: 0.5830 - acc: 0.7517 - val_loss: 1.1938 - val_acc: 0.6989\n",
      "Epoch 32/300\n",
      "435/435 [==============================] - 0s - loss: 0.6495 - acc: 0.7448 - val_loss: 0.9752 - val_acc: 0.7204\n",
      "Epoch 33/300\n",
      "435/435 [==============================] - 0s - loss: 0.6000 - acc: 0.7379 - val_loss: 0.9482 - val_acc: 0.7527\n",
      "Epoch 34/300\n",
      "435/435 [==============================] - 0s - loss: 0.5837 - acc: 0.7425 - val_loss: 0.9312 - val_acc: 0.7312\n",
      "Epoch 35/300\n",
      "435/435 [==============================] - 0s - loss: 0.5858 - acc: 0.7517 - val_loss: 1.0377 - val_acc: 0.7312\n",
      "Epoch 36/300\n",
      "435/435 [==============================] - 0s - loss: 0.5458 - acc: 0.7448 - val_loss: 1.0468 - val_acc: 0.7312\n",
      "Epoch 37/300\n",
      "435/435 [==============================] - 0s - loss: 0.5814 - acc: 0.7655 - val_loss: 1.0134 - val_acc: 0.7527\n",
      "Epoch 38/300\n",
      "435/435 [==============================] - 0s - loss: 0.5644 - acc: 0.7701 - val_loss: 0.9811 - val_acc: 0.7419\n",
      "Epoch 39/300\n",
      "435/435 [==============================] - 0s - loss: 0.6065 - acc: 0.7563 - val_loss: 0.9764 - val_acc: 0.7312\n",
      "Epoch 40/300\n",
      "435/435 [==============================] - 0s - loss: 0.5304 - acc: 0.7770 - val_loss: 1.0148 - val_acc: 0.7312\n",
      "Epoch 41/300\n",
      "435/435 [==============================] - 0s - loss: 0.5168 - acc: 0.7747 - val_loss: 1.0009 - val_acc: 0.7849\n",
      "Epoch 42/300\n",
      "435/435 [==============================] - 0s - loss: 0.5401 - acc: 0.7494 - val_loss: 0.9783 - val_acc: 0.7634\n",
      "Epoch 43/300\n",
      "435/435 [==============================] - 0s - loss: 0.5574 - acc: 0.7908 - val_loss: 0.9306 - val_acc: 0.7742\n",
      "Epoch 44/300\n",
      "435/435 [==============================] - 0s - loss: 0.6031 - acc: 0.7425 - val_loss: 1.0594 - val_acc: 0.6989\n",
      "Epoch 45/300\n",
      "435/435 [==============================] - 0s - loss: 0.5931 - acc: 0.7379 - val_loss: 0.9412 - val_acc: 0.7849\n",
      "Epoch 46/300\n",
      "435/435 [==============================] - 0s - loss: 0.5552 - acc: 0.7793 - val_loss: 1.0233 - val_acc: 0.7527\n",
      "Epoch 47/300\n",
      "435/435 [==============================] - 0s - loss: 0.5489 - acc: 0.7747 - val_loss: 1.0206 - val_acc: 0.7312\n",
      "Epoch 48/300\n",
      "435/435 [==============================] - 0s - loss: 0.5151 - acc: 0.7724 - val_loss: 0.9883 - val_acc: 0.7097\n",
      "Epoch 49/300\n",
      "435/435 [==============================] - 0s - loss: 0.5282 - acc: 0.7770 - val_loss: 1.0255 - val_acc: 0.7634\n",
      "Epoch 50/300\n",
      "435/435 [==============================] - 0s - loss: 0.5546 - acc: 0.7839 - val_loss: 1.0796 - val_acc: 0.7312\n",
      "Epoch 51/300\n",
      "435/435 [==============================] - 0s - loss: 0.5335 - acc: 0.7931 - val_loss: 1.0105 - val_acc: 0.7312\n",
      "Epoch 52/300\n",
      "435/435 [==============================] - 0s - loss: 0.5014 - acc: 0.8023 - val_loss: 0.9945 - val_acc: 0.7419\n",
      "Epoch 53/300\n",
      "435/435 [==============================] - 0s - loss: 0.5172 - acc: 0.7931 - val_loss: 1.0723 - val_acc: 0.7527\n",
      "Epoch 54/300\n",
      "435/435 [==============================] - 0s - loss: 0.4533 - acc: 0.8115 - val_loss: 1.4543 - val_acc: 0.7527\n",
      "Epoch 55/300\n",
      "435/435 [==============================] - 0s - loss: 0.6324 - acc: 0.7724 - val_loss: 1.0262 - val_acc: 0.7634\n",
      "Epoch 56/300\n",
      "435/435 [==============================] - 0s - loss: 0.6421 - acc: 0.7793 - val_loss: 1.1149 - val_acc: 0.7419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc066ad850>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 300\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='nadam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "50/94 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.90714684699444059, 0.75531914386343446]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/94 [=========>....................] - ETA: 0s[0 0 2 2 3 2 0 3 1 1 0 0 0 3 2 1 1 0 3 0 2 2 0 0 1 0 0 3 1 3 0 1 0 2 0 0 0\n",
      " 2 1 0 2 0 0 0 3 0 2 0 2 2 0 1 3 0 3 0 3 3 0 2 2 0 2 2 2 3 1 3 0 2 0 3 0 2\n",
      " 2 0 1 2 3 3 2 2 2 0 0 2 1 2 1 0 2 0 0 3]\n",
      "32/94 [=========>....................] - ETA: 0s                precision    recall  f1-score   support\n",
      "\n",
      "class 0(0back)       0.70      0.87      0.78        30\n",
      "class 1(1back)       0.92      0.48      0.63        25\n",
      "class 2(2back)       0.78      1.00      0.88        21\n",
      " class3(3back)       0.71      0.67      0.69        18\n",
      "\n",
      "   avg / total       0.78      0.76      0.74        94\n",
      "\n",
      "[[26  1  0  3]\n",
      " [ 9 12  2  2]\n",
      " [ 0  0 21  0]\n",
      " [ 2  0  4 12]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(0back)', 'class 1(1back)', 'class 2(2back)', 'class3(3back)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
