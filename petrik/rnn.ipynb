{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import LSTM\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(286, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"result1.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "touch_only = 'false'\n",
    "touch_heart = 'false'\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete irrelevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.delete(data, 13, 1)    # TouchNumber\n",
    "data = np.delete(data, 12, 1)    # T/S\n",
    "data = np.delete(data, 11, 1)    # TouchTimestamp\n",
    "data = np.delete(data, 4, 1)     # RRInterval\n",
    "data = np.delete(data, 3, 1)     # hpvPower\n",
    "data = np.delete(data, 2, 1)     # Heartrate\n",
    "data = np.delete(data, 1, 1)     # Timestamp\n",
    "data.shape\n",
    "\n",
    "if(touch_only == 'true'):\n",
    "    data = np.delete(data, 7, 1)     # SDNN\n",
    "    data = np.delete(data, 3, 1)     # Burg\n",
    "    data = np.delete(data, 2, 1)     # ReactionTime\n",
    "\n",
    "if(touch_heart == 'true'):\n",
    "    data = np.delete(data, 7, 1)     # ReactionTime\n",
    "    \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " one:  81  two:  105  three:  100\n"
     ]
    }
   ],
   "source": [
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == 'NbackSym1'):\n",
    "        one = one + 1\n",
    "    if (data[i, 0] == 'NbackSym2'):\n",
    "        two = two + 1\n",
    "    if (data[i, 0] == 'NbackSym3'):\n",
    "        three = three + 1\n",
    "\n",
    "print(' one: ', one, ' two: ', two, ' three: ', three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"NbackSym1\",\"NbackSym2\",\"NbackSym3\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,data.shape[1]):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "back1 = np.zeros((one,data.shape[1]-1))\n",
    "back2 = np.zeros((two,data.shape[1]-1))\n",
    "back3 = np.zeros((three,data.shape[1]-1))\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if (data[i, 0] == 'NbackSym1'):\n",
    "        back1[j] = data[i, 1:]\n",
    "        j = j+1\n",
    "    if (data[i, 0] == 'NbackSym2'):\n",
    "        back2[k] = data[i, 1:]\n",
    "        k = k+1\n",
    "    if (data[i, 0] == 'NbackSym3'):\n",
    "        back3[l] = data[i, 1:]\n",
    "        l = l+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_data = data[:, 0]\n",
    "for i in range(len(data)):\n",
    "    y_data[i] = level2int[y_data[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group data for recurrent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window = 10\n",
    "null = np.array([0,0,0,0,0,0,0])\n",
    "\n",
    "for i in range(window-1):\n",
    "        back1 = np.vstack([back1, null])\n",
    "        back2 = np.vstack([back2, null])\n",
    "        back3 = np.vstack([back3, null])\n",
    "        \n",
    "for i in range(window-1):\n",
    "        back1 = np.vstack([null, back1])\n",
    "        back2 = np.vstack([null, back2])\n",
    "        back3 = np.vstack([null, back3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_length = len(back1) + window - 1 + len(back2) + window - 1 + len(back3) + window - 1\n",
    "\n",
    "x_data = np.zeros((data_length,window, back1.shape[1]))         # final input data for the network\n",
    "y_one_hot = np.zeros((data_length,one_hot.shape[1]))             # to store one-hot data groupped\n",
    "\n",
    "\n",
    "for i in range(len(back1)-window):\n",
    "    for j in range(window):\n",
    "        x_data[i, j, :] = back1[i+j]\n",
    "    y_one_hot[i] = [0,0,1]\n",
    "    \n",
    "\n",
    "index = 0\n",
    "for i in range(len(back1)-window, len(back1)-window+ len(back2)-window):\n",
    "    for j in range(window):\n",
    "        x_data[i, j, :] = back2[index+j]\n",
    "    y_one_hot[i] = [0,1,0]\n",
    "    index = index+1\n",
    "\n",
    "index = 0\n",
    "for i in range(len(back1)-window+ len(back2)-window, len(back1)-window + len(back2)-window + len(back3)-window):\n",
    "    for j in range(window):\n",
    "        x_data[i, j, :] = back3[index+j]\n",
    "    y_one_hot[i] = [1,0,0]\n",
    "        \n",
    "    index = index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 7) (256, 3) (55, 10, 7) (55, 3) (56, 10, 7) (56, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')\n",
    "\n",
    "model.add(LSTM(64, input_dim=back1.shape[1], input_length=window, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "\n",
    "model.add(LSTM(40,return_sequences=False))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(output_dim=y_one_hot.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 55 samples\n",
      "Epoch 1/200\n",
      "256/256 [==============================] - 2s - loss: 0.8308 - acc: 0.5781 - val_loss: 0.6820 - val_acc: 0.8364\n",
      "Epoch 2/200\n",
      "256/256 [==============================] - 0s - loss: 0.6395 - acc: 0.6406 - val_loss: 0.4857 - val_acc: 0.8909\n",
      "Epoch 3/200\n",
      "256/256 [==============================] - 0s - loss: 0.5198 - acc: 0.6914 - val_loss: 0.3639 - val_acc: 0.8909\n",
      "Epoch 4/200\n",
      "256/256 [==============================] - 0s - loss: 0.4373 - acc: 0.7188 - val_loss: 0.2906 - val_acc: 0.8727\n",
      "Epoch 5/200\n",
      "256/256 [==============================] - 0s - loss: 0.3630 - acc: 0.7188 - val_loss: 0.2440 - val_acc: 0.8909\n",
      "Epoch 6/200\n",
      "256/256 [==============================] - 0s - loss: 0.3140 - acc: 0.7227 - val_loss: 0.2174 - val_acc: 0.8727\n",
      "Epoch 7/200\n",
      "256/256 [==============================] - 0s - loss: 0.2782 - acc: 0.7344 - val_loss: 0.2021 - val_acc: 0.8727\n",
      "Epoch 8/200\n",
      "256/256 [==============================] - 0s - loss: 0.2576 - acc: 0.7422 - val_loss: 0.2002 - val_acc: 0.8727\n",
      "Epoch 9/200\n",
      "256/256 [==============================] - 0s - loss: 0.2124 - acc: 0.7617 - val_loss: 0.1797 - val_acc: 0.8727\n",
      "Epoch 10/200\n",
      "256/256 [==============================] - 0s - loss: 0.2018 - acc: 0.7656 - val_loss: 0.1583 - val_acc: 0.8909\n",
      "Epoch 11/200\n",
      "256/256 [==============================] - 0s - loss: 0.1931 - acc: 0.7695 - val_loss: 0.1482 - val_acc: 0.8909\n",
      "Epoch 12/200\n",
      "256/256 [==============================] - 0s - loss: 0.1890 - acc: 0.7578 - val_loss: 0.1417 - val_acc: 0.8909\n",
      "Epoch 13/200\n",
      "256/256 [==============================] - 0s - loss: 0.1806 - acc: 0.7695 - val_loss: 0.1430 - val_acc: 0.8909\n",
      "Epoch 14/200\n",
      "256/256 [==============================] - 0s - loss: 0.1600 - acc: 0.7695 - val_loss: 0.1449 - val_acc: 0.8909\n",
      "Epoch 15/200\n",
      "256/256 [==============================] - 0s - loss: 0.1567 - acc: 0.7656 - val_loss: 0.1465 - val_acc: 0.8909\n",
      "Epoch 16/200\n",
      "256/256 [==============================] - 0s - loss: 0.1475 - acc: 0.7656 - val_loss: 0.1463 - val_acc: 0.8727\n",
      "Epoch 17/200\n",
      "256/256 [==============================] - 0s - loss: 0.1434 - acc: 0.7695 - val_loss: 0.1469 - val_acc: 0.8727\n",
      "Epoch 18/200\n",
      "256/256 [==============================] - 0s - loss: 0.1301 - acc: 0.7656 - val_loss: 0.1455 - val_acc: 0.8727\n",
      "Epoch 19/200\n",
      "256/256 [==============================] - 0s - loss: 0.1310 - acc: 0.7812 - val_loss: 0.1414 - val_acc: 0.8909\n",
      "Epoch 20/200\n",
      "256/256 [==============================] - 0s - loss: 0.1185 - acc: 0.7773 - val_loss: 0.1368 - val_acc: 0.8909\n",
      "Epoch 21/200\n",
      "256/256 [==============================] - 0s - loss: 0.1176 - acc: 0.7734 - val_loss: 0.1315 - val_acc: 0.8909\n",
      "Epoch 22/200\n",
      "256/256 [==============================] - 0s - loss: 0.1210 - acc: 0.7773 - val_loss: 0.1312 - val_acc: 0.8909\n",
      "Epoch 23/200\n",
      "256/256 [==============================] - 0s - loss: 0.1012 - acc: 0.7812 - val_loss: 0.1308 - val_acc: 0.8909\n",
      "Epoch 24/200\n",
      "256/256 [==============================] - 0s - loss: 0.1102 - acc: 0.7773 - val_loss: 0.1304 - val_acc: 0.8909\n",
      "Epoch 25/200\n",
      "256/256 [==============================] - 0s - loss: 0.1019 - acc: 0.7852 - val_loss: 0.1307 - val_acc: 0.8909\n",
      "Epoch 26/200\n",
      "256/256 [==============================] - 0s - loss: 0.0982 - acc: 0.7969 - val_loss: 0.1375 - val_acc: 0.8909\n",
      "Epoch 27/200\n",
      "256/256 [==============================] - 0s - loss: 0.1054 - acc: 0.7773 - val_loss: 0.1332 - val_acc: 0.8909\n",
      "Epoch 28/200\n",
      "256/256 [==============================] - 0s - loss: 0.0938 - acc: 0.7891 - val_loss: 0.1298 - val_acc: 0.8909\n",
      "Epoch 29/200\n",
      "256/256 [==============================] - 0s - loss: 0.0948 - acc: 0.7891 - val_loss: 0.1323 - val_acc: 0.8909\n",
      "Epoch 30/200\n",
      "256/256 [==============================] - 0s - loss: 0.0937 - acc: 0.7930 - val_loss: 0.1344 - val_acc: 0.8909\n",
      "Epoch 31/200\n",
      "256/256 [==============================] - 0s - loss: 0.0864 - acc: 0.8008 - val_loss: 0.1331 - val_acc: 0.8909\n",
      "Epoch 32/200\n",
      "256/256 [==============================] - 0s - loss: 0.0834 - acc: 0.8086 - val_loss: 0.1253 - val_acc: 0.8909\n",
      "Epoch 33/200\n",
      "256/256 [==============================] - 0s - loss: 0.0894 - acc: 0.7891 - val_loss: 0.1217 - val_acc: 0.8909\n",
      "Epoch 34/200\n",
      "256/256 [==============================] - 0s - loss: 0.0826 - acc: 0.7969 - val_loss: 0.1201 - val_acc: 0.8909\n",
      "Epoch 35/200\n",
      "256/256 [==============================] - 0s - loss: 0.0741 - acc: 0.7930 - val_loss: 0.1201 - val_acc: 0.8909\n",
      "Epoch 36/200\n",
      "256/256 [==============================] - 0s - loss: 0.0614 - acc: 0.8125 - val_loss: 0.1197 - val_acc: 0.8909\n",
      "Epoch 37/200\n",
      "256/256 [==============================] - 0s - loss: 0.0622 - acc: 0.8086 - val_loss: 0.1210 - val_acc: 0.8909\n",
      "Epoch 38/200\n",
      "256/256 [==============================] - 0s - loss: 0.0762 - acc: 0.8008 - val_loss: 0.1122 - val_acc: 0.8909\n",
      "Epoch 39/200\n",
      "256/256 [==============================] - 0s - loss: 0.0487 - acc: 0.8125 - val_loss: 0.1113 - val_acc: 0.8909\n",
      "Epoch 40/200\n",
      "256/256 [==============================] - 0s - loss: 0.0617 - acc: 0.8047 - val_loss: 0.1144 - val_acc: 0.8909\n",
      "Epoch 41/200\n",
      "256/256 [==============================] - 0s - loss: 0.0518 - acc: 0.8086 - val_loss: 0.1167 - val_acc: 0.8909\n",
      "Epoch 42/200\n",
      "256/256 [==============================] - 0s - loss: 0.0632 - acc: 0.8008 - val_loss: 0.1134 - val_acc: 0.8909\n",
      "Epoch 43/200\n",
      "256/256 [==============================] - 0s - loss: 0.0439 - acc: 0.8125 - val_loss: 0.1046 - val_acc: 0.8909\n",
      "Epoch 44/200\n",
      "256/256 [==============================] - 0s - loss: 0.0347 - acc: 0.8203 - val_loss: 0.1047 - val_acc: 0.8909\n",
      "Epoch 45/200\n",
      "256/256 [==============================] - 0s - loss: 0.0278 - acc: 0.8164 - val_loss: 0.1099 - val_acc: 0.8909\n",
      "Epoch 46/200\n",
      "256/256 [==============================] - 0s - loss: 0.0331 - acc: 0.8125 - val_loss: 0.1186 - val_acc: 0.8909\n",
      "Epoch 47/200\n",
      "256/256 [==============================] - 0s - loss: 0.0357 - acc: 0.8086 - val_loss: 0.1156 - val_acc: 0.8909\n",
      "Epoch 48/200\n",
      "256/256 [==============================] - 0s - loss: 0.0237 - acc: 0.8125 - val_loss: 0.1148 - val_acc: 0.8909\n",
      "Epoch 49/200\n",
      "256/256 [==============================] - 0s - loss: 0.0228 - acc: 0.8164 - val_loss: 0.1209 - val_acc: 0.8909\n",
      "Epoch 50/200\n",
      "256/256 [==============================] - 0s - loss: 0.0198 - acc: 0.8203 - val_loss: 0.1347 - val_acc: 0.8909\n",
      "Epoch 51/200\n",
      "256/256 [==============================] - 0s - loss: 0.0179 - acc: 0.8242 - val_loss: 0.1384 - val_acc: 0.8909\n",
      "Epoch 52/200\n",
      "256/256 [==============================] - 0s - loss: 0.0193 - acc: 0.8281 - val_loss: 0.1380 - val_acc: 0.8909\n",
      "Epoch 53/200\n",
      "256/256 [==============================] - 0s - loss: 0.0153 - acc: 0.8242 - val_loss: 0.1460 - val_acc: 0.8909\n",
      "Epoch 54/200\n",
      "256/256 [==============================] - 0s - loss: 0.0190 - acc: 0.8203 - val_loss: 0.1586 - val_acc: 0.8909\n",
      "Epoch 55/200\n",
      "256/256 [==============================] - 0s - loss: 0.0213 - acc: 0.8164 - val_loss: 0.1562 - val_acc: 0.8909\n",
      "Epoch 56/200\n",
      "256/256 [==============================] - 0s - loss: 0.0160 - acc: 0.8242 - val_loss: 0.1348 - val_acc: 0.8909\n",
      "Epoch 57/200\n",
      "256/256 [==============================] - 0s - loss: 0.0132 - acc: 0.8242 - val_loss: 0.1521 - val_acc: 0.8909\n",
      "Epoch 58/200\n",
      "256/256 [==============================] - 0s - loss: 0.0157 - acc: 0.8164 - val_loss: 0.1724 - val_acc: 0.8909\n",
      "Epoch 59/200\n",
      "256/256 [==============================] - 0s - loss: 0.0123 - acc: 0.8281 - val_loss: 0.1797 - val_acc: 0.8909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4500264cd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, nb_epoch=200, shuffle=True, callbacks=[earlyStopping], \n",
    "          validation_data = (x_valid, y_valid), batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12963881955615111, 0.82142856291362221]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s     \n",
      "[2 1 0 1 1 1 2 1 1 1 1 0 0 0 2 1 2 1 1 1 1 0 1 1 1 0 1 0 2 2 0 1 1 2 1 0 1\n",
      " 1 2 1 0 1 1 2 0 1 1 1 0 1 2 0 2 2 2 0]\n",
      "56/56 [==============================] - 0s     \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "class 0(0back)       0.86      0.60      0.71        20\n",
      "class 1(1back)       0.72      0.91      0.81        23\n",
      "class 2(2back)       1.00      1.00      1.00        13\n",
      "\n",
      "   avg / total       0.84      0.82      0.82        56\n",
      "\n",
      "[[12  8  0]\n",
      " [ 2 21  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(0back)', 'class 1(1back)', 'class 2(2back)', 'class3(3back)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
