{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(313, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"result9.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "touch_only = 'false'\n",
    "touch_heart = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 7)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.delete(data, 13, 1)    # TouchNumber\n",
    "data = np.delete(data, 12, 1)    # T/S\n",
    "data = np.delete(data, 11, 1)    # TouchTimestamp\n",
    "data = np.delete(data, 4, 1)     # RRInterval\n",
    "data = np.delete(data, 3, 1)     # hpvPower\n",
    "data = np.delete(data, 2, 1)     # Heartrate\n",
    "data = np.delete(data, 1, 1)     # Timestamp\n",
    "data.shape\n",
    "\n",
    "if(touch_only == 'true'):\n",
    "    data = np.delete(data, 7, 1)     # SDNN\n",
    "    data = np.delete(data, 3, 1)     # Burg\n",
    "    data = np.delete(data, 2, 1)     # ReactionTime\n",
    "\n",
    "if(touch_heart == 'true'):\n",
    "    data = np.delete(data, 7, 1)     # ReactionTime\n",
    "    \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"NbackSym1\",\"NbackSym2\",\"NbackSym3\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,data.shape[1]):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i, 0] = level2int[data[i, 0]]\n",
    "\n",
    "x_data = data[:, 1:]\n",
    "y_data = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 6) (219, 3) (46, 6) (46, 3) (48, 6) (48, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, input_shape=(x_train.shape[1],)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 219 samples, validate on 46 samples\n",
      "Epoch 1/200\n",
      "219/219 [==============================] - 0s - loss: 1.0216 - acc: 0.5297 - val_loss: 0.9096 - val_acc: 0.7174\n",
      "Epoch 2/200\n",
      "219/219 [==============================] - 0s - loss: 0.8077 - acc: 0.7260 - val_loss: 0.6833 - val_acc: 0.7391\n",
      "Epoch 3/200\n",
      "219/219 [==============================] - 0s - loss: 0.6100 - acc: 0.7443 - val_loss: 0.4975 - val_acc: 0.8043\n",
      "Epoch 4/200\n",
      "219/219 [==============================] - 0s - loss: 0.4929 - acc: 0.7991 - val_loss: 0.3593 - val_acc: 0.8478\n",
      "Epoch 5/200\n",
      "219/219 [==============================] - 0s - loss: 0.4261 - acc: 0.8174 - val_loss: 0.3126 - val_acc: 0.8913\n",
      "Epoch 6/200\n",
      "219/219 [==============================] - 0s - loss: 0.3592 - acc: 0.8676 - val_loss: 0.2925 - val_acc: 0.8696\n",
      "Epoch 7/200\n",
      "219/219 [==============================] - 0s - loss: 0.3851 - acc: 0.8584 - val_loss: 0.2780 - val_acc: 0.8696\n",
      "Epoch 8/200\n",
      "219/219 [==============================] - 0s - loss: 0.3214 - acc: 0.8539 - val_loss: 0.2635 - val_acc: 0.8913\n",
      "Epoch 9/200\n",
      "219/219 [==============================] - 0s - loss: 0.3093 - acc: 0.8584 - val_loss: 0.2452 - val_acc: 0.8478\n",
      "Epoch 10/200\n",
      "219/219 [==============================] - 0s - loss: 0.3185 - acc: 0.8813 - val_loss: 0.2325 - val_acc: 0.9130\n",
      "Epoch 11/200\n",
      "219/219 [==============================] - 0s - loss: 0.2795 - acc: 0.9041 - val_loss: 0.2131 - val_acc: 0.9130\n",
      "Epoch 12/200\n",
      "219/219 [==============================] - 0s - loss: 0.2757 - acc: 0.8721 - val_loss: 0.1947 - val_acc: 0.9130\n",
      "Epoch 13/200\n",
      "219/219 [==============================] - 0s - loss: 0.2630 - acc: 0.8904 - val_loss: 0.1829 - val_acc: 0.8913\n",
      "Epoch 14/200\n",
      "219/219 [==============================] - 0s - loss: 0.2542 - acc: 0.8950 - val_loss: 0.1823 - val_acc: 0.9130\n",
      "Epoch 15/200\n",
      "219/219 [==============================] - 0s - loss: 0.1986 - acc: 0.9224 - val_loss: 0.1705 - val_acc: 0.9130\n",
      "Epoch 16/200\n",
      "219/219 [==============================] - 0s - loss: 0.2440 - acc: 0.9087 - val_loss: 0.1540 - val_acc: 0.9348\n",
      "Epoch 17/200\n",
      "219/219 [==============================] - 0s - loss: 0.2223 - acc: 0.9041 - val_loss: 0.1386 - val_acc: 0.9565\n",
      "Epoch 18/200\n",
      "219/219 [==============================] - 0s - loss: 0.1884 - acc: 0.9224 - val_loss: 0.1390 - val_acc: 0.9348\n",
      "Epoch 19/200\n",
      "219/219 [==============================] - 0s - loss: 0.2077 - acc: 0.9132 - val_loss: 0.1407 - val_acc: 0.9348\n",
      "Epoch 20/200\n",
      "219/219 [==============================] - 0s - loss: 0.1998 - acc: 0.9087 - val_loss: 0.1188 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "219/219 [==============================] - 0s - loss: 0.1911 - acc: 0.9041 - val_loss: 0.1197 - val_acc: 0.9565\n",
      "Epoch 22/200\n",
      "219/219 [==============================] - 0s - loss: 0.1736 - acc: 0.9315 - val_loss: 0.1917 - val_acc: 0.9348\n",
      "Epoch 23/200\n",
      "219/219 [==============================] - 0s - loss: 0.1659 - acc: 0.9315 - val_loss: 0.1310 - val_acc: 0.9565\n",
      "Epoch 24/200\n",
      "219/219 [==============================] - 0s - loss: 0.1718 - acc: 0.9269 - val_loss: 0.1158 - val_acc: 0.9565\n",
      "Epoch 25/200\n",
      "219/219 [==============================] - 0s - loss: 0.1621 - acc: 0.9087 - val_loss: 0.1165 - val_acc: 0.9565\n",
      "Epoch 26/200\n",
      "219/219 [==============================] - 0s - loss: 0.1540 - acc: 0.9224 - val_loss: 0.0996 - val_acc: 0.9783\n",
      "Epoch 27/200\n",
      "219/219 [==============================] - 0s - loss: 0.1331 - acc: 0.9269 - val_loss: 0.0803 - val_acc: 0.9783\n",
      "Epoch 28/200\n",
      "219/219 [==============================] - 0s - loss: 0.1270 - acc: 0.9452 - val_loss: 0.0651 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "219/219 [==============================] - 0s - loss: 0.1350 - acc: 0.9361 - val_loss: 0.0765 - val_acc: 0.9783\n",
      "Epoch 30/200\n",
      "219/219 [==============================] - 0s - loss: 0.1591 - acc: 0.9269 - val_loss: 0.0801 - val_acc: 0.9783\n",
      "Epoch 31/200\n",
      "219/219 [==============================] - 0s - loss: 0.1212 - acc: 0.9498 - val_loss: 0.0693 - val_acc: 0.9783\n",
      "Epoch 32/200\n",
      "219/219 [==============================] - 0s - loss: 0.0997 - acc: 0.9635 - val_loss: 0.0575 - val_acc: 0.9783\n",
      "Epoch 33/200\n",
      "219/219 [==============================] - 0s - loss: 0.1336 - acc: 0.9589 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "219/219 [==============================] - 0s - loss: 0.0951 - acc: 0.9680 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "219/219 [==============================] - 0s - loss: 0.0811 - acc: 0.9726 - val_loss: 0.0649 - val_acc: 0.9565\n",
      "Epoch 36/200\n",
      "219/219 [==============================] - 0s - loss: 0.0742 - acc: 0.9772 - val_loss: 0.0369 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "219/219 [==============================] - 0s - loss: 0.0848 - acc: 0.9635 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "219/219 [==============================] - 0s - loss: 0.1071 - acc: 0.9498 - val_loss: 0.0467 - val_acc: 0.9783\n",
      "Epoch 39/200\n",
      "219/219 [==============================] - 0s - loss: 0.0982 - acc: 0.9543 - val_loss: 0.0548 - val_acc: 0.9565\n",
      "Epoch 40/200\n",
      "219/219 [==============================] - 0s - loss: 0.0610 - acc: 0.9772 - val_loss: 0.0312 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "219/219 [==============================] - 0s - loss: 0.0886 - acc: 0.9589 - val_loss: 0.0313 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "219/219 [==============================] - 0s - loss: 0.0776 - acc: 0.9772 - val_loss: 0.0461 - val_acc: 0.9783\n",
      "Epoch 43/200\n",
      "219/219 [==============================] - 0s - loss: 0.0645 - acc: 0.9726 - val_loss: 0.0335 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "219/219 [==============================] - 0s - loss: 0.0569 - acc: 0.9817 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "219/219 [==============================] - 0s - loss: 0.0769 - acc: 0.9635 - val_loss: 0.0268 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "219/219 [==============================] - 0s - loss: 0.0566 - acc: 0.9772 - val_loss: 0.0325 - val_acc: 0.9783\n",
      "Epoch 47/200\n",
      "219/219 [==============================] - 0s - loss: 0.0500 - acc: 0.9863 - val_loss: 0.0236 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "219/219 [==============================] - 0s - loss: 0.0516 - acc: 0.9817 - val_loss: 0.0174 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "219/219 [==============================] - 0s - loss: 0.0498 - acc: 0.9863 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "219/219 [==============================] - 0s - loss: 0.0468 - acc: 0.9772 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "219/219 [==============================] - 0s - loss: 0.0279 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "219/219 [==============================] - 0s - loss: 0.0339 - acc: 0.9863 - val_loss: 0.0171 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "219/219 [==============================] - 0s - loss: 0.0494 - acc: 0.9772 - val_loss: 0.0363 - val_acc: 0.9783\n",
      "Epoch 54/200\n",
      "219/219 [==============================] - 0s - loss: 0.0693 - acc: 0.9726 - val_loss: 0.1570 - val_acc: 0.9348\n",
      "Epoch 55/200\n",
      "219/219 [==============================] - 0s - loss: 0.0654 - acc: 0.9726 - val_loss: 0.0423 - val_acc: 0.9783\n",
      "Epoch 56/200\n",
      "219/219 [==============================] - 0s - loss: 0.0411 - acc: 0.9863 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "219/219 [==============================] - 0s - loss: 0.0732 - acc: 0.9726 - val_loss: 0.0273 - val_acc: 0.9783\n",
      "Epoch 58/200\n",
      "219/219 [==============================] - 0s - loss: 0.0313 - acc: 0.9954 - val_loss: 0.0693 - val_acc: 0.9783\n",
      "Epoch 59/200\n",
      "219/219 [==============================] - 0s - loss: 0.0470 - acc: 0.9772 - val_loss: 0.0165 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "219/219 [==============================] - 0s - loss: 0.0333 - acc: 0.9772 - val_loss: 0.0129 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "219/219 [==============================] - 0s - loss: 0.0347 - acc: 0.9817 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "219/219 [==============================] - 0s - loss: 0.0425 - acc: 0.9817 - val_loss: 0.0061 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "219/219 [==============================] - 0s - loss: 0.0313 - acc: 0.9909 - val_loss: 0.0109 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "219/219 [==============================] - 0s - loss: 0.0358 - acc: 0.9863 - val_loss: 0.0473 - val_acc: 0.9783\n",
      "Epoch 65/200\n",
      "219/219 [==============================] - 0s - loss: 0.0217 - acc: 0.9954 - val_loss: 0.0473 - val_acc: 0.9783\n",
      "Epoch 66/200\n",
      "219/219 [==============================] - 0s - loss: 0.0514 - acc: 0.9817 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "219/219 [==============================] - 0s - loss: 0.0547 - acc: 0.9772 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "219/219 [==============================] - 0s - loss: 0.0484 - acc: 0.9817 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "219/219 [==============================] - 0s - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "219/219 [==============================] - 0s - loss: 0.0200 - acc: 0.9954 - val_loss: 0.0322 - val_acc: 0.9783\n",
      "Epoch 71/200\n",
      "219/219 [==============================] - 0s - loss: 0.0197 - acc: 0.9954 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "219/219 [==============================] - 0s - loss: 0.0224 - acc: 0.9909 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "219/219 [==============================] - 0s - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "219/219 [==============================] - 0s - loss: 0.0235 - acc: 0.9863 - val_loss: 0.0470 - val_acc: 0.9783\n",
      "Epoch 75/200\n",
      "219/219 [==============================] - 0s - loss: 0.0195 - acc: 0.9954 - val_loss: 0.1727 - val_acc: 0.9348\n",
      "Epoch 76/200\n",
      "219/219 [==============================] - 0s - loss: 0.0258 - acc: 0.9863 - val_loss: 0.1033 - val_acc: 0.9565\n",
      "Epoch 77/200\n",
      "219/219 [==============================] - 0s - loss: 0.0323 - acc: 0.9909 - val_loss: 0.0841 - val_acc: 0.9783\n",
      "Epoch 78/200\n",
      "219/219 [==============================] - 0s - loss: 0.0270 - acc: 0.9817 - val_loss: 0.0507 - val_acc: 0.9783\n",
      "Epoch 79/200\n",
      "219/219 [==============================] - 0s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "219/219 [==============================] - 0s - loss: 0.0398 - acc: 0.9909 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "219/219 [==============================] - 0s - loss: 0.0129 - acc: 0.9954 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "219/219 [==============================] - 0s - loss: 0.0135 - acc: 0.9954 - val_loss: 9.9751e-04 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "219/219 [==============================] - 0s - loss: 0.0263 - acc: 0.9863 - val_loss: 8.8581e-04 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "219/219 [==============================] - 0s - loss: 0.0202 - acc: 0.9954 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "219/219 [==============================] - 0s - loss: 0.0330 - acc: 0.9863 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "219/219 [==============================] - 0s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "219/219 [==============================] - 0s - loss: 0.0106 - acc: 1.0000 - val_loss: 7.7713e-04 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "219/219 [==============================] - 0s - loss: 0.0149 - acc: 0.9954 - val_loss: 6.4271e-04 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "219/219 [==============================] - 0s - loss: 0.0497 - acc: 0.9817 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "219/219 [==============================] - 0s - loss: 0.0479 - acc: 0.9863 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "219/219 [==============================] - 0s - loss: 0.0133 - acc: 0.9954 - val_loss: 8.7683e-04 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "219/219 [==============================] - 0s - loss: 0.0167 - acc: 0.9909 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "219/219 [==============================] - 0s - loss: 0.0220 - acc: 0.9954 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "219/219 [==============================] - 0s - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "219/219 [==============================] - 0s - loss: 0.0282 - acc: 0.9954 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "219/219 [==============================] - 0s - loss: 0.0177 - acc: 0.9909 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "219/219 [==============================] - 0s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "219/219 [==============================] - 0s - loss: 0.0127 - acc: 0.9954 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "219/219 [==============================] - 0s - loss: 0.0505 - acc: 0.9863 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "219/219 [==============================] - 0s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1685 - val_acc: 0.9348\n",
      "Epoch 101/200\n",
      "219/219 [==============================] - 0s - loss: 0.1093 - acc: 0.9726 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "219/219 [==============================] - 0s - loss: 0.0297 - acc: 0.9909 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "219/219 [==============================] - 0s - loss: 0.0538 - acc: 0.9726 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "219/219 [==============================] - 0s - loss: 0.0254 - acc: 0.9909 - val_loss: 0.0267 - val_acc: 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3ced194d0>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 200\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00044534937478601933, 1.0]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/48 [===================>..........] - ETA: 0s[2 2 1 1 1 2 2 0 0 1 0 2 2 2 2 0 0 0 1 1 1 2 2 2 2 0 2 2 1 2 2 2 1 2 1 2 0\n",
      " 1 1 0 1 0 1 0 2 2 0 1]\n",
      "32/48 [===================>..........] - ETA: 0s                precision    recall  f1-score   support\n",
      "\n",
      "class 1(1back)       1.00      1.00      1.00        12\n",
      "class 2(2back)       1.00      1.00      1.00        15\n",
      " class3(3back)       1.00      1.00      1.00        21\n",
      "\n",
      "   avg / total       1.00      1.00      1.00        48\n",
      "\n",
      "[[12  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  0 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 1(1back)', 'class 2(2back)', 'class3(3back)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
