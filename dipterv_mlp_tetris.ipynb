{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(603, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"result_tetris.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    data = np.delete(data, 1, 1) \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tetris1', 349860.0, 1688.7, 676.15, 4.378305084745762, 335.19,\n",
       "       537.78], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"tetris1\",\"tetris2\",\"tetris3\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,7):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i, 0] = level2int[data[i, 0]]\n",
    "\n",
    "x_data = data[:, 1:]\n",
    "y_data = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422, 6) (422, 3) (90, 6) (90, 3) (91, 6) (91, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, input_shape=(6,)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples, validate on 90 samples\n",
      "Epoch 1/150\n",
      "422/422 [==============================] - 0s - loss: 0.7594 - acc: 0.6682 - val_loss: 0.5401 - val_acc: 0.7333\n",
      "Epoch 2/150\n",
      "422/422 [==============================] - 0s - loss: 0.5013 - acc: 0.7370 - val_loss: 0.4463 - val_acc: 0.7556\n",
      "Epoch 3/150\n",
      "422/422 [==============================] - 0s - loss: 0.4412 - acc: 0.7654 - val_loss: 0.4240 - val_acc: 0.7444\n",
      "Epoch 4/150\n",
      "422/422 [==============================] - 0s - loss: 0.4613 - acc: 0.7370 - val_loss: 0.4138 - val_acc: 0.8000\n",
      "Epoch 5/150\n",
      "422/422 [==============================] - 0s - loss: 0.4254 - acc: 0.7559 - val_loss: 0.4014 - val_acc: 0.7778\n",
      "Epoch 6/150\n",
      "422/422 [==============================] - 0s - loss: 0.4125 - acc: 0.7701 - val_loss: 0.3993 - val_acc: 0.7889\n",
      "Epoch 7/150\n",
      "422/422 [==============================] - 0s - loss: 0.3953 - acc: 0.7962 - val_loss: 0.3921 - val_acc: 0.7667\n",
      "Epoch 8/150\n",
      "422/422 [==============================] - 0s - loss: 0.4056 - acc: 0.7678 - val_loss: 0.3982 - val_acc: 0.7222\n",
      "Epoch 9/150\n",
      "422/422 [==============================] - 0s - loss: 0.3909 - acc: 0.7796 - val_loss: 0.3956 - val_acc: 0.8000\n",
      "Epoch 10/150\n",
      "422/422 [==============================] - 0s - loss: 0.3889 - acc: 0.7630 - val_loss: 0.3837 - val_acc: 0.7778\n",
      "Epoch 11/150\n",
      "422/422 [==============================] - 0s - loss: 0.3844 - acc: 0.7796 - val_loss: 0.3695 - val_acc: 0.7778\n",
      "Epoch 12/150\n",
      "422/422 [==============================] - 0s - loss: 0.3689 - acc: 0.7820 - val_loss: 0.3644 - val_acc: 0.7889\n",
      "Epoch 13/150\n",
      "422/422 [==============================] - 0s - loss: 0.3625 - acc: 0.8033 - val_loss: 0.3576 - val_acc: 0.8111\n",
      "Epoch 14/150\n",
      "422/422 [==============================] - 0s - loss: 0.3545 - acc: 0.8057 - val_loss: 0.3531 - val_acc: 0.7889\n",
      "Epoch 15/150\n",
      "422/422 [==============================] - 0s - loss: 0.3616 - acc: 0.8009 - val_loss: 0.3476 - val_acc: 0.8111\n",
      "Epoch 16/150\n",
      "422/422 [==============================] - 0s - loss: 0.3417 - acc: 0.8246 - val_loss: 0.3539 - val_acc: 0.7889\n",
      "Epoch 17/150\n",
      "422/422 [==============================] - 0s - loss: 0.3491 - acc: 0.8199 - val_loss: 0.3585 - val_acc: 0.7889\n",
      "Epoch 18/150\n",
      "422/422 [==============================] - 0s - loss: 0.3357 - acc: 0.8365 - val_loss: 0.3363 - val_acc: 0.8111\n",
      "Epoch 19/150\n",
      "422/422 [==============================] - 0s - loss: 0.3257 - acc: 0.8246 - val_loss: 0.3251 - val_acc: 0.8111\n",
      "Epoch 20/150\n",
      "422/422 [==============================] - 0s - loss: 0.3220 - acc: 0.8270 - val_loss: 0.3289 - val_acc: 0.8222\n",
      "Epoch 21/150\n",
      "422/422 [==============================] - 0s - loss: 0.3389 - acc: 0.8128 - val_loss: 0.3277 - val_acc: 0.8000\n",
      "Epoch 22/150\n",
      "422/422 [==============================] - 0s - loss: 0.3106 - acc: 0.8578 - val_loss: 0.3203 - val_acc: 0.8222\n",
      "Epoch 23/150\n",
      "422/422 [==============================] - 0s - loss: 0.3014 - acc: 0.8460 - val_loss: 0.3200 - val_acc: 0.8222\n",
      "Epoch 24/150\n",
      "422/422 [==============================] - 0s - loss: 0.3127 - acc: 0.8199 - val_loss: 0.3130 - val_acc: 0.8444\n",
      "Epoch 25/150\n",
      "422/422 [==============================] - 0s - loss: 0.2934 - acc: 0.8412 - val_loss: 0.3095 - val_acc: 0.8333\n",
      "Epoch 26/150\n",
      "422/422 [==============================] - 0s - loss: 0.2974 - acc: 0.8507 - val_loss: 0.3151 - val_acc: 0.8444\n",
      "Epoch 27/150\n",
      "422/422 [==============================] - 0s - loss: 0.2879 - acc: 0.8460 - val_loss: 0.3245 - val_acc: 0.8333\n",
      "Epoch 28/150\n",
      "422/422 [==============================] - 0s - loss: 0.3043 - acc: 0.8365 - val_loss: 0.3155 - val_acc: 0.8444\n",
      "Epoch 29/150\n",
      "422/422 [==============================] - 0s - loss: 0.3021 - acc: 0.8365 - val_loss: 0.3064 - val_acc: 0.8556\n",
      "Epoch 30/150\n",
      "422/422 [==============================] - 0s - loss: 0.3020 - acc: 0.8128 - val_loss: 0.3224 - val_acc: 0.8333\n",
      "Epoch 31/150\n",
      "422/422 [==============================] - 0s - loss: 0.2822 - acc: 0.8578 - val_loss: 0.2990 - val_acc: 0.8444\n",
      "Epoch 32/150\n",
      "422/422 [==============================] - 0s - loss: 0.2661 - acc: 0.8531 - val_loss: 0.2993 - val_acc: 0.8556\n",
      "Epoch 33/150\n",
      "422/422 [==============================] - 0s - loss: 0.2658 - acc: 0.8626 - val_loss: 0.3008 - val_acc: 0.8444\n",
      "Epoch 34/150\n",
      "422/422 [==============================] - 0s - loss: 0.2914 - acc: 0.8460 - val_loss: 0.2946 - val_acc: 0.8556\n",
      "Epoch 35/150\n",
      "422/422 [==============================] - 0s - loss: 0.2935 - acc: 0.8341 - val_loss: 0.3039 - val_acc: 0.8444\n",
      "Epoch 36/150\n",
      "422/422 [==============================] - 0s - loss: 0.2789 - acc: 0.8531 - val_loss: 0.2914 - val_acc: 0.8667\n",
      "Epoch 37/150\n",
      "422/422 [==============================] - 0s - loss: 0.2492 - acc: 0.8720 - val_loss: 0.2792 - val_acc: 0.8889\n",
      "Epoch 38/150\n",
      "422/422 [==============================] - 0s - loss: 0.2747 - acc: 0.8626 - val_loss: 0.2958 - val_acc: 0.8556\n",
      "Epoch 39/150\n",
      "422/422 [==============================] - 0s - loss: 0.2708 - acc: 0.8555 - val_loss: 0.2975 - val_acc: 0.8667\n",
      "Epoch 40/150\n",
      "422/422 [==============================] - 0s - loss: 0.2625 - acc: 0.8483 - val_loss: 0.2777 - val_acc: 0.8667\n",
      "Epoch 41/150\n",
      "422/422 [==============================] - 0s - loss: 0.2616 - acc: 0.8626 - val_loss: 0.2884 - val_acc: 0.8667\n",
      "Epoch 42/150\n",
      "422/422 [==============================] - 0s - loss: 0.2611 - acc: 0.8531 - val_loss: 0.2861 - val_acc: 0.8556\n",
      "Epoch 43/150\n",
      "422/422 [==============================] - 0s - loss: 0.2790 - acc: 0.8555 - val_loss: 0.3045 - val_acc: 0.8667\n",
      "Epoch 44/150\n",
      "422/422 [==============================] - 0s - loss: 0.2639 - acc: 0.8626 - val_loss: 0.2951 - val_acc: 0.8333\n",
      "Epoch 45/150\n",
      "422/422 [==============================] - 0s - loss: 0.2515 - acc: 0.8531 - val_loss: 0.2885 - val_acc: 0.8556\n",
      "Epoch 46/150\n",
      "422/422 [==============================] - 0s - loss: 0.2679 - acc: 0.8436 - val_loss: 0.2802 - val_acc: 0.8556\n",
      "Epoch 47/150\n",
      "422/422 [==============================] - 0s - loss: 0.2410 - acc: 0.8744 - val_loss: 0.2792 - val_acc: 0.8778\n",
      "Epoch 48/150\n",
      "422/422 [==============================] - 0s - loss: 0.2629 - acc: 0.8483 - val_loss: 0.2950 - val_acc: 0.8444\n",
      "Epoch 49/150\n",
      "422/422 [==============================] - 0s - loss: 0.2477 - acc: 0.8720 - val_loss: 0.2794 - val_acc: 0.8556\n",
      "Epoch 50/150\n",
      "422/422 [==============================] - 0s - loss: 0.2568 - acc: 0.8649 - val_loss: 0.2849 - val_acc: 0.8556\n",
      "Epoch 51/150\n",
      "422/422 [==============================] - 0s - loss: 0.2552 - acc: 0.8673 - val_loss: 0.2796 - val_acc: 0.8667\n",
      "Epoch 52/150\n",
      "422/422 [==============================] - 0s - loss: 0.2578 - acc: 0.8673 - val_loss: 0.2716 - val_acc: 0.8667\n",
      "Epoch 53/150\n",
      "422/422 [==============================] - 0s - loss: 0.2657 - acc: 0.8649 - val_loss: 0.2816 - val_acc: 0.8556\n",
      "Epoch 54/150\n",
      "422/422 [==============================] - 0s - loss: 0.2516 - acc: 0.8555 - val_loss: 0.2811 - val_acc: 0.8556\n",
      "Epoch 55/150\n",
      "422/422 [==============================] - 0s - loss: 0.2326 - acc: 0.8863 - val_loss: 0.2617 - val_acc: 0.8778\n",
      "Epoch 56/150\n",
      "422/422 [==============================] - 0s - loss: 0.2439 - acc: 0.8673 - val_loss: 0.2658 - val_acc: 0.8667\n",
      "Epoch 57/150\n",
      "422/422 [==============================] - 0s - loss: 0.2403 - acc: 0.8697 - val_loss: 0.2808 - val_acc: 0.8556\n",
      "Epoch 58/150\n",
      "422/422 [==============================] - 0s - loss: 0.2401 - acc: 0.8815 - val_loss: 0.2710 - val_acc: 0.8667\n",
      "Epoch 59/150\n",
      "422/422 [==============================] - 0s - loss: 0.2490 - acc: 0.8697 - val_loss: 0.2887 - val_acc: 0.8444\n",
      "Epoch 60/150\n",
      "422/422 [==============================] - 0s - loss: 0.2503 - acc: 0.8412 - val_loss: 0.2861 - val_acc: 0.8556\n",
      "Epoch 61/150\n",
      "422/422 [==============================] - 0s - loss: 0.2490 - acc: 0.8697 - val_loss: 0.2536 - val_acc: 0.8778\n",
      "Epoch 62/150\n",
      "422/422 [==============================] - 0s - loss: 0.2364 - acc: 0.8815 - val_loss: 0.2707 - val_acc: 0.8778\n",
      "Epoch 63/150\n",
      "422/422 [==============================] - 0s - loss: 0.2374 - acc: 0.8791 - val_loss: 0.2737 - val_acc: 0.8667\n",
      "Epoch 64/150\n",
      "422/422 [==============================] - 0s - loss: 0.2485 - acc: 0.8649 - val_loss: 0.2960 - val_acc: 0.8444\n",
      "Epoch 65/150\n",
      "422/422 [==============================] - 0s - loss: 0.2427 - acc: 0.8626 - val_loss: 0.2736 - val_acc: 0.8667\n",
      "Epoch 66/150\n",
      "422/422 [==============================] - 0s - loss: 0.2404 - acc: 0.8768 - val_loss: 0.2672 - val_acc: 0.8667\n",
      "Epoch 67/150\n",
      "422/422 [==============================] - 0s - loss: 0.2329 - acc: 0.8863 - val_loss: 0.2549 - val_acc: 0.8667\n",
      "Epoch 68/150\n",
      "422/422 [==============================] - 0s - loss: 0.2351 - acc: 0.8720 - val_loss: 0.2553 - val_acc: 0.8778\n",
      "Epoch 69/150\n",
      "422/422 [==============================] - 0s - loss: 0.2324 - acc: 0.8791 - val_loss: 0.2825 - val_acc: 0.8667\n",
      "Epoch 70/150\n",
      "422/422 [==============================] - 0s - loss: 0.2228 - acc: 0.8815 - val_loss: 0.2810 - val_acc: 0.8556\n",
      "Epoch 71/150\n",
      "422/422 [==============================] - 0s - loss: 0.2293 - acc: 0.8839 - val_loss: 0.2570 - val_acc: 0.8778\n",
      "Epoch 72/150\n",
      "422/422 [==============================] - 0s - loss: 0.2175 - acc: 0.8863 - val_loss: 0.2842 - val_acc: 0.8667\n",
      "Epoch 73/150\n",
      "422/422 [==============================] - 0s - loss: 0.2223 - acc: 0.8863 - val_loss: 0.2806 - val_acc: 0.8556\n",
      "Epoch 74/150\n",
      "422/422 [==============================] - 0s - loss: 0.2201 - acc: 0.8934 - val_loss: 0.2567 - val_acc: 0.8667\n",
      "Epoch 75/150\n",
      "422/422 [==============================] - 0s - loss: 0.2299 - acc: 0.8886 - val_loss: 0.2648 - val_acc: 0.8778\n",
      "Epoch 76/150\n",
      "422/422 [==============================] - 0s - loss: 0.2278 - acc: 0.8720 - val_loss: 0.2580 - val_acc: 0.8667\n",
      "Epoch 77/150\n",
      "422/422 [==============================] - 0s - loss: 0.2113 - acc: 0.8957 - val_loss: 0.2555 - val_acc: 0.8556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02ba3b2fd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 150\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "50/91 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2026680493420297, 0.9230769099770012]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/91 [=========>....................] - ETA: 0s[1 0 2 1 0 2 2 0 0 0 1 2 2 0 2 2 1 2 2 2 2 0 2 2 0 1 1 0 2 2 1 0 2 2 0 0 2\n",
      " 1 0 1 2 0 0 2 1 2 0 2 2 1 2 1 2 2 1 1 2 2 1 2 0 2 2 1 2 0 1 2 0 1 2 1 0 0\n",
      " 1 0 2 0 0 1 1 1 0 2 1 0 0 2 2 2 1]\n",
      "32/91 [=========>....................] - ETA: 0s                  precision    recall  f1-score   support\n",
      "\n",
      "class 0(tetris1)       1.00      1.00      1.00        27\n",
      "class 1(tetris2)       0.92      0.82      0.87        28\n",
      "class 2(tetris3)       0.87      0.94      0.91        36\n",
      "\n",
      "     avg / total       0.92      0.92      0.92        91\n",
      "\n",
      "[[27  0  0]\n",
      " [ 0 23  5]\n",
      " [ 0  2 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(tetris1)', 'class 1(tetris2)', 'class 2(tetris3)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
