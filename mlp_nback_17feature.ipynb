{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(5057, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"nback_full_1.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5057, 5)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    data = np.delete(data, 1, 1) \n",
    "    \n",
    "\n",
    "data = data[:,0:5]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3back', 1802.4, 796.06, 39.528, 4.7517777777777805], dtype=object)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"0back\",\"1back\",\"2back\",\"3back\"]\n",
    "#level=[\"tetris1\",\"tetris2\",\"tetris3\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i, 0] = level2int[data[i, 0]]\n",
    "\n",
    "x_data = data[:, 1:]\n",
    "y_data = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3539, 4) (3539, 4) (758, 4) (758, 4) (760, 4) (760, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#TETRIS\n",
    "#model.add(Dense(200, input_shape=(4,)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(700, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(200, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.add(Dense(200, input_shape=(4,)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3539 samples, validate on 758 samples\n",
      "Epoch 1/300\n",
      "3539/3539 [==============================] - 1s - loss: 1.3813 - acc: 0.2735 - val_loss: 1.3698 - val_acc: 0.3153\n",
      "Epoch 2/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3649 - acc: 0.3055 - val_loss: 1.3583 - val_acc: 0.3311\n",
      "Epoch 3/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3572 - acc: 0.3165 - val_loss: 1.3584 - val_acc: 0.3391\n",
      "Epoch 4/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3552 - acc: 0.3156 - val_loss: 1.3544 - val_acc: 0.3377\n",
      "Epoch 5/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3515 - acc: 0.3221 - val_loss: 1.3517 - val_acc: 0.3325\n",
      "Epoch 6/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3547 - acc: 0.3159 - val_loss: 1.3455 - val_acc: 0.3351\n",
      "Epoch 7/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3489 - acc: 0.3204 - val_loss: 1.3409 - val_acc: 0.3364\n",
      "Epoch 8/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3499 - acc: 0.3199 - val_loss: 1.3409 - val_acc: 0.3443\n",
      "Epoch 9/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3477 - acc: 0.3216 - val_loss: 1.3434 - val_acc: 0.3351\n",
      "Epoch 10/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3493 - acc: 0.3221 - val_loss: 1.3428 - val_acc: 0.3377\n",
      "Epoch 11/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3458 - acc: 0.3306 - val_loss: 1.3409 - val_acc: 0.3377\n",
      "Epoch 12/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3412 - acc: 0.3230 - val_loss: 1.3419 - val_acc: 0.3404\n",
      "Epoch 13/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3391 - acc: 0.3278 - val_loss: 1.3351 - val_acc: 0.3549\n",
      "Epoch 14/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3427 - acc: 0.3272 - val_loss: 1.3344 - val_acc: 0.3602\n",
      "Epoch 15/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3402 - acc: 0.3351 - val_loss: 1.3325 - val_acc: 0.3536\n",
      "Epoch 16/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3386 - acc: 0.3343 - val_loss: 1.3358 - val_acc: 0.3509\n",
      "Epoch 17/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3423 - acc: 0.3371 - val_loss: 1.3278 - val_acc: 0.3628\n",
      "Epoch 18/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3385 - acc: 0.3425 - val_loss: 1.3228 - val_acc: 0.3813\n",
      "Epoch 19/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3282 - acc: 0.3428 - val_loss: 1.3220 - val_acc: 0.3668\n",
      "Epoch 20/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3303 - acc: 0.3473 - val_loss: 1.3159 - val_acc: 0.3747\n",
      "Epoch 21/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3277 - acc: 0.3546 - val_loss: 1.3133 - val_acc: 0.3879\n",
      "Epoch 22/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3189 - acc: 0.3603 - val_loss: 1.3171 - val_acc: 0.3760\n",
      "Epoch 23/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3283 - acc: 0.3549 - val_loss: 1.3173 - val_acc: 0.3694\n",
      "Epoch 24/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3242 - acc: 0.3476 - val_loss: 1.3150 - val_acc: 0.3641\n",
      "Epoch 25/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3237 - acc: 0.3495 - val_loss: 1.3065 - val_acc: 0.3747\n",
      "Epoch 26/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3170 - acc: 0.3549 - val_loss: 1.3016 - val_acc: 0.3826\n",
      "Epoch 27/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3216 - acc: 0.3493 - val_loss: 1.3074 - val_acc: 0.3786\n",
      "Epoch 28/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3210 - acc: 0.3464 - val_loss: 1.3042 - val_acc: 0.3786\n",
      "Epoch 29/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3204 - acc: 0.3487 - val_loss: 1.2979 - val_acc: 0.3892\n",
      "Epoch 30/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3122 - acc: 0.3509 - val_loss: 1.2981 - val_acc: 0.3734\n",
      "Epoch 31/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3202 - acc: 0.3515 - val_loss: 1.2951 - val_acc: 0.3865\n",
      "Epoch 32/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3196 - acc: 0.3538 - val_loss: 1.2947 - val_acc: 0.3826\n",
      "Epoch 33/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3157 - acc: 0.3504 - val_loss: 1.2984 - val_acc: 0.3773\n",
      "Epoch 34/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3114 - acc: 0.3526 - val_loss: 1.2970 - val_acc: 0.3628\n",
      "Epoch 35/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3073 - acc: 0.3586 - val_loss: 1.2925 - val_acc: 0.3892\n",
      "Epoch 36/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3107 - acc: 0.3543 - val_loss: 1.2832 - val_acc: 0.3602\n",
      "Epoch 37/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3092 - acc: 0.3606 - val_loss: 1.2817 - val_acc: 0.4011\n",
      "Epoch 38/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3059 - acc: 0.3526 - val_loss: 1.2810 - val_acc: 0.3958\n",
      "Epoch 39/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3040 - acc: 0.3651 - val_loss: 1.2761 - val_acc: 0.3971\n",
      "Epoch 40/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.3012 - acc: 0.3704 - val_loss: 1.2687 - val_acc: 0.4024\n",
      "Epoch 41/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2933 - acc: 0.3716 - val_loss: 1.2706 - val_acc: 0.4090\n",
      "Epoch 42/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2953 - acc: 0.3642 - val_loss: 1.2661 - val_acc: 0.4077\n",
      "Epoch 43/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2938 - acc: 0.3730 - val_loss: 1.2669 - val_acc: 0.3997\n",
      "Epoch 44/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2929 - acc: 0.3741 - val_loss: 1.2658 - val_acc: 0.3958\n",
      "Epoch 45/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2931 - acc: 0.3654 - val_loss: 1.2644 - val_acc: 0.4050\n",
      "Epoch 46/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2956 - acc: 0.3702 - val_loss: 1.2634 - val_acc: 0.3773\n",
      "Epoch 47/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2890 - acc: 0.3707 - val_loss: 1.2658 - val_acc: 0.3799\n",
      "Epoch 48/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2931 - acc: 0.3690 - val_loss: 1.2656 - val_acc: 0.3905\n",
      "Epoch 49/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2913 - acc: 0.3679 - val_loss: 1.2591 - val_acc: 0.4103\n",
      "Epoch 50/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2841 - acc: 0.3820 - val_loss: 1.2515 - val_acc: 0.4195\n",
      "Epoch 51/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2823 - acc: 0.3789 - val_loss: 1.2499 - val_acc: 0.4077\n",
      "Epoch 52/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2851 - acc: 0.3747 - val_loss: 1.2544 - val_acc: 0.3997\n",
      "Epoch 53/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2819 - acc: 0.3837 - val_loss: 1.2502 - val_acc: 0.4248\n",
      "Epoch 54/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2854 - acc: 0.3730 - val_loss: 1.2478 - val_acc: 0.4182\n",
      "Epoch 55/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2808 - acc: 0.3846 - val_loss: 1.2499 - val_acc: 0.4380\n",
      "Epoch 56/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2814 - acc: 0.3792 - val_loss: 1.2503 - val_acc: 0.3984\n",
      "Epoch 57/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2808 - acc: 0.3690 - val_loss: 1.2496 - val_acc: 0.4077\n",
      "Epoch 58/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2818 - acc: 0.3716 - val_loss: 1.2467 - val_acc: 0.4142\n",
      "Epoch 59/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2793 - acc: 0.3840 - val_loss: 1.2510 - val_acc: 0.4142\n",
      "Epoch 60/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2918 - acc: 0.3662 - val_loss: 1.2615 - val_acc: 0.3734\n",
      "Epoch 61/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2804 - acc: 0.3817 - val_loss: 1.2497 - val_acc: 0.3984\n",
      "Epoch 62/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2784 - acc: 0.3857 - val_loss: 1.2433 - val_acc: 0.4301\n",
      "Epoch 63/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2715 - acc: 0.3976 - val_loss: 1.2431 - val_acc: 0.4261\n",
      "Epoch 64/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2731 - acc: 0.3823 - val_loss: 1.2374 - val_acc: 0.4459\n",
      "Epoch 65/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2723 - acc: 0.3897 - val_loss: 1.2322 - val_acc: 0.4261\n",
      "Epoch 66/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2722 - acc: 0.3987 - val_loss: 1.2327 - val_acc: 0.4261\n",
      "Epoch 67/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2748 - acc: 0.3905 - val_loss: 1.2359 - val_acc: 0.4433\n",
      "Epoch 68/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2658 - acc: 0.3942 - val_loss: 1.2332 - val_acc: 0.4380\n",
      "Epoch 69/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2642 - acc: 0.4052 - val_loss: 1.2288 - val_acc: 0.4288\n",
      "Epoch 70/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2713 - acc: 0.3993 - val_loss: 1.2308 - val_acc: 0.4261\n",
      "Epoch 71/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2761 - acc: 0.3865 - val_loss: 1.2363 - val_acc: 0.4340\n",
      "Epoch 72/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2655 - acc: 0.3987 - val_loss: 1.2376 - val_acc: 0.4327\n",
      "Epoch 73/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2628 - acc: 0.4069 - val_loss: 1.2291 - val_acc: 0.4222\n",
      "Epoch 74/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2576 - acc: 0.4032 - val_loss: 1.2262 - val_acc: 0.4327\n",
      "Epoch 75/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2538 - acc: 0.3998 - val_loss: 1.2232 - val_acc: 0.4301\n",
      "Epoch 76/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2648 - acc: 0.3967 - val_loss: 1.2251 - val_acc: 0.4367\n",
      "Epoch 77/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2558 - acc: 0.3945 - val_loss: 1.2236 - val_acc: 0.4446\n",
      "Epoch 78/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2582 - acc: 0.4066 - val_loss: 1.2214 - val_acc: 0.4485\n",
      "Epoch 79/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2601 - acc: 0.4018 - val_loss: 1.2231 - val_acc: 0.4406\n",
      "Epoch 80/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2584 - acc: 0.4027 - val_loss: 1.2199 - val_acc: 0.4393\n",
      "Epoch 81/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2542 - acc: 0.4148 - val_loss: 1.2191 - val_acc: 0.4182\n",
      "Epoch 82/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2518 - acc: 0.4142 - val_loss: 1.2101 - val_acc: 0.4301\n",
      "Epoch 83/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2461 - acc: 0.4109 - val_loss: 1.2143 - val_acc: 0.4314\n",
      "Epoch 84/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2501 - acc: 0.3976 - val_loss: 1.2105 - val_acc: 0.4406\n",
      "Epoch 85/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2547 - acc: 0.4063 - val_loss: 1.2127 - val_acc: 0.4354\n",
      "Epoch 86/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2523 - acc: 0.4103 - val_loss: 1.2227 - val_acc: 0.4182\n",
      "Epoch 87/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2405 - acc: 0.4069 - val_loss: 1.2106 - val_acc: 0.4446\n",
      "Epoch 88/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2456 - acc: 0.4080 - val_loss: 1.2116 - val_acc: 0.4459\n",
      "Epoch 89/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2430 - acc: 0.4213 - val_loss: 1.2115 - val_acc: 0.4551\n",
      "Epoch 90/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2462 - acc: 0.4253 - val_loss: 1.2260 - val_acc: 0.4380\n",
      "Epoch 91/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2458 - acc: 0.4046 - val_loss: 1.2134 - val_acc: 0.4182\n",
      "Epoch 92/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2466 - acc: 0.4072 - val_loss: 1.2087 - val_acc: 0.4393\n",
      "Epoch 93/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2414 - acc: 0.4128 - val_loss: 1.2044 - val_acc: 0.4499\n",
      "Epoch 94/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2417 - acc: 0.4233 - val_loss: 1.2024 - val_acc: 0.4499\n",
      "Epoch 95/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2333 - acc: 0.4179 - val_loss: 1.2046 - val_acc: 0.4367\n",
      "Epoch 96/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2371 - acc: 0.4253 - val_loss: 1.2031 - val_acc: 0.4565\n",
      "Epoch 97/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2347 - acc: 0.4244 - val_loss: 1.2029 - val_acc: 0.4367\n",
      "Epoch 98/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2396 - acc: 0.4140 - val_loss: 1.2071 - val_acc: 0.4485\n",
      "Epoch 99/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2397 - acc: 0.4193 - val_loss: 1.2010 - val_acc: 0.4499\n",
      "Epoch 100/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2326 - acc: 0.4284 - val_loss: 1.1958 - val_acc: 0.4617\n",
      "Epoch 101/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2257 - acc: 0.4247 - val_loss: 1.2007 - val_acc: 0.4538\n",
      "Epoch 102/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2291 - acc: 0.4337 - val_loss: 1.1979 - val_acc: 0.4591\n",
      "Epoch 103/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2253 - acc: 0.4222 - val_loss: 1.1921 - val_acc: 0.4631\n",
      "Epoch 104/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2203 - acc: 0.4261 - val_loss: 1.1908 - val_acc: 0.4736\n",
      "Epoch 105/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2258 - acc: 0.4253 - val_loss: 1.1865 - val_acc: 0.4565\n",
      "Epoch 106/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2213 - acc: 0.4272 - val_loss: 1.1952 - val_acc: 0.4433\n",
      "Epoch 107/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2261 - acc: 0.4303 - val_loss: 1.1968 - val_acc: 0.4512\n",
      "Epoch 108/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2359 - acc: 0.4151 - val_loss: 1.1917 - val_acc: 0.4512\n",
      "Epoch 109/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2225 - acc: 0.4244 - val_loss: 1.1921 - val_acc: 0.4354\n",
      "Epoch 110/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2197 - acc: 0.4250 - val_loss: 1.1917 - val_acc: 0.4420\n",
      "Epoch 111/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2177 - acc: 0.4411 - val_loss: 1.1851 - val_acc: 0.4710\n",
      "Epoch 112/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2313 - acc: 0.4306 - val_loss: 1.1907 - val_acc: 0.4789\n",
      "Epoch 113/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2179 - acc: 0.4400 - val_loss: 1.1817 - val_acc: 0.4472\n",
      "Epoch 114/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2115 - acc: 0.4343 - val_loss: 1.1812 - val_acc: 0.4697\n",
      "Epoch 115/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2110 - acc: 0.4428 - val_loss: 1.1810 - val_acc: 0.4578\n",
      "Epoch 116/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2145 - acc: 0.4354 - val_loss: 1.1782 - val_acc: 0.4420\n",
      "Epoch 117/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2131 - acc: 0.4456 - val_loss: 1.1807 - val_acc: 0.4644\n",
      "Epoch 118/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2158 - acc: 0.4383 - val_loss: 1.1744 - val_acc: 0.4736\n",
      "Epoch 119/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2085 - acc: 0.4335 - val_loss: 1.1828 - val_acc: 0.4710\n",
      "Epoch 120/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2113 - acc: 0.4329 - val_loss: 1.1741 - val_acc: 0.4683\n",
      "Epoch 121/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2065 - acc: 0.4371 - val_loss: 1.1742 - val_acc: 0.4631\n",
      "Epoch 122/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2030 - acc: 0.4453 - val_loss: 1.1694 - val_acc: 0.4710\n",
      "Epoch 123/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2069 - acc: 0.4377 - val_loss: 1.1711 - val_acc: 0.4789\n",
      "Epoch 124/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1934 - acc: 0.4515 - val_loss: 1.1720 - val_acc: 0.4697\n",
      "Epoch 125/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1924 - acc: 0.4431 - val_loss: 1.1672 - val_acc: 0.4723\n",
      "Epoch 126/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1976 - acc: 0.4442 - val_loss: 1.1702 - val_acc: 0.4538\n",
      "Epoch 127/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.2018 - acc: 0.4419 - val_loss: 1.1694 - val_acc: 0.4591\n",
      "Epoch 128/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1960 - acc: 0.4433 - val_loss: 1.1602 - val_acc: 0.4697\n",
      "Epoch 129/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1912 - acc: 0.4453 - val_loss: 1.1580 - val_acc: 0.4776\n",
      "Epoch 130/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1838 - acc: 0.4484 - val_loss: 1.1584 - val_acc: 0.4802\n",
      "Epoch 131/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1942 - acc: 0.4408 - val_loss: 1.1579 - val_acc: 0.4723\n",
      "Epoch 132/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1881 - acc: 0.4617 - val_loss: 1.1597 - val_acc: 0.4802\n",
      "Epoch 133/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1976 - acc: 0.4346 - val_loss: 1.1551 - val_acc: 0.4749\n",
      "Epoch 134/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1923 - acc: 0.4535 - val_loss: 1.1607 - val_acc: 0.4763\n",
      "Epoch 135/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1880 - acc: 0.4521 - val_loss: 1.1664 - val_acc: 0.4472\n",
      "Epoch 136/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1971 - acc: 0.4368 - val_loss: 1.1602 - val_acc: 0.4670\n",
      "Epoch 137/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1868 - acc: 0.4552 - val_loss: 1.1590 - val_acc: 0.4697\n",
      "Epoch 138/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1865 - acc: 0.4532 - val_loss: 1.1601 - val_acc: 0.4763\n",
      "Epoch 139/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1871 - acc: 0.4535 - val_loss: 1.1559 - val_acc: 0.4763\n",
      "Epoch 140/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1895 - acc: 0.4558 - val_loss: 1.1488 - val_acc: 0.4842\n",
      "Epoch 141/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1821 - acc: 0.4620 - val_loss: 1.1507 - val_acc: 0.4710\n",
      "Epoch 142/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1879 - acc: 0.4479 - val_loss: 1.1440 - val_acc: 0.4947\n",
      "Epoch 143/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1879 - acc: 0.4496 - val_loss: 1.1494 - val_acc: 0.4802\n",
      "Epoch 144/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1802 - acc: 0.4586 - val_loss: 1.1483 - val_acc: 0.4868\n",
      "Epoch 145/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1829 - acc: 0.4524 - val_loss: 1.1516 - val_acc: 0.4881\n",
      "Epoch 146/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1744 - acc: 0.4657 - val_loss: 1.1510 - val_acc: 0.4802\n",
      "Epoch 147/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1842 - acc: 0.4544 - val_loss: 1.1487 - val_acc: 0.4828\n",
      "Epoch 148/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1805 - acc: 0.4535 - val_loss: 1.1459 - val_acc: 0.4842\n",
      "Epoch 149/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1732 - acc: 0.4640 - val_loss: 1.1414 - val_acc: 0.4763\n",
      "Epoch 150/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1693 - acc: 0.4563 - val_loss: 1.1412 - val_acc: 0.4763\n",
      "Epoch 151/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1744 - acc: 0.4496 - val_loss: 1.1482 - val_acc: 0.4802\n",
      "Epoch 152/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1674 - acc: 0.4575 - val_loss: 1.1365 - val_acc: 0.4934\n",
      "Epoch 153/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1737 - acc: 0.4518 - val_loss: 1.1409 - val_acc: 0.4776\n",
      "Epoch 154/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1682 - acc: 0.4592 - val_loss: 1.1341 - val_acc: 0.4789\n",
      "Epoch 155/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1721 - acc: 0.4600 - val_loss: 1.1368 - val_acc: 0.4881\n",
      "Epoch 156/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1754 - acc: 0.4637 - val_loss: 1.1410 - val_acc: 0.4828\n",
      "Epoch 157/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1616 - acc: 0.4705 - val_loss: 1.1403 - val_acc: 0.4763\n",
      "Epoch 158/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1754 - acc: 0.4546 - val_loss: 1.1355 - val_acc: 0.4921\n",
      "Epoch 159/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1665 - acc: 0.4552 - val_loss: 1.1328 - val_acc: 0.4776\n",
      "Epoch 160/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1604 - acc: 0.4597 - val_loss: 1.1395 - val_acc: 0.5013\n",
      "Epoch 161/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1714 - acc: 0.4530 - val_loss: 1.1395 - val_acc: 0.4683\n",
      "Epoch 162/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1567 - acc: 0.4662 - val_loss: 1.1304 - val_acc: 0.4934\n",
      "Epoch 163/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1674 - acc: 0.4668 - val_loss: 1.1240 - val_acc: 0.5013\n",
      "Epoch 164/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1635 - acc: 0.4668 - val_loss: 1.1271 - val_acc: 0.5066\n",
      "Epoch 165/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1590 - acc: 0.4682 - val_loss: 1.1331 - val_acc: 0.4802\n",
      "Epoch 166/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1571 - acc: 0.4685 - val_loss: 1.1262 - val_acc: 0.4908\n",
      "Epoch 167/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1562 - acc: 0.4654 - val_loss: 1.1324 - val_acc: 0.4828\n",
      "Epoch 168/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1563 - acc: 0.4713 - val_loss: 1.1317 - val_acc: 0.4828\n",
      "Epoch 169/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1600 - acc: 0.4643 - val_loss: 1.1243 - val_acc: 0.4974\n",
      "Epoch 170/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1487 - acc: 0.4730 - val_loss: 1.1203 - val_acc: 0.5026\n",
      "Epoch 171/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1548 - acc: 0.4710 - val_loss: 1.1197 - val_acc: 0.5066\n",
      "Epoch 172/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1463 - acc: 0.4812 - val_loss: 1.1298 - val_acc: 0.4815\n",
      "Epoch 173/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1533 - acc: 0.4685 - val_loss: 1.1224 - val_acc: 0.4908\n",
      "Epoch 174/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1434 - acc: 0.4770 - val_loss: 1.1257 - val_acc: 0.4842\n",
      "Epoch 175/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1523 - acc: 0.4730 - val_loss: 1.1213 - val_acc: 0.4947\n",
      "Epoch 176/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1487 - acc: 0.4713 - val_loss: 1.1261 - val_acc: 0.4894\n",
      "Epoch 177/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1432 - acc: 0.4744 - val_loss: 1.1317 - val_acc: 0.4736\n",
      "Epoch 178/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1368 - acc: 0.4832 - val_loss: 1.1159 - val_acc: 0.5013\n",
      "Epoch 179/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1511 - acc: 0.4792 - val_loss: 1.1151 - val_acc: 0.4987\n",
      "Epoch 180/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1463 - acc: 0.4753 - val_loss: 1.1250 - val_acc: 0.5066\n",
      "Epoch 181/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1580 - acc: 0.4679 - val_loss: 1.1162 - val_acc: 0.4947\n",
      "Epoch 182/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1340 - acc: 0.4708 - val_loss: 1.1144 - val_acc: 0.5053\n",
      "Epoch 183/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1388 - acc: 0.4804 - val_loss: 1.1195 - val_acc: 0.4855\n",
      "Epoch 184/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1486 - acc: 0.4730 - val_loss: 1.1172 - val_acc: 0.4934\n",
      "Epoch 185/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1375 - acc: 0.4691 - val_loss: 1.1136 - val_acc: 0.5000\n",
      "Epoch 186/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1403 - acc: 0.4795 - val_loss: 1.1087 - val_acc: 0.5079\n",
      "Epoch 187/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1378 - acc: 0.4806 - val_loss: 1.1136 - val_acc: 0.5172\n",
      "Epoch 188/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1545 - acc: 0.4702 - val_loss: 1.1197 - val_acc: 0.4776\n",
      "Epoch 189/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1463 - acc: 0.4756 - val_loss: 1.1114 - val_acc: 0.5066\n",
      "Epoch 190/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1355 - acc: 0.4674 - val_loss: 1.1109 - val_acc: 0.4921\n",
      "Epoch 191/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1507 - acc: 0.4671 - val_loss: 1.1065 - val_acc: 0.5040\n",
      "Epoch 192/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1330 - acc: 0.4750 - val_loss: 1.1126 - val_acc: 0.4987\n",
      "Epoch 193/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1397 - acc: 0.4835 - val_loss: 1.1092 - val_acc: 0.5172\n",
      "Epoch 194/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1338 - acc: 0.4744 - val_loss: 1.1084 - val_acc: 0.5066\n",
      "Epoch 195/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1298 - acc: 0.4806 - val_loss: 1.1063 - val_acc: 0.5277\n",
      "Epoch 196/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1355 - acc: 0.4716 - val_loss: 1.1083 - val_acc: 0.5000\n",
      "Epoch 197/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1526 - acc: 0.4736 - val_loss: 1.1099 - val_acc: 0.5119\n",
      "Epoch 198/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1407 - acc: 0.4778 - val_loss: 1.1045 - val_acc: 0.4987\n",
      "Epoch 199/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1295 - acc: 0.4789 - val_loss: 1.0987 - val_acc: 0.5158\n",
      "Epoch 200/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1275 - acc: 0.4798 - val_loss: 1.0932 - val_acc: 0.5211\n",
      "Epoch 201/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1231 - acc: 0.4934 - val_loss: 1.0937 - val_acc: 0.5172\n",
      "Epoch 202/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1169 - acc: 0.4982 - val_loss: 1.0928 - val_acc: 0.5185\n",
      "Epoch 203/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1193 - acc: 0.4914 - val_loss: 1.0919 - val_acc: 0.5264\n",
      "Epoch 204/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1212 - acc: 0.4951 - val_loss: 1.0892 - val_acc: 0.5079\n",
      "Epoch 205/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1193 - acc: 0.4860 - val_loss: 1.0928 - val_acc: 0.5172\n",
      "Epoch 206/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1225 - acc: 0.4905 - val_loss: 1.0992 - val_acc: 0.4987\n",
      "Epoch 207/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1143 - acc: 0.4945 - val_loss: 1.0910 - val_acc: 0.5158\n",
      "Epoch 208/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1205 - acc: 0.4877 - val_loss: 1.0870 - val_acc: 0.5106\n",
      "Epoch 209/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1145 - acc: 0.5007 - val_loss: 1.0900 - val_acc: 0.5119\n",
      "Epoch 210/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1098 - acc: 0.4942 - val_loss: 1.0908 - val_acc: 0.5224\n",
      "Epoch 211/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1218 - acc: 0.4979 - val_loss: 1.0768 - val_acc: 0.5277\n",
      "Epoch 212/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1227 - acc: 0.4829 - val_loss: 1.0779 - val_acc: 0.5277\n",
      "Epoch 213/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1155 - acc: 0.4934 - val_loss: 1.0943 - val_acc: 0.5053\n",
      "Epoch 214/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1186 - acc: 0.4871 - val_loss: 1.0956 - val_acc: 0.5237\n",
      "Epoch 215/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1103 - acc: 0.4880 - val_loss: 1.0874 - val_acc: 0.5264\n",
      "Epoch 216/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1087 - acc: 0.4993 - val_loss: 1.0860 - val_acc: 0.5224\n",
      "Epoch 217/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1143 - acc: 0.4956 - val_loss: 1.0842 - val_acc: 0.5237\n",
      "Epoch 218/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1099 - acc: 0.4852 - val_loss: 1.0816 - val_acc: 0.5158\n",
      "Epoch 219/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1111 - acc: 0.4860 - val_loss: 1.0760 - val_acc: 0.5185\n",
      "Epoch 220/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1184 - acc: 0.4854 - val_loss: 1.0741 - val_acc: 0.5132\n",
      "Epoch 221/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1080 - acc: 0.4948 - val_loss: 1.0812 - val_acc: 0.5198\n",
      "Epoch 222/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1076 - acc: 0.4911 - val_loss: 1.0852 - val_acc: 0.5145\n",
      "Epoch 223/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1188 - acc: 0.4747 - val_loss: 1.0814 - val_acc: 0.5330\n",
      "Epoch 224/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1102 - acc: 0.4968 - val_loss: 1.0894 - val_acc: 0.5092\n",
      "Epoch 225/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1110 - acc: 0.4956 - val_loss: 1.0752 - val_acc: 0.5356\n",
      "Epoch 226/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1039 - acc: 0.5035 - val_loss: 1.0734 - val_acc: 0.5330\n",
      "Epoch 227/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0925 - acc: 0.4976 - val_loss: 1.0791 - val_acc: 0.5264\n",
      "Epoch 228/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0999 - acc: 0.4936 - val_loss: 1.0754 - val_acc: 0.5369\n",
      "Epoch 229/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1077 - acc: 0.4914 - val_loss: 1.0805 - val_acc: 0.5356\n",
      "Epoch 230/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1148 - acc: 0.4965 - val_loss: 1.0716 - val_acc: 0.5264\n",
      "Epoch 231/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1039 - acc: 0.4922 - val_loss: 1.0721 - val_acc: 0.5369\n",
      "Epoch 232/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1071 - acc: 0.4908 - val_loss: 1.0650 - val_acc: 0.5290\n",
      "Epoch 233/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0979 - acc: 0.4934 - val_loss: 1.0724 - val_acc: 0.5264\n",
      "Epoch 234/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0950 - acc: 0.5007 - val_loss: 1.0643 - val_acc: 0.5475\n",
      "Epoch 235/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0927 - acc: 0.5092 - val_loss: 1.0737 - val_acc: 0.5290\n",
      "Epoch 236/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1043 - acc: 0.4968 - val_loss: 1.0699 - val_acc: 0.5251\n",
      "Epoch 237/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0947 - acc: 0.5004 - val_loss: 1.0672 - val_acc: 0.5303\n",
      "Epoch 238/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1010 - acc: 0.4987 - val_loss: 1.0669 - val_acc: 0.5303\n",
      "Epoch 239/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0937 - acc: 0.5027 - val_loss: 1.0691 - val_acc: 0.5264\n",
      "Epoch 240/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0904 - acc: 0.4945 - val_loss: 1.0621 - val_acc: 0.5396\n",
      "Epoch 241/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0916 - acc: 0.5007 - val_loss: 1.0587 - val_acc: 0.5475\n",
      "Epoch 242/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0916 - acc: 0.5100 - val_loss: 1.0669 - val_acc: 0.5277\n",
      "Epoch 243/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1071 - acc: 0.4897 - val_loss: 1.0703 - val_acc: 0.5264\n",
      "Epoch 244/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1108 - acc: 0.4866 - val_loss: 1.0657 - val_acc: 0.5330\n",
      "Epoch 245/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0979 - acc: 0.4894 - val_loss: 1.0606 - val_acc: 0.5396\n",
      "Epoch 246/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0879 - acc: 0.5069 - val_loss: 1.0578 - val_acc: 0.5396\n",
      "Epoch 247/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0886 - acc: 0.5069 - val_loss: 1.0633 - val_acc: 0.5343\n",
      "Epoch 248/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0945 - acc: 0.4984 - val_loss: 1.0618 - val_acc: 0.5343\n",
      "Epoch 249/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0932 - acc: 0.5016 - val_loss: 1.0642 - val_acc: 0.5422\n",
      "Epoch 250/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0918 - acc: 0.5007 - val_loss: 1.0571 - val_acc: 0.5449\n",
      "Epoch 251/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0878 - acc: 0.5117 - val_loss: 1.0568 - val_acc: 0.5330\n",
      "Epoch 252/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0933 - acc: 0.4953 - val_loss: 1.0611 - val_acc: 0.5264\n",
      "Epoch 253/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0979 - acc: 0.4931 - val_loss: 1.0592 - val_acc: 0.5277\n",
      "Epoch 254/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0842 - acc: 0.5058 - val_loss: 1.0525 - val_acc: 0.5409\n",
      "Epoch 255/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0829 - acc: 0.5047 - val_loss: 1.0551 - val_acc: 0.5290\n",
      "Epoch 256/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0973 - acc: 0.4993 - val_loss: 1.0593 - val_acc: 0.5435\n",
      "Epoch 257/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0949 - acc: 0.4965 - val_loss: 1.0649 - val_acc: 0.5369\n",
      "Epoch 258/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0793 - acc: 0.5032 - val_loss: 1.0626 - val_acc: 0.5145\n",
      "Epoch 259/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0852 - acc: 0.5047 - val_loss: 1.0603 - val_acc: 0.5317\n",
      "Epoch 260/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0821 - acc: 0.5035 - val_loss: 1.0582 - val_acc: 0.5251\n",
      "Epoch 261/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0907 - acc: 0.5157 - val_loss: 1.0534 - val_acc: 0.5396\n",
      "Epoch 262/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0850 - acc: 0.5072 - val_loss: 1.0601 - val_acc: 0.5449\n",
      "Epoch 263/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0832 - acc: 0.5100 - val_loss: 1.0523 - val_acc: 0.5541\n",
      "Epoch 264/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.1022 - acc: 0.4999 - val_loss: 1.0547 - val_acc: 0.5290\n",
      "Epoch 265/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0820 - acc: 0.5095 - val_loss: 1.0510 - val_acc: 0.5356\n",
      "Epoch 266/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0774 - acc: 0.4993 - val_loss: 1.0512 - val_acc: 0.5501\n",
      "Epoch 267/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0769 - acc: 0.5114 - val_loss: 1.0469 - val_acc: 0.5369\n",
      "Epoch 268/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0810 - acc: 0.5041 - val_loss: 1.0579 - val_acc: 0.5449\n",
      "Epoch 269/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0720 - acc: 0.5129 - val_loss: 1.0428 - val_acc: 0.5515\n",
      "Epoch 270/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0733 - acc: 0.5114 - val_loss: 1.0451 - val_acc: 0.5475\n",
      "Epoch 271/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0714 - acc: 0.5154 - val_loss: 1.0535 - val_acc: 0.5396\n",
      "Epoch 272/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0846 - acc: 0.5044 - val_loss: 1.0494 - val_acc: 0.5330\n",
      "Epoch 273/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0763 - acc: 0.5092 - val_loss: 1.0424 - val_acc: 0.5422\n",
      "Epoch 274/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0700 - acc: 0.5058 - val_loss: 1.0473 - val_acc: 0.5435\n",
      "Epoch 275/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0735 - acc: 0.5148 - val_loss: 1.0515 - val_acc: 0.5422\n",
      "Epoch 276/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0661 - acc: 0.5129 - val_loss: 1.0407 - val_acc: 0.5475\n",
      "Epoch 277/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0613 - acc: 0.5148 - val_loss: 1.0371 - val_acc: 0.5422\n",
      "Epoch 278/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0651 - acc: 0.5140 - val_loss: 1.0455 - val_acc: 0.5303\n",
      "Epoch 279/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0624 - acc: 0.5191 - val_loss: 1.0417 - val_acc: 0.5409\n",
      "Epoch 280/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0575 - acc: 0.5165 - val_loss: 1.0441 - val_acc: 0.5462\n",
      "Epoch 281/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0656 - acc: 0.5182 - val_loss: 1.0428 - val_acc: 0.5409\n",
      "Epoch 282/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0835 - acc: 0.5052 - val_loss: 1.0440 - val_acc: 0.5277\n",
      "Epoch 283/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0572 - acc: 0.5191 - val_loss: 1.0459 - val_acc: 0.5317\n",
      "Epoch 284/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0667 - acc: 0.5106 - val_loss: 1.0381 - val_acc: 0.5435\n",
      "Epoch 285/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0729 - acc: 0.5049 - val_loss: 1.0383 - val_acc: 0.5343\n",
      "Epoch 286/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0647 - acc: 0.5131 - val_loss: 1.0425 - val_acc: 0.5369\n",
      "Epoch 287/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0527 - acc: 0.5194 - val_loss: 1.0426 - val_acc: 0.5435\n",
      "Epoch 288/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0768 - acc: 0.5171 - val_loss: 1.0394 - val_acc: 0.5554\n",
      "Epoch 289/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0518 - acc: 0.5250 - val_loss: 1.0348 - val_acc: 0.5435\n",
      "Epoch 290/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0712 - acc: 0.5103 - val_loss: 1.0279 - val_acc: 0.5435\n",
      "Epoch 291/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0579 - acc: 0.5216 - val_loss: 1.0368 - val_acc: 0.5449\n",
      "Epoch 292/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0594 - acc: 0.5154 - val_loss: 1.0308 - val_acc: 0.5449\n",
      "Epoch 293/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0487 - acc: 0.5168 - val_loss: 1.0260 - val_acc: 0.5422\n",
      "Epoch 294/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0614 - acc: 0.5160 - val_loss: 1.0335 - val_acc: 0.5435\n",
      "Epoch 295/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0518 - acc: 0.5211 - val_loss: 1.0340 - val_acc: 0.5528\n",
      "Epoch 296/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0651 - acc: 0.5097 - val_loss: 1.0357 - val_acc: 0.5528\n",
      "Epoch 297/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0549 - acc: 0.5097 - val_loss: 1.0248 - val_acc: 0.5528\n",
      "Epoch 298/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0565 - acc: 0.5273 - val_loss: 1.0322 - val_acc: 0.5501\n",
      "Epoch 299/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0531 - acc: 0.5131 - val_loss: 1.0251 - val_acc: 0.5435\n",
      "Epoch 300/300\n",
      "3539/3539 [==============================] - 0s - loss: 1.0582 - acc: 0.5281 - val_loss: 1.0260 - val_acc: 0.5515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1b6c81c450>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 500\n",
    "epochs = 300\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0296555883006047, 0.53157895489742879]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 0s     \n",
      "[1 1 3 1 2 2 0 2 2 2 1 1 2 2 2 2 2 1 2 1 0 3 3 0 3 2 3 0 2 2 2 0 2 2 1 2 0\n",
      " 2 2 1 1 3 0 2 3 0 1 1 2 0 2 0 1 1 1 3 2 2 3 1 0 3 3 2 2 0 3 1 3 0 2 2 2 1\n",
      " 0 2 1 0 0 2 1 1 3 1 3 0 3 0 0 2 2 1 1 1 2 1 3 2 0 2 2 2 1 0 2 1 1 3 1 3 2\n",
      " 0 0 2 2 3 3 3 3 3 2 2 1 0 0 3 1 2 0 2 1 2 2 2 2 2 2 3 2 1 0 2 2 1 1 2 0 2\n",
      " 2 2 0 1 1 0 1 2 2 2 0 0 0 1 2 1 3 1 2 0 1 0 1 3 0 0 1 0 0 1 0 2 2 2 1 1 2\n",
      " 2 2 2 2 1 1 1 0 2 2 3 1 2 3 2 1 1 2 2 2 2 0 2 3 3 3 0 3 0 3 3 3 1 1 1 1 0\n",
      " 2 1 2 2 0 1 0 2 2 2 2 1 2 0 1 3 2 0 1 3 3 3 2 1 1 1 3 0 2 0 0 3 0 2 3 0 0\n",
      " 0 1 0 1 1 2 2 1 1 2 0 2 2 2 3 3 0 3 1 2 3 3 3 3 0 2 0 1 2 3 2 2 0 0 2 1 2\n",
      " 1 3 3 1 2 0 1 0 2 0 3 2 3 3 3 2 2 1 1 2 3 1 2 3 3 0 2 1 1 3 1 1 2 1 1 3 3\n",
      " 0 1 2 2 2 1 3 0 3 0 2 3 0 0 2 2 2 3 3 2 2 2 3 3 1 1 2 2 1 2 1 3 3 0 0 1 0\n",
      " 3 1 1 1 2 2 0 1 0 3 1 3 3 0 3 3 1 3 1 0 3 3 2 0 1 0 3 1 2 2 0 2 0 1 1 3 1\n",
      " 1 0 1 2 2 1 1 1 2 1 1 2 0 3 0 0 2 1 2 0 2 1 1 2 1 2 2 3 1 1 1 1 2 3 2 1 2\n",
      " 1 0 1 3 1 2 1 1 0 1 3 1 0 2 3 3 1 2 2 1 2 1 1 3 0 0 2 1 2 1 1 3 0 3 2 0 2\n",
      " 0 2 0 2 1 1 2 2 3 0 3 2 0 1 2 3 0 3 0 2 0 1 1 0 3 2 3 2 3 2 1 3 0 1 3 0 2\n",
      " 2 0 2 2 1 1 1 2 3 1 1 2 2 3 3 2 1 2 1 2 1 3 2 0 2 3 1 2 1 2 1 1 0 3 2 3 2\n",
      " 2 0 3 2 1 1 3 0 3 1 2 2 0 0 0 2 2 2 2 0 3 2 2 0 3 0 1 2 1 2 3 0 3 2 1 1 2\n",
      " 3 0 2 0 0 1 1 2 1 3 3 2 3 3 2 0 2 0 2 1 3 2 2 3 1 3 1 3 2 2 3 1 0 1 3 2 1\n",
      " 1 3 3 0 3 3 2 0 1 1 1 0 3 1 0 3 3 0 2 0 0 1 2 2 2 0 2 3 3 1 1 3 0 2 0 1 1\n",
      " 2 2 3 3 2 3 1 0 3 2 3 2 2 2 3 1 0 1 3 0 2 3 3 1 1 2 2 2 1 1 1 3 3 2 0 2 2\n",
      " 1 3 1 1 2 0 2 2 2 1 3 2 2 3 1 3 2 2 1 2 0 2 3 1 3 2 0 1 1 1 2 2 2 1 2 1 1\n",
      " 3 2 3 0 0 2 3 1 3 0 2 2 2 2 2 0 2 2 2 0]\n",
      "704/760 [==========================>...] - ETA: 0s                precision    recall  f1-score   support\n",
      "\n",
      "class 0(0back)       0.60      0.42      0.49       207\n",
      "class 1(1back)       0.40      0.59      0.47       135\n",
      "class 2(2back)       0.50      0.62      0.55       204\n",
      "class 3(3back)       0.70      0.52      0.60       214\n",
      "\n",
      "   avg / total       0.56      0.53      0.53       760\n",
      "\n",
      "[[ 87  45  50  25]\n",
      " [ 16  80  31   8]\n",
      " [ 23  40 126  15]\n",
      " [ 19  37  47 111]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(0back)', 'class 1(1back)', 'class 2(2back)', 'class 3(3back)']\n",
    "#target_names = ['class 0(tetris1)', 'class 1(tetris2)', 'class 2(tetris3)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
