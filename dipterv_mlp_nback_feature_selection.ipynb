{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from sklearn import preprocessing\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model,Sequential\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read started...\n",
      "Data read finished.\n",
      "(828, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data read started...\")\n",
    "data = pd.read_csv(\"result_nback.csv\")\n",
    "data = data.as_matrix()\n",
    "print (\"Data read finished.\")\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_selection(data, feature):\n",
    "    if(feature == \"ECG_Burg\"):\n",
    "        data = np.delete(data, 6, 1) \n",
    "        data = np.delete(data, 5, 1) \n",
    "        data = np.delete(data, 3, 1) \n",
    "        data = np.delete(data, 2, 1) \n",
    "    if(feature == \"ECG_TimeSeries\"):\n",
    "        data = np.delete(data, 6, 1) \n",
    "        data = np.delete(data, 5, 1) \n",
    "        data = np.delete(data, 3, 1) \n",
    "        data = np.delete(data, 1, 1) \n",
    "    if(feature == \"ECG_SDNN\"):\n",
    "        data = np.delete(data, 6, 1) \n",
    "        data = np.delete(data, 5, 1) \n",
    "        data = np.delete(data, 2, 1) \n",
    "        data = np.delete(data, 1, 1) \n",
    "    if(feature == \"ECG_SDSD\"):\n",
    "        data = np.delete(data, 6, 1) \n",
    "        data = np.delete(data, 3, 1) \n",
    "        data = np.delete(data, 2, 1) \n",
    "        data = np.delete(data, 1, 1) \n",
    "    if(feature == \"ECG_RMSSD\"):\n",
    "        data = np.delete(data, 5, 1) \n",
    "        data = np.delete(data, 3, 1) \n",
    "        data = np.delete(data, 2, 1) \n",
    "        data = np.delete(data, 1, 1) \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(828, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (1,5):\n",
    "    data = np.delete(data, 1, 1) \n",
    "\n",
    "data = feature_selection(data, \"ECG_SDNN\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nback gyakorlas', 352.6, 4.9275], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary for the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level=[\"nback gyakorlas\",\"0back\",\"1back\",\"2back\",\"3back\"]\n",
    "level2int = dict((p, i) for i, p in enumerate(level))\n",
    "int2level = dict((i, p) for i, p in enumerate(level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/amoro/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,3):\n",
    "    data[:, i] = preprocessing.scale(data[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i, 0] = level2int[data[i, 0]]\n",
    "\n",
    "x_data = data[:, 1:]\n",
    "y_data = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "y_one_hot = ohe.fit_transform(y_data.reshape(-1,1)).toarray()\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_data = x_data[indices]\n",
    "y_one_hot = y_one_hot[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_data = len(x_data)\n",
    "\n",
    "nb_test = int(len_data*0.15)\n",
    "nb_validation = int(len_data*0.15)\n",
    "nb_train = int(len_data*0.7)\n",
    "\n",
    "end_valid = nb_train+nb_validation\n",
    "\n",
    "x_train = x_data[0:nb_train]\n",
    "y_train = y_one_hot[0:nb_train]\n",
    "\n",
    "x_valid = x_data[nb_train:end_valid]\n",
    "y_valid = y_one_hot[nb_train:end_valid]\n",
    "\n",
    "x_test = x_data[end_valid:]\n",
    "y_test = y_one_hot[end_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 2) (579, 5) (124, 2) (124, 5) (125, 2) (125, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(200, input_shape=(2,)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579 samples, validate on 124 samples\n",
      "Epoch 1/150\n",
      "579/579 [==============================] - 0s - loss: 1.5679 - acc: 0.3506 - val_loss: 1.4750 - val_acc: 0.4113\n",
      "Epoch 2/150\n",
      "579/579 [==============================] - 0s - loss: 1.4795 - acc: 0.4059 - val_loss: 1.4130 - val_acc: 0.4032\n",
      "Epoch 3/150\n",
      "579/579 [==============================] - 0s - loss: 1.4345 - acc: 0.4335 - val_loss: 1.3726 - val_acc: 0.3871\n",
      "Epoch 4/150\n",
      "579/579 [==============================] - 0s - loss: 1.4080 - acc: 0.4335 - val_loss: 1.3499 - val_acc: 0.4032\n",
      "Epoch 5/150\n",
      "579/579 [==============================] - 0s - loss: 1.3990 - acc: 0.4145 - val_loss: 1.3165 - val_acc: 0.4677\n",
      "Epoch 6/150\n",
      "579/579 [==============================] - 0s - loss: 1.3696 - acc: 0.4508 - val_loss: 1.2958 - val_acc: 0.4435\n",
      "Epoch 7/150\n",
      "579/579 [==============================] - 0s - loss: 1.3640 - acc: 0.4370 - val_loss: 1.2958 - val_acc: 0.4274\n",
      "Epoch 8/150\n",
      "579/579 [==============================] - 0s - loss: 1.3426 - acc: 0.4387 - val_loss: 1.2798 - val_acc: 0.4113\n",
      "Epoch 9/150\n",
      "579/579 [==============================] - 0s - loss: 1.3386 - acc: 0.4456 - val_loss: 1.2572 - val_acc: 0.4516\n",
      "Epoch 10/150\n",
      "579/579 [==============================] - 0s - loss: 1.2950 - acc: 0.4352 - val_loss: 1.2421 - val_acc: 0.4435\n",
      "Epoch 11/150\n",
      "579/579 [==============================] - 0s - loss: 1.2838 - acc: 0.4439 - val_loss: 1.2457 - val_acc: 0.4435\n",
      "Epoch 12/150\n",
      "579/579 [==============================] - 0s - loss: 1.2850 - acc: 0.4473 - val_loss: 1.2277 - val_acc: 0.4597\n",
      "Epoch 13/150\n",
      "579/579 [==============================] - 0s - loss: 1.2843 - acc: 0.4473 - val_loss: 1.2223 - val_acc: 0.4435\n",
      "Epoch 14/150\n",
      "579/579 [==============================] - 0s - loss: 1.2623 - acc: 0.4560 - val_loss: 1.2091 - val_acc: 0.4516\n",
      "Epoch 15/150\n",
      "579/579 [==============================] - 0s - loss: 1.2534 - acc: 0.4663 - val_loss: 1.2152 - val_acc: 0.4597\n",
      "Epoch 16/150\n",
      "579/579 [==============================] - 0s - loss: 1.2427 - acc: 0.4715 - val_loss: 1.2049 - val_acc: 0.4677\n",
      "Epoch 17/150\n",
      "579/579 [==============================] - 0s - loss: 1.2409 - acc: 0.4801 - val_loss: 1.1876 - val_acc: 0.4435\n",
      "Epoch 18/150\n",
      "579/579 [==============================] - 0s - loss: 1.2213 - acc: 0.4801 - val_loss: 1.1934 - val_acc: 0.4435\n",
      "Epoch 19/150\n",
      "579/579 [==============================] - 0s - loss: 1.2316 - acc: 0.4663 - val_loss: 1.1955 - val_acc: 0.4758\n",
      "Epoch 20/150\n",
      "579/579 [==============================] - 0s - loss: 1.2311 - acc: 0.4698 - val_loss: 1.1757 - val_acc: 0.4355\n",
      "Epoch 21/150\n",
      "579/579 [==============================] - 0s - loss: 1.1912 - acc: 0.4888 - val_loss: 1.1831 - val_acc: 0.4758\n",
      "Epoch 22/150\n",
      "579/579 [==============================] - 0s - loss: 1.1999 - acc: 0.4646 - val_loss: 1.1749 - val_acc: 0.4355\n",
      "Epoch 23/150\n",
      "579/579 [==============================] - 0s - loss: 1.1617 - acc: 0.5130 - val_loss: 1.1852 - val_acc: 0.4194\n",
      "Epoch 24/150\n",
      "579/579 [==============================] - 0s - loss: 1.1953 - acc: 0.4801 - val_loss: 1.1616 - val_acc: 0.4839\n",
      "Epoch 25/150\n",
      "579/579 [==============================] - 0s - loss: 1.1859 - acc: 0.4870 - val_loss: 1.1543 - val_acc: 0.4516\n",
      "Epoch 26/150\n",
      "579/579 [==============================] - 0s - loss: 1.1633 - acc: 0.4750 - val_loss: 1.1539 - val_acc: 0.4597\n",
      "Epoch 27/150\n",
      "579/579 [==============================] - 0s - loss: 1.1473 - acc: 0.4905 - val_loss: 1.1719 - val_acc: 0.4839\n",
      "Epoch 28/150\n",
      "579/579 [==============================] - 0s - loss: 1.1648 - acc: 0.4991 - val_loss: 1.1556 - val_acc: 0.4597\n",
      "Epoch 29/150\n",
      "579/579 [==============================] - 0s - loss: 1.1535 - acc: 0.4922 - val_loss: 1.1507 - val_acc: 0.4677\n",
      "Epoch 30/150\n",
      "579/579 [==============================] - 0s - loss: 1.1677 - acc: 0.4836 - val_loss: 1.1422 - val_acc: 0.4677\n",
      "Epoch 31/150\n",
      "579/579 [==============================] - 0s - loss: 1.1448 - acc: 0.4801 - val_loss: 1.1652 - val_acc: 0.4435\n",
      "Epoch 32/150\n",
      "579/579 [==============================] - 0s - loss: 1.1477 - acc: 0.5164 - val_loss: 1.1331 - val_acc: 0.4677\n",
      "Epoch 33/150\n",
      "579/579 [==============================] - 0s - loss: 1.1492 - acc: 0.5302 - val_loss: 1.1264 - val_acc: 0.5000\n",
      "Epoch 34/150\n",
      "579/579 [==============================] - 0s - loss: 1.1346 - acc: 0.4888 - val_loss: 1.1398 - val_acc: 0.4516\n",
      "Epoch 35/150\n",
      "579/579 [==============================] - 0s - loss: 1.1292 - acc: 0.5026 - val_loss: 1.1368 - val_acc: 0.5000\n",
      "Epoch 36/150\n",
      "579/579 [==============================] - 0s - loss: 1.1311 - acc: 0.5268 - val_loss: 1.1133 - val_acc: 0.5081\n",
      "Epoch 37/150\n",
      "579/579 [==============================] - 0s - loss: 1.1303 - acc: 0.4922 - val_loss: 1.1248 - val_acc: 0.5081\n",
      "Epoch 38/150\n",
      "579/579 [==============================] - 0s - loss: 1.1259 - acc: 0.5147 - val_loss: 1.1388 - val_acc: 0.4677\n",
      "Epoch 39/150\n",
      "579/579 [==============================] - 0s - loss: 1.0908 - acc: 0.5250 - val_loss: 1.1125 - val_acc: 0.4677\n",
      "Epoch 40/150\n",
      "579/579 [==============================] - 0s - loss: 1.1330 - acc: 0.5078 - val_loss: 1.1277 - val_acc: 0.4758\n",
      "Epoch 41/150\n",
      "579/579 [==============================] - 0s - loss: 1.0920 - acc: 0.5337 - val_loss: 1.1001 - val_acc: 0.4597\n",
      "Epoch 42/150\n",
      "579/579 [==============================] - 0s - loss: 1.1117 - acc: 0.5233 - val_loss: 1.1061 - val_acc: 0.5242\n",
      "Epoch 43/150\n",
      "579/579 [==============================] - 0s - loss: 1.1255 - acc: 0.5095 - val_loss: 1.1083 - val_acc: 0.4677\n",
      "Epoch 44/150\n",
      "579/579 [==============================] - 0s - loss: 1.1027 - acc: 0.5026 - val_loss: 1.1314 - val_acc: 0.4677\n",
      "Epoch 45/150\n",
      "579/579 [==============================] - 0s - loss: 1.1157 - acc: 0.5302 - val_loss: 1.1217 - val_acc: 0.4677\n",
      "Epoch 46/150\n",
      "579/579 [==============================] - 0s - loss: 1.1043 - acc: 0.5389 - val_loss: 1.0933 - val_acc: 0.5081\n",
      "Epoch 47/150\n",
      "579/579 [==============================] - 0s - loss: 1.0894 - acc: 0.5164 - val_loss: 1.1103 - val_acc: 0.5081\n",
      "Epoch 48/150\n",
      "579/579 [==============================] - 0s - loss: 1.0835 - acc: 0.5440 - val_loss: 1.1088 - val_acc: 0.5000\n",
      "Epoch 49/150\n",
      "579/579 [==============================] - 0s - loss: 1.0943 - acc: 0.5216 - val_loss: 1.1024 - val_acc: 0.5000\n",
      "Epoch 50/150\n",
      "579/579 [==============================] - 0s - loss: 1.0747 - acc: 0.5233 - val_loss: 1.0898 - val_acc: 0.5000\n",
      "Epoch 51/150\n",
      "579/579 [==============================] - 0s - loss: 1.0823 - acc: 0.5371 - val_loss: 1.1073 - val_acc: 0.4597\n",
      "Epoch 52/150\n",
      "579/579 [==============================] - 0s - loss: 1.0844 - acc: 0.5147 - val_loss: 1.0878 - val_acc: 0.5161\n",
      "Epoch 53/150\n",
      "579/579 [==============================] - 0s - loss: 1.0477 - acc: 0.5509 - val_loss: 1.0834 - val_acc: 0.5161\n",
      "Epoch 54/150\n",
      "579/579 [==============================] - 0s - loss: 1.0623 - acc: 0.5371 - val_loss: 1.0998 - val_acc: 0.5161\n",
      "Epoch 55/150\n",
      "579/579 [==============================] - 0s - loss: 1.0685 - acc: 0.5181 - val_loss: 1.0770 - val_acc: 0.5081\n",
      "Epoch 56/150\n",
      "579/579 [==============================] - 0s - loss: 1.0519 - acc: 0.5544 - val_loss: 1.0833 - val_acc: 0.5081\n",
      "Epoch 57/150\n",
      "579/579 [==============================] - 0s - loss: 1.0660 - acc: 0.5440 - val_loss: 1.0754 - val_acc: 0.5081\n",
      "Epoch 58/150\n",
      "579/579 [==============================] - 0s - loss: 1.0865 - acc: 0.5147 - val_loss: 1.0827 - val_acc: 0.5081\n",
      "Epoch 59/150\n",
      "579/579 [==============================] - 0s - loss: 1.0663 - acc: 0.5320 - val_loss: 1.0759 - val_acc: 0.5161\n",
      "Epoch 60/150\n",
      "579/579 [==============================] - 0s - loss: 1.0441 - acc: 0.5579 - val_loss: 1.0723 - val_acc: 0.5484\n",
      "Epoch 61/150\n",
      "579/579 [==============================] - 0s - loss: 1.0655 - acc: 0.5337 - val_loss: 1.0769 - val_acc: 0.5323\n",
      "Epoch 62/150\n",
      "579/579 [==============================] - 0s - loss: 1.0545 - acc: 0.5613 - val_loss: 1.0886 - val_acc: 0.5242\n",
      "Epoch 63/150\n",
      "579/579 [==============================] - 0s - loss: 1.0309 - acc: 0.5527 - val_loss: 1.0694 - val_acc: 0.5403\n",
      "Epoch 64/150\n",
      "579/579 [==============================] - 0s - loss: 1.0650 - acc: 0.5371 - val_loss: 1.0812 - val_acc: 0.5161\n",
      "Epoch 65/150\n",
      "579/579 [==============================] - 0s - loss: 1.0660 - acc: 0.5579 - val_loss: 1.0669 - val_acc: 0.5484\n",
      "Epoch 66/150\n",
      "579/579 [==============================] - 0s - loss: 1.0368 - acc: 0.5509 - val_loss: 1.0742 - val_acc: 0.5242\n",
      "Epoch 67/150\n",
      "579/579 [==============================] - 0s - loss: 1.0377 - acc: 0.5492 - val_loss: 1.0676 - val_acc: 0.5484\n",
      "Epoch 68/150\n",
      "579/579 [==============================] - 0s - loss: 1.0340 - acc: 0.5509 - val_loss: 1.0547 - val_acc: 0.5484\n",
      "Epoch 69/150\n",
      "579/579 [==============================] - 0s - loss: 1.0557 - acc: 0.5544 - val_loss: 1.0636 - val_acc: 0.5323\n",
      "Epoch 70/150\n",
      "579/579 [==============================] - 0s - loss: 1.0428 - acc: 0.5406 - val_loss: 1.0829 - val_acc: 0.5242\n",
      "Epoch 71/150\n",
      "579/579 [==============================] - 0s - loss: 1.0462 - acc: 0.5475 - val_loss: 1.0476 - val_acc: 0.5484\n",
      "Epoch 72/150\n",
      "579/579 [==============================] - 0s - loss: 1.0321 - acc: 0.5544 - val_loss: 1.0568 - val_acc: 0.5323\n",
      "Epoch 73/150\n",
      "579/579 [==============================] - 0s - loss: 1.0546 - acc: 0.5492 - val_loss: 1.0679 - val_acc: 0.5323\n",
      "Epoch 74/150\n",
      "579/579 [==============================] - 0s - loss: 1.0509 - acc: 0.5509 - val_loss: 1.0540 - val_acc: 0.5081\n",
      "Epoch 75/150\n",
      "579/579 [==============================] - 0s - loss: 1.0247 - acc: 0.5561 - val_loss: 1.0516 - val_acc: 0.5161\n",
      "Epoch 76/150\n",
      "579/579 [==============================] - 0s - loss: 1.0356 - acc: 0.5509 - val_loss: 1.0520 - val_acc: 0.5323\n",
      "Epoch 77/150\n",
      "579/579 [==============================] - 0s - loss: 1.0502 - acc: 0.5440 - val_loss: 1.0640 - val_acc: 0.5000\n",
      "Epoch 78/150\n",
      "579/579 [==============================] - 0s - loss: 1.0335 - acc: 0.5665 - val_loss: 1.0518 - val_acc: 0.5323\n",
      "Epoch 79/150\n",
      "579/579 [==============================] - 0s - loss: 1.0114 - acc: 0.5613 - val_loss: 1.0805 - val_acc: 0.5161\n",
      "Epoch 80/150\n",
      "579/579 [==============================] - 0s - loss: 1.0113 - acc: 0.5475 - val_loss: 1.0655 - val_acc: 0.5242\n",
      "Epoch 81/150\n",
      "579/579 [==============================] - 0s - loss: 1.0405 - acc: 0.5648 - val_loss: 1.0566 - val_acc: 0.5242\n",
      "Epoch 82/150\n",
      "579/579 [==============================] - 0s - loss: 1.0353 - acc: 0.5648 - val_loss: 1.0789 - val_acc: 0.5323\n",
      "Epoch 83/150\n",
      "579/579 [==============================] - 0s - loss: 1.0461 - acc: 0.5423 - val_loss: 1.0777 - val_acc: 0.5323\n",
      "Epoch 84/150\n",
      "579/579 [==============================] - 0s - loss: 1.0220 - acc: 0.5492 - val_loss: 1.0388 - val_acc: 0.5565\n",
      "Epoch 85/150\n",
      "579/579 [==============================] - 0s - loss: 1.0129 - acc: 0.5665 - val_loss: 1.0597 - val_acc: 0.5323\n",
      "Epoch 86/150\n",
      "579/579 [==============================] - 0s - loss: 0.9945 - acc: 0.5786 - val_loss: 1.0505 - val_acc: 0.5565\n",
      "Epoch 87/150\n",
      "579/579 [==============================] - 0s - loss: 1.0090 - acc: 0.5682 - val_loss: 1.0441 - val_acc: 0.5565\n",
      "Epoch 88/150\n",
      "579/579 [==============================] - 0s - loss: 1.0064 - acc: 0.5699 - val_loss: 1.0619 - val_acc: 0.5161\n",
      "Epoch 89/150\n",
      "579/579 [==============================] - 0s - loss: 1.0233 - acc: 0.5509 - val_loss: 1.0385 - val_acc: 0.5161\n",
      "Epoch 90/150\n",
      "579/579 [==============================] - 0s - loss: 1.0116 - acc: 0.5682 - val_loss: 1.0567 - val_acc: 0.5403\n",
      "Epoch 91/150\n",
      "579/579 [==============================] - 0s - loss: 1.0286 - acc: 0.5717 - val_loss: 1.0414 - val_acc: 0.5565\n",
      "Epoch 92/150\n",
      "579/579 [==============================] - 0s - loss: 0.9932 - acc: 0.5630 - val_loss: 1.0676 - val_acc: 0.5403\n",
      "Epoch 93/150\n",
      "579/579 [==============================] - 0s - loss: 1.0103 - acc: 0.5769 - val_loss: 1.0324 - val_acc: 0.5565\n",
      "Epoch 94/150\n",
      "579/579 [==============================] - 0s - loss: 1.0237 - acc: 0.5682 - val_loss: 1.0522 - val_acc: 0.5242\n",
      "Epoch 95/150\n",
      "579/579 [==============================] - 0s - loss: 1.0174 - acc: 0.5423 - val_loss: 1.0326 - val_acc: 0.5242\n",
      "Epoch 96/150\n",
      "579/579 [==============================] - 0s - loss: 1.0285 - acc: 0.5561 - val_loss: 1.0368 - val_acc: 0.5403\n",
      "Epoch 97/150\n",
      "579/579 [==============================] - 0s - loss: 0.9942 - acc: 0.5699 - val_loss: 1.0450 - val_acc: 0.5645\n",
      "Epoch 98/150\n",
      "579/579 [==============================] - 0s - loss: 1.0078 - acc: 0.5630 - val_loss: 1.0339 - val_acc: 0.5323\n",
      "Epoch 99/150\n",
      "579/579 [==============================] - 0s - loss: 1.0231 - acc: 0.5544 - val_loss: 1.0389 - val_acc: 0.5484\n",
      "Epoch 100/150\n",
      "579/579 [==============================] - 0s - loss: 1.0108 - acc: 0.5561 - val_loss: 1.0313 - val_acc: 0.5403\n",
      "Epoch 101/150\n",
      "579/579 [==============================] - 0s - loss: 1.0049 - acc: 0.5492 - val_loss: 1.0612 - val_acc: 0.5323\n",
      "Epoch 102/150\n",
      "579/579 [==============================] - 0s - loss: 0.9969 - acc: 0.5769 - val_loss: 1.0267 - val_acc: 0.5565\n",
      "Epoch 103/150\n",
      "579/579 [==============================] - 0s - loss: 1.0084 - acc: 0.5769 - val_loss: 1.0228 - val_acc: 0.5565\n",
      "Epoch 104/150\n",
      "579/579 [==============================] - 0s - loss: 1.0069 - acc: 0.5492 - val_loss: 1.0466 - val_acc: 0.5323\n",
      "Epoch 105/150\n",
      "579/579 [==============================] - 0s - loss: 1.0224 - acc: 0.5579 - val_loss: 1.0415 - val_acc: 0.5161\n",
      "Epoch 106/150\n",
      "579/579 [==============================] - 0s - loss: 0.9940 - acc: 0.5803 - val_loss: 1.0265 - val_acc: 0.5242\n",
      "Epoch 107/150\n",
      "579/579 [==============================] - 0s - loss: 1.0035 - acc: 0.5579 - val_loss: 1.0133 - val_acc: 0.5565\n",
      "Epoch 108/150\n",
      "579/579 [==============================] - 0s - loss: 0.9869 - acc: 0.5717 - val_loss: 1.0210 - val_acc: 0.5403\n",
      "Epoch 109/150\n",
      "579/579 [==============================] - 0s - loss: 1.0028 - acc: 0.5803 - val_loss: 1.0140 - val_acc: 0.5565\n",
      "Epoch 110/150\n",
      "579/579 [==============================] - 0s - loss: 0.9815 - acc: 0.5751 - val_loss: 1.0263 - val_acc: 0.5565\n",
      "Epoch 111/150\n",
      "579/579 [==============================] - 0s - loss: 0.9886 - acc: 0.5751 - val_loss: 1.0195 - val_acc: 0.5484\n",
      "Epoch 112/150\n",
      "579/579 [==============================] - 0s - loss: 0.9755 - acc: 0.5682 - val_loss: 1.0454 - val_acc: 0.5242\n",
      "Epoch 113/150\n",
      "579/579 [==============================] - 0s - loss: 1.0313 - acc: 0.5682 - val_loss: 1.0445 - val_acc: 0.5806\n",
      "Epoch 114/150\n",
      "579/579 [==============================] - 0s - loss: 0.9982 - acc: 0.5613 - val_loss: 1.0251 - val_acc: 0.5565\n",
      "Epoch 115/150\n",
      "579/579 [==============================] - 0s - loss: 0.9790 - acc: 0.5976 - val_loss: 1.0194 - val_acc: 0.5726\n",
      "Epoch 116/150\n",
      "579/579 [==============================] - 0s - loss: 0.9686 - acc: 0.5820 - val_loss: 1.0354 - val_acc: 0.5565\n",
      "Epoch 117/150\n",
      "579/579 [==============================] - 0s - loss: 0.9818 - acc: 0.5630 - val_loss: 1.0289 - val_acc: 0.5484\n",
      "Epoch 118/150\n",
      "579/579 [==============================] - 0s - loss: 1.0022 - acc: 0.5613 - val_loss: 1.0200 - val_acc: 0.5403\n",
      "Epoch 119/150\n",
      "579/579 [==============================] - 0s - loss: 1.0167 - acc: 0.5423 - val_loss: 1.0312 - val_acc: 0.5323\n",
      "Epoch 120/150\n",
      "579/579 [==============================] - 0s - loss: 0.9862 - acc: 0.5769 - val_loss: 1.0304 - val_acc: 0.5887\n",
      "Epoch 121/150\n",
      "579/579 [==============================] - 0s - loss: 0.9874 - acc: 0.5769 - val_loss: 1.0214 - val_acc: 0.5968\n",
      "Epoch 122/150\n",
      "579/579 [==============================] - 0s - loss: 0.9847 - acc: 0.5561 - val_loss: 1.0200 - val_acc: 0.5484\n",
      "Epoch 123/150\n",
      "579/579 [==============================] - 0s - loss: 0.9798 - acc: 0.5786 - val_loss: 1.0205 - val_acc: 0.5565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4d116fdd90>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "epochs = 150\n",
    "earlyStopping=keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=0, mode='auto')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.fit(x_train, y_train, nb_epoch=epochs,batch_size=batch_size, \n",
    "          callbacks=[earlyStopping], shuffle=True, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50/125 [===========>..................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0507098436355591, 0.54399999380111697]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s     \n",
      "[2 0 3 3 3 0 1 1 2 4 0 2 1 1 3 1 3 4 3 2 0 0 4 4 3 4 0 1 1 4 1 4 0 1 1 2 2\n",
      " 2 3 0 1 1 2 4 0 4 2 0 1 1 2 4 0 1 4 3 1 3 1 1 4 3 1 2 4 2 4 0 2 3 4 4 2 4\n",
      " 0 3 4 3 2 1 1 4 4 4 1 0 1 1 2 2 1 2 3 4 4 2 4 1 1 3 1 4 2 3 2 4 0 4 0 0 1\n",
      " 4 3 3 3 1 3 1 1 3 1 3 2 4 3]\n",
      " 32/125 [======>.......................] - ETA: 0s                          precision    recall  f1-score   support\n",
      "\n",
      "class 0(nback gyakorlas)       0.35      0.30      0.32        20\n",
      "          class 1(0back)       0.24      0.42      0.31        19\n",
      "          class 2(1back)       0.32      0.35      0.33        20\n",
      "          class 3(2back)       0.54      0.48      0.51        27\n",
      "          class 4(3back)       0.72      0.54      0.62        39\n",
      "\n",
      "             avg / total       0.49      0.44      0.45       125\n",
      "\n",
      "[[ 6  7  3  4  0]\n",
      " [ 3  8  6  1  1]\n",
      " [ 0  4  7  2  7]\n",
      " [ 5  5  4 13  0]\n",
      " [ 3  9  2  4 21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(y_pred)\n",
    "\n",
    "p=model.predict_proba(x_test)\n",
    "\n",
    "target_names = ['class 0(nback gyakorlas)', 'class 1(0back)', 'class 2(1back)', 'class 3(2back)', 'class 4(3back)']\n",
    "print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
